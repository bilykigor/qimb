{
 "metadata": {
  "name": "",
  "signature": "sha256:7e093d01f440c3ed03581298e1b9aaa19575f21b87bb2bf977a75cf320547888"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import datetime\n",
      "from ggplot import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def import_month(month):\n",
      "    import os.path\n",
      "    df=pd.DataFrame()\n",
      "    \n",
      "    if month<10:\n",
      "        m = '0%s' % month\n",
      "    else:\n",
      "        m = '%s' % month\n",
      "    \n",
      "    #Read data for the month\n",
      "    for i in range (1,32):  \n",
      "        if i<10:\n",
      "            d = '0%s' % i\n",
      "        else:\n",
      "            d = '%s' % i\n",
      "        \n",
      "        f = '/home/user1/PyProjects/data/2014-%s-%s/CommonAggr_2014-%s-%s.csv' % (m,d,m,d)\n",
      "        \n",
      "        if (not os.path.isfile(f)): continue\n",
      "            \n",
      "        if (df.shape[0]==0):\n",
      "            df = pd.read_csv(f, low_memory=False)\n",
      "        else:\n",
      "            df=df.append(pd.read_csv(f, low_memory=False))\n",
      "    \n",
      "    #Set target columns\n",
      "    target_cols = ['Date','Time','Fracs','Symbol','Reason','tSide','tPrice','tShares',\n",
      "                    'Bid_P', 'Bid_S', 'Ask_P', 'Ask_S', \n",
      "                    'ImbRef','ImbCBC', 'ImbFar', 'ImbShares', 'ImbPaired']\n",
      "\n",
      "    #Get target columts from the data\n",
      "    df = df[target_cols]\n",
      "    df.index = range(df.shape[0])\n",
      "    \n",
      "    return df\n",
      "\n",
      "def import_file(f):\n",
      "    df = pd.read_csv('/home/user1/PyProjects/data/' + f, low_memory=False)\n",
      "    target_cols = ['Date','Time','Fracs','Symbol','Reason','tSide','tPrice','tShares',\n",
      "                    'Bid_P', 'Bid_S', 'Ask_P', 'Ask_S', \n",
      "                    'ImbRef','ImbCBC', 'ImbFar', 'ImbShares', 'ImbPaired']\n",
      "\n",
      "    df = df[target_cols]\n",
      "    df.index = range(df.shape[0])\n",
      "    \n",
      "    return df\n",
      "  \n",
      "def create_timestamp(df):\n",
      "    Timestamp = []\n",
      "    for i in range(df.shape[0]):\n",
      "        Timestamp.append(datetime.datetime.strptime(df.Date[i] +' '+df.Time[i]+' '+df.Fracs[i][0:3]+df.Fracs[i][4:7],'%Y-%m-%d %H:%M:%S %f'))\n",
      "\n",
      "    df['Timestamp'] = Timestamp\n",
      "    df = df.set_index(['Timestamp'])\n",
      "    df = df.drop(['Date','Time','Fracs'],1)\n",
      "    \n",
      "    return df\n",
      "\n",
      "def sigmoid(x):\n",
      "    import numpy\n",
      "    return 1/(1+numpy.exp(-x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Visualization of features\n",
      "from sklearn import preprocessing\n",
      "def visualize(fdf,Features,f,binwidth,scaled):\n",
      "    fdf_new = fdf.copy()\n",
      "    if scaled:\n",
      "        fdf_new[f] = preprocessing.scale(fdf_new[f])\n",
      "    g=ggplot(fdf_new[fdf_new.Move<0],aes(x=f)) + \\\n",
      "    geom_histogram(color='red',binwidth = binwidth,alpha=0.25,\\\n",
      "                   fill = 'red') + \\\n",
      "    geom_histogram(fdf_new[fdf_new.Move>0],aes(x=f), \\\n",
      "                   color='green',fill = 'green',\\\n",
      "                   binwidth = binwidth,alpha=0.25) + \\\n",
      "    ggtitle(Features[f]) \n",
      "    #xlim(-1,1)+ ylim(-20,20)\n",
      "    return g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_imbelanceMSG(df,nImb):\n",
      "    startTime = '9:27:58'\n",
      "    endTime = '9:28:03'\n",
      "    if nImb==2:\n",
      "        startTime = '9:28:03'\n",
      "        endTime = '9:28:08'\n",
      "    elif nImb==3:\n",
      "        startTime = '9:28:08'\n",
      "        endTime = '9:28:12'\n",
      "    elif nImb==4:\n",
      "        startTime = '9:28:12'\n",
      "        endTime = '9:28:18'\n",
      "    elif nImb==5:\n",
      "        startTime = '9:28:18'\n",
      "        endTime = '9:28:22'\n",
      "    elif nImb==6:\n",
      "        startTime = '9:28:22'\n",
      "        endTime = '9:28:28'\n",
      "    elif nImb==7:\n",
      "        startTime = '9:28:28'\n",
      "        endTime = '9:28:32'\n",
      "    elif nImb==8:\n",
      "        startTime = '9:28:32'\n",
      "        endTime = '9:28:38'\n",
      "    elif nImb==9:\n",
      "        startTime = '9:28:38'\n",
      "        endTime = '9:28:42'\n",
      "    elif nImb==10:\n",
      "        startTime = '9:28:42'\n",
      "        endTime = '9:28:48'\n",
      "    elif nImb==11:\n",
      "        startTime = '9:28:48'\n",
      "        endTime = '9:28:52'\n",
      "    elif nImb==12:\n",
      "        startTime = '9:28:52'\n",
      "        endTime = '9:28:58'\n",
      "    elif nImb==13:\n",
      "        startTime = '9:28:58'\n",
      "        endTime = '9:29:02'\n",
      "    elif nImb==14:\n",
      "        startTime = '9:29:02'\n",
      "        endTime = '9:29:08'\n",
      "    elif nImb==15:\n",
      "        startTime = '9:29:08'\n",
      "        endTime = '9:29:12'\n",
      "    elif nImb==16:\n",
      "        startTime = '9:29:12'\n",
      "        endTime = '9:29:18'\n",
      "    elif nImb==17:\n",
      "        startTime = '9:29:18'\n",
      "        endTime = '9:29:22'\n",
      "    elif nImb==18:\n",
      "        startTime = '9:29:22'\n",
      "        endTime = '9:29:28'\n",
      "    elif nImb==19:\n",
      "        startTime = '9:29:28'\n",
      "        endTime = '9:29:32'\n",
      "    elif nImb==20:\n",
      "        startTime = '9:29:32'\n",
      "        endTime = '9:29:38'\n",
      "    elif nImb==21:\n",
      "        startTime = '9:29:38'\n",
      "        endTime = '9:29:42'\n",
      "    elif nImb==22:\n",
      "        startTime = '9:29:42'\n",
      "        endTime = '9:29:48'\n",
      "    elif nImb==23:\n",
      "        startTime = '9:29:48'\n",
      "        endTime = '9:29:52'\n",
      "    elif nImb==24:\n",
      "        startTime = '9:29:52'\n",
      "        endTime = '9:29:58'\n",
      "\n",
      "    \n",
      "    imbalanceMsg = df[df.Reason == 'Imbalance'].between_time(startTime,endTime)\n",
      "    #.between_time('9:29:52','9:29:57')\n",
      "    imbalanceMsg = imbalanceMsg[\n",
      "    (imbalanceMsg.Bid_P>0.01) & \n",
      "    (imbalanceMsg.Ask_P<199999.99) & \n",
      "    (imbalanceMsg.ImbRef>0) & \n",
      "    (imbalanceMsg.ImbCBC>0) &\n",
      "    (imbalanceMsg.ImbFar>0) &\n",
      "    (imbalanceMsg.ImbShares!=0)\n",
      "    ]\n",
      "\n",
      "    imbalanceMsg = imbalanceMsg[['Symbol','Bid_P','Bid_S','Ask_P','Ask_S','ImbRef','ImbCBC','ImbFar','ImbShares','ImbPaired']]\n",
      "    imbalanceMsg['Date'] = imbalanceMsg.index.date\n",
      "    imbalanceMsg['Timestamp'] = imbalanceMsg.index\n",
      "        \n",
      "    #Getting additional info about previous day\n",
      "    OPC = df[df.Reason == 'OPG']\n",
      "    OPC = OPC[['Symbol','tPrice']]\n",
      "    OPC.columns = ['Symbol','OPC_P']\n",
      "    OPC['Date'] = OPC.index.date\n",
      "\n",
      "    prev_OPC = df[df.Reason == 'OPG']\n",
      "    prev_OPC = prev_OPC[['Symbol','tPrice','tShares']]\n",
      "    prev_OPC.columns = ['Symbol','PrevOPC_P','PrevOPC_S']\n",
      "    prev_OPC['Date'] = prev_OPC.index.date\n",
      "    for i in range(prev_OPC.shape[0]):\n",
      "        if prev_OPC.Date[i].weekday()==4:\n",
      "            prev_OPC.Date[i]+=datetime.timedelta(days=3)\n",
      "        else:\n",
      "            prev_OPC.Date[i]+=datetime.timedelta(days=1)\n",
      "\n",
      "    prev_CLC = df[df.tSide == 'YDAY']\n",
      "    prev_CLC = prev_CLC[['Symbol','tPrice','tShares']]\n",
      "    prev_CLC.columns = ['Symbol','PrevCLC_P','PrevCLC_S']\n",
      "    prev_CLC['Date'] = prev_CLC.index.date\n",
      "\n",
      "    #Adding prev day info to imbalance information\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_CLC, on=['Symbol','Date'])\n",
      "\n",
      "    #Filtering data with no prev OPC or prev CLC\n",
      "    imbalanceMsg = imbalanceMsg[(imbalanceMsg.OPC_P>0) & (imbalanceMsg.PrevOPC_P>0)]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])\n",
      "    \n",
      "    #Adding new feature which reflects price move direction\n",
      "    imbalanceMsg['Move'] = imbalanceMsg.Bid_P\n",
      "    imbalanceMsg.Move = 0\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P>imbalanceMsg.Ask_P] = 1\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P<imbalanceMsg.Bid_P] = -1\n",
      "    \n",
      "    return imbalanceMsg   \n",
      "    \n",
      "def create_features(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.Move\n",
      "    Features['Move'] = '1:OpenCross>Ask(9.28); -1:OpenCross<Bid(9.28); 0:otherwise'\n",
      "    \n",
      "    fdf['Pnl'] = (imbalanceMsg.Move==-1)*(imbalanceMsg.OPC_P-imbalanceMsg.Ask_P)+\\\n",
      "                 (imbalanceMsg.Move==1)*(imbalanceMsg.Bid_P-imbalanceMsg.OPC_P)\n",
      "\n",
      "    fdf['Spread'] = (imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)/imbalanceMsg.PrevCLC_P\n",
      "    Features['Spread'] = '(Ask-Bid) at 9.28'\n",
      "\n",
      "    fdf['D1'] = 100*(imbalanceMsg.PrevCLC_P/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D1'] = 'Asset growth a day before'\n",
      "\n",
      "    fdf['D2'] = 100*(0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D2'] = 'Mid(9.28)/OPC(day before)-1'\n",
      "\n",
      "    fdf['D3'] = 100*(0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)/imbalanceMsg.PrevCLC_P-1)\n",
      "    Features['D3'] = 'Mid(9.28)/CloseCross(day before)-1'\n",
      "\n",
      "    \n",
      "    \n",
      "    fdf['D4'] = 100*(imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/imbalanceMsg.PrevCLC_P\n",
      "    Features['D4'] = '(Bid(9.28)-ImbRef(9.28))/CloseCross(day before)'\n",
      "\n",
      "    fdf['D5'] = 100*(imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/imbalanceMsg.PrevCLC_P\n",
      "    Features['D5'] = '(ImbRef(9.28)-Ask(9.28))/CloseCross(day before)'\n",
      "    \n",
      "    \n",
      "    fdf['D44'] = 100*(imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/imbalanceMsg.PrevOPC_P\n",
      "    Features['D44'] = '(Bid(9.28)-ImbRef(9.28))/OpenCross(day before)'\n",
      "\n",
      "    fdf['D55'] = 100*(imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/imbalanceMsg.PrevOPC_P\n",
      "    Features['D55'] = '(ImbRef(9.28)-Ask(9.28))/OpenCross(day before)'\n",
      "    \n",
      "    \n",
      "    fdf['D444'] = (imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/(1+imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['D444'] = '(Bid(9.28)-ImbRef(9.28))/1+Spread'\n",
      "\n",
      "    fdf['D555'] = (imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/(1+imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['D555'] = '(ImbRef(9.28)-Ask(9.28))/1+Spread'\n",
      "    \n",
      "\n",
      "    fdf['D6'] = 100*(imbalanceMsg.ImbRef/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D6'] = 'ImbRef(9.28)/OpenCross(day before)-1'\n",
      "\n",
      "    fdf['D7'] = 100*(imbalanceMsg.ImbRef/imbalanceMsg.PrevCLC_P-1)\n",
      "    Features['D7'] = 'ImbRef(9.28)/CloseCross(day before)-1'\n",
      "    \n",
      "    fdf['D66'] = 100*(2*imbalanceMsg.ImbRef/(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)-1)\n",
      "    Features['D66'] = 'ImbRef(9.28)/Mid-1'\n",
      "    \n",
      "    \n",
      "\n",
      "    fdf['V1'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/(100*numpy.sign(imbalanceMsg.ImbShares)+imbalanceMsg.ImbShares)\n",
      "    Features['V1'] = '(Ask_S-Bid_S) at 9.28/Imbalance(9.28)'\n",
      "    \n",
      "    fdf['V11'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V11'] = '(Ask_S-Bid_S) at 9.28/PairedS(9.28)'\n",
      "\n",
      "    fdf['V2'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/imbalanceMsg.PrevOPC_S\n",
      "    Features['V2'] = '(Ask_S-Bid_S) at 9.28/OpenCross(day before)'\n",
      "\n",
      "    fdf['V3'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/imbalanceMsg.PrevCLC_S\n",
      "    Features['V3'] = '(Ask_S-Bid_S) at 9.28/CloseCross(day before)'\n",
      "\n",
      "    fdf['V4'] = imbalanceMsg.ImbShares/imbalanceMsg.PrevOPC_S\n",
      "    Features['V4'] = 'ImbalanceS(9.28)/OpenCrossS(day before)'\n",
      "\n",
      "    fdf['V5'] = imbalanceMsg.ImbShares/imbalanceMsg.PrevCLC_S\n",
      "    Features['V5'] = 'ImbalanceS(9.28)/CloseCrossS(day before)'\n",
      "\n",
      "    fdf['V6'] = imbalanceMsg.ImbPaired/imbalanceMsg.PrevOPC_S\n",
      "    Features['V6'] = 'PairedS(9.28)/OpenCrossS(day before)'\n",
      "\n",
      "    fdf['V7'] = imbalanceMsg.ImbPaired/imbalanceMsg.PrevCLC_S\n",
      "    Features['V7'] = 'PairedS(9.28)/CloseCrossS(day before)'\n",
      "    \n",
      "    fdf['V8'] = imbalanceMsg.ImbShares/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V8'] = 'ImbalanceS(9.28)/PairedS(9.28)'\n",
      "    \n",
      "    fdf['V9'] = imbalanceMsg.PrevOPC_S/(100+imbalanceMsg.PrevCLC_S)\n",
      "    Features['V9'] = 'OpenCrossS(day before)/CloseCrossS(day before)'\n",
      "\n",
      "\n",
      "    fdf['a1'] = fdf['D1']*fdf['D2']\n",
      "    Features['a1'] = Features['D1'] + ' Multiply ' + Features['D2']\n",
      "    \n",
      "    fdf['a2'] = fdf['D2']*fdf['D3']\n",
      "    Features['a2'] = Features['D3'] + ' Multiply ' + Features['D2']\n",
      "    \n",
      "    fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "    fdf['a4'] = fdf['D5']*fdf['D4']\n",
      "    Features['a4'] = Features['D5'] + ' Multiply ' + Features['D4']\n",
      "    \n",
      "    fdf['a5'] = fdf['D5']*fdf['D6']\n",
      "    fdf['a6'] = fdf['D1']*fdf['D6']\n",
      "    Features['a6'] = Features['D1'] + ' Multiply ' + Features['D6']\n",
      "    \n",
      "    fdf['a7'] = fdf['V1']*fdf['V2']\n",
      "    Features['a7'] = Features['V1'] + ' Multiply ' + Features['V2']\n",
      "    \n",
      "    fdf['a8'] = fdf['V2']*fdf['V3']\n",
      "    fdf['a9'] = fdf['V3']*fdf['V4']\n",
      "    Features['a9'] = Features['V3'] + ' Multiply ' + Features['V4']\n",
      "    \n",
      "    fdf['a10'] = fdf['V5']*fdf['V4']\n",
      "    fdf['a11'] = fdf['V5']*fdf['V6']\n",
      "    Features['a11'] = Features['V5'] + ' Multiply ' + Features['V6']\n",
      "    \n",
      "    fdf['a12'] = fdf['V7']*fdf['V6']\n",
      "    fdf['a13'] = fdf['V7']*fdf['V1']\n",
      "    Features['a13'] = Features['V1'] + ' Multiply ' + Features['V7']\n",
      "    \n",
      "    fdf['a14'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    Features['a14'] = 'Sign of Imbalance'\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features\n",
      "\n",
      "def create_features2(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.OPC_P/imbalanceMsg.ImbRef-1   \n",
      "    Features['Move'] = 'OpenCross/RefPrice(9.28)-1'\n",
      "    \n",
      "    fdf['Pnl'] = imbalanceMsg.OPC_P-imbalanceMsg.ImbRef\n",
      "    Features['Pnl'] = 'OpenCross/RefPrice(9.28)'\n",
      "    \n",
      "    fdf['Bid'] = imbalanceMsg.Bid_P/imbalanceMsg.ImbRef-1\n",
      "    Features['Bid'] = 'Bid(9.28)'\n",
      "    \n",
      "    fdf['Ask'] = imbalanceMsg.Ask_P/imbalanceMsg.ImbRef-1\n",
      "    Features['Ask'] = 'Ask(9.28)'\n",
      "    \n",
      "    fdf['Ref'] = imbalanceMsg.ImbRef\n",
      "    Features['Ref'] = 'Ref(9.28)'\n",
      "    \n",
      "    fdf['Near'] = imbalanceMsg.ImbCBC/imbalanceMsg.ImbRef-1\n",
      "    Features['Near'] = 'Near(9.28)'\n",
      "    \n",
      "    fdf['Far'] = imbalanceMsg.ImbFar/imbalanceMsg.ImbRef-1\n",
      "    Features['Far'] = 'Far(9.28)'\n",
      "    \n",
      "    fdf['PrevOPC'] = imbalanceMsg.PrevOPC_P/imbalanceMsg.ImbRef-1\n",
      "    Features['PrevOPC'] = 'PrevOPC'\n",
      "    \n",
      "    fdf['PrevCLC'] = imbalanceMsg.PrevCLC_P/imbalanceMsg.ImbRef-1\n",
      "    Features['PrevCLC'] = 'PrevCLC'\n",
      "\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features\n",
      "\n",
      "def create_features3(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.Move\n",
      "    Features['Move'] = 'Move'\n",
      "       \n",
      "    fdf['Bid'] = imbalanceMsg.Bid_P/imbalanceMsg.ImbRef-1\n",
      "    Features['Bid'] = 'Bid(9.28)'\n",
      "    \n",
      "    fdf['Ask'] = imbalanceMsg.Ask_P/imbalanceMsg.ImbRef-1\n",
      "    Features['Ask'] = 'Ask(9.28)'\n",
      "       \n",
      "    fdf['Near'] = imbalanceMsg.ImbCBC/imbalanceMsg.ImbRef-1\n",
      "    Features['Near'] = 'Near(9.28)'\n",
      "    \n",
      "    fdf['Far'] = imbalanceMsg.ImbFar/imbalanceMsg.ImbRef-1\n",
      "    Features['Far'] = 'Far(9.28)'\n",
      "        \n",
      "    fdf['PrevCLC'] = imbalanceMsg.PrevCLC_P/imbalanceMsg.ImbRef-1\n",
      "    Features['PrevCLC'] = 'PrevCLC'\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_imbelanceMSG2(df,nImb):\n",
      "    startTime = '9:27:58'\n",
      "    endTime = '9:28:03'\n",
      "    if nImb==2:\n",
      "        startTime = '9:28:03'\n",
      "        endTime = '9:28:08'\n",
      "    elif nImb==3:\n",
      "        startTime = '9:28:08'\n",
      "        endTime = '9:28:12'\n",
      "    elif nImb==4:\n",
      "        startTime = '9:28:12'\n",
      "        endTime = '9:28:18'\n",
      "    elif nImb==5:\n",
      "        startTime = '9:28:18'\n",
      "        endTime = '9:28:22'\n",
      "    elif nImb==6:\n",
      "        startTime = '9:28:22'\n",
      "        endTime = '9:28:28'\n",
      "    elif nImb==7:\n",
      "        startTime = '9:28:28'\n",
      "        endTime = '9:28:32'\n",
      "    elif nImb==8:\n",
      "        startTime = '9:28:32'\n",
      "        endTime = '9:28:38'\n",
      "    elif nImb==9:\n",
      "        startTime = '9:28:38'\n",
      "        endTime = '9:28:42'\n",
      "    elif nImb==10:\n",
      "        startTime = '9:28:42'\n",
      "        endTime = '9:28:48'\n",
      "    elif nImb==11:\n",
      "        startTime = '9:28:48'\n",
      "        endTime = '9:28:52'\n",
      "    elif nImb==12:\n",
      "        startTime = '9:28:52'\n",
      "        endTime = '9:28:58'\n",
      "    elif nImb==13:\n",
      "        startTime = '9:28:58'\n",
      "        endTime = '9:29:02'\n",
      "    elif nImb==14:\n",
      "        startTime = '9:29:02'\n",
      "        endTime = '9:29:08'\n",
      "    elif nImb==15:\n",
      "        startTime = '9:29:08'\n",
      "        endTime = '9:29:12'\n",
      "    elif nImb==16:\n",
      "        startTime = '9:29:12'\n",
      "        endTime = '9:29:18'\n",
      "    elif nImb==17:\n",
      "        startTime = '9:29:18'\n",
      "        endTime = '9:29:22'\n",
      "    elif nImb==18:\n",
      "        startTime = '9:29:22'\n",
      "        endTime = '9:29:28'\n",
      "    elif nImb==19:\n",
      "        startTime = '9:29:28'\n",
      "        endTime = '9:29:32'\n",
      "    elif nImb==20:\n",
      "        startTime = '9:29:32'\n",
      "        endTime = '9:29:38'\n",
      "    elif nImb==21:\n",
      "        startTime = '9:29:38'\n",
      "        endTime = '9:29:42'\n",
      "    elif nImb==22:\n",
      "        startTime = '9:29:42'\n",
      "        endTime = '9:29:48'\n",
      "    elif nImb==23:\n",
      "        startTime = '9:29:48'\n",
      "        endTime = '9:29:52'\n",
      "    elif nImb==24:\n",
      "        startTime = '9:29:52'\n",
      "        endTime = '9:29:58'\n",
      "\n",
      "    \n",
      "    imbalanceMsg = df[df.Reason == 'Imbalance'].between_time(startTime,endTime)\n",
      "    imbalanceMsg = imbalanceMsg[\n",
      "    (imbalanceMsg.ImbRef>0) & \n",
      "    (imbalanceMsg.ImbCBC>0) &\n",
      "    (imbalanceMsg.ImbFar>0) &\n",
      "    (imbalanceMsg.ImbShares!=0)\n",
      "    ]\n",
      "\n",
      "    imbalanceMsg = imbalanceMsg[['Symbol','Bid_P','Bid_S','Ask_P','Ask_S','ImbRef','ImbCBC','ImbFar','ImbShares','ImbPaired']]\n",
      "    imbalanceMsg['Date'] = imbalanceMsg.index.date\n",
      "    imbalanceMsg['Timestamp'] = imbalanceMsg.index\n",
      "         \n",
      "    #Getting additional info about previous day\n",
      "    OPC = df[df.Reason == 'OPG']\n",
      "    OPC = OPC[['Symbol','tPrice']]\n",
      "    OPC.columns = ['Symbol','OPC_P']\n",
      "    OPC['Date'] = OPC.index.date\n",
      "    \n",
      "    prev_CLC = df[df.tSide == 'YDAY']\n",
      "    prev_CLC = prev_CLC[['Symbol','tPrice','tShares']]\n",
      "    prev_CLC.columns = ['Symbol','PrevCLC_P','PrevCLC_S']\n",
      "    prev_CLC['Date'] = prev_CLC.index.date\n",
      "    \n",
      "    #Adding OPC\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_CLC, on=['Symbol','Date'])\n",
      "\n",
      "    #Filtering data with no prev OPC\n",
      "    imbalanceMsg = imbalanceMsg[imbalanceMsg.OPC_P>0]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])    \n",
      "    \n",
      "    #Adding new feature which reflects price move direction\n",
      "    imbalanceMsg['Move'] = imbalanceMsg.Bid_P\n",
      "    imbalanceMsg.Move = 0\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P>imbalanceMsg.Ask_P] = 1\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P<imbalanceMsg.Bid_P] = -1\n",
      "    \n",
      "    return imbalanceMsg   \n",
      "    \n",
      "    return imbalanceMsg   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Precision_Recall(cm):\n",
      "    m = cm.shape[0]\n",
      "    sums1 = cm.sum(axis=1);\n",
      "    sums2 = cm.sum(axis=0);\n",
      "    precision = 0\n",
      "    s1 = 0\n",
      "    s2 = 0\n",
      "    for i in range(1,m):\n",
      "        precision +=  cm[i,i]\n",
      "        s1 += sums1[i]\n",
      "        s2 += sums2[i]\n",
      "\n",
      "    return precision/s2, precision/s1, 2*(precision/s1 * precision/s2)/(precision/s2 + precision/s1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dates_tmp_df(fdf):\n",
      "    import numpy\n",
      "    \n",
      "    datesDF = pd.DataFrame()\n",
      "    datesDF['Date'] = fdf.Date\n",
      "    datesDF['newIndex'] = numpy.zeros((datesDF.shape[0],1))\n",
      "    datesDF.index = range(datesDF.shape[0])\n",
      "\n",
      "    dates = sorted(list(set(fdf.Date)))\n",
      "    for i in range(datesDF.shape[0]):\n",
      "        for j in range(len(dates)):\n",
      "            if (datesDF.Date[i]==dates[j]):            \n",
      "                datesDF.newIndex[i] = j\n",
      "            \n",
      "    datesDF.index = datesDF.newIndex \n",
      "    datesDF.newIndex = range(datesDF.shape[0])\n",
      "    datesDF = datesDF['newIndex']\n",
      "    \n",
      "    return datesDF\n",
      "\n",
      "def run_cv2(X,y,clf_class,n_folds,test_size,dates,datesDF,**kwargs):\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn import preprocessing\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    \n",
      "    labels = list(set(y))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        if clf_class!='B':\n",
      "            if not kwargs.has_key('n_ensembles'):\n",
      "                n_ensembles = 1\n",
      "                test_size_ensemble = 0\n",
      "            else:\n",
      "                n_ensembles = kwargs['n_ensembles']\n",
      "                test_size_ensemble = kwargs['test_size_ensemble']\n",
      "                \n",
      "            ypred = ytest.copy(); ypred[:] = 0\n",
      "            ypredTrain = ytrain.copy(); ypredTrain[:] = 0\n",
      "            for j in range(n_ensembles):  \n",
      "                Xtrain_sub, Xtest_sub, ytrain_sub, ytest_sub = train_test_split(Xtrain, ytrain, test_size=test_size_ensemble)\n",
      "\n",
      "                #scaler = preprocessing.StandardScaler().fit(Xtrain_sub)\n",
      "                if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "                    clf = clf_class(class_weight='auto')\n",
      "                else:\n",
      "                    clf = clf_class(min_samples_split = 20)\n",
      "                    \n",
      "                clf.fit(Xtrain_sub,ytrain_sub)\n",
      "                #print clf.coef_\n",
      "                #print '-------------------'\n",
      "\n",
      "\n",
      "                ypred += clf.predict(Xtest).astype(float)/n_ensembles\n",
      "                ypredTrain += clf.predict(Xtrain).astype(float)/n_ensembles\n",
      "\n",
      "            #Averaging of assemblies results\n",
      "            ypred[ypred>0.5] = 1\n",
      "            ypred[ypred<-0.5] = -1\n",
      "            ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "\n",
      "            ypredTrain[ypredTrain>0.5] = 1\n",
      "            ypredTrain[ypredTrain<-0.5] = -1\n",
      "            ypredTrain[(ypredTrain!=1) & (ypredTrain!=-1)] = 0\n",
      "        else:\n",
      "            ypred = ytest.copy(); ypred[:] = 0\n",
      "            ypredTrain = ytrain.copy(); ypredTrain[:] = 0\n",
      "            ypred[(Xtest.a14>0) & (Xtest.D5>=0)] = 1\n",
      "            ypred[(Xtest.a14<0) & (Xtest.D4>=0)] = -1\n",
      "            ypredTrain[(Xtrain.a14>0) & (Xtrain.D5>=0)] = 1\n",
      "            ypredTrain[(Xtrain.a14<0) & (Xtrain.D4>=0)] = -1\n",
      "        \n",
      "\n",
      "        test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "        train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        #testError += np.mean(ypred != ytest)/n_folds\n",
      "        #trainError += np.mean(ypredTrain != ytrain)/n_folds\n",
      "        \n",
      "    test_pr = Precision_Recall(test_cm)\n",
      "    train_pr = Precision_Recall(train_cm)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n",
      "def OneModelResults(clf_class, input,target,ERRORS,dates,datesDF,**kwargs):\n",
      "    fig1 = plt.figure(figsize=(15, 5))\n",
      "    plt.clf()\n",
      "    ax1 = fig1.add_subplot(1,3,1)\n",
      "    trainError, testError, cm = run_cv2(input,target,clf_class,10,1,dates,datesDF,**kwargs)\n",
      "    draw_confusion_matrix(cm, [0,1,-1], fig1, ax1)\n",
      "    ERRORS.loc[ERRORS.shape[0]] =[str(clf_class).split('.')[-1].strip('>'),trainError,testError]\n",
      "    pr = Precision_Recall(cm)\n",
      "    print 'Precision - %s, Recall - %s, F_Score - %s' % (pr[0],pr[1],pr[2])\n",
      "\n",
      "    \n",
      "    #Show learning curves\n",
      "    TrainError=[]\n",
      "    TestError=[]\n",
      "    nDays = len(dates)\n",
      "    testRange = range(nDays-1)\n",
      "    for i in testRange: \n",
      "        trainError, testError, cm = run_cv2(input,target,clf_class,10,i+1,dates,datesDF,**kwargs)\n",
      "        #print i,testError\n",
      "        TrainError.append(trainError)\n",
      "        TestError.append(testError)\n",
      "\n",
      "    LearningCurves = pd.DataFrame()\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index']+= 1\n",
      "    LearningCurves['TrainError'] = TrainError\n",
      "    LearningCurves['TestError'] = TestError\n",
      "    LearningCurves['Index'] = nDays-LearningCurves['Index']\n",
      "    LearningCurves = pd.melt(LearningCurves, id_vars = 'Index', value_vars = ['TestError','TrainError'])\n",
      "\n",
      "    g = ggplot(LearningCurves, aes('Index', 'value', color = 'variable')) + geom_step() + \\\n",
      "    ggtitle('Learning curves') + xlab(\"% of data sent to train\") + ylab(\"Error\")\n",
      "    \n",
      "    return g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_cvNN(X,y,n_folds,test_size,**kwargs):\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn import preprocessing\n",
      "    import neurolab as nl\n",
      "    \n",
      "    lb = preprocessing.LabelBinarizer()\n",
      "    lb.fit(y)\n",
      "    \n",
      "    labels = list(set(y))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
      "        \n",
      "        input = scaler.transform(Xtrain)  \n",
      "        \n",
      "        net = nl.net.newff(nl.tool.minmax(input), **kwargs)\n",
      "        error = net.train(input, lb.transform(ytrain),show=500)\n",
      "        \n",
      "        ypred = lb.inverse_transform(net.sim(scaler.transform(Xtest)))\n",
      "        ypredTrain = lb.inverse_transform(net.sim(input))\n",
      "        \n",
      "        ypred = clf.predict(Xtest)\n",
      "        ypredTrain = clf.predict(Xtrain)\n",
      "\n",
      "        test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "        train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        \n",
      "    test_pr = Precision_Recall(test_cm)\n",
      "    train_pr = Precision_Recall(train_cm)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n",
      "\n",
      "def run_cvNN2(X,y,n_folds,threshold,test_size,**kwargs):\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn import preprocessing\n",
      "    import neurolab as nl\n",
      "    \n",
      "    lb = preprocessing.LabelBinarizer()\n",
      "    lb.fit(y)\n",
      "    \n",
      "    labels = list(set(y))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
      "        \n",
      "        input = scaler.transform(Xtrain)  \n",
      "        \n",
      "        net = nl.net.newff(nl.tool.minmax(input), **kwargs)\n",
      "        error = net.train(input, ytrain.reshape(len(ytrain),1),show=500)\n",
      "        \n",
      "        ypred = net.sim(scaler.transform(Xtest)).flatten()\n",
      "        ypred[ypred>threshold] = 1\n",
      "        ypred[ypred<-threshold] = -1\n",
      "        ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "        \n",
      "        ypredTrain = net.sim(input).flatten()\n",
      "        ypredTrain[ypredTrain>threshold] = 1\n",
      "        ypredTrain[ypredTrain<-threshold] = -1\n",
      "        ypredTrain[(ypredTrain!=1) & (ypredTrain!=-1)] = 0\n",
      "        \n",
      "        test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "        train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        \n",
      "    test_pr = Precision_Recall(test_cm)\n",
      "    train_pr = Precision_Recall(train_cm)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_confusion_matrix(conf_arr, labels, fig, ax):  \n",
      "    #print conf_arr\n",
      "    conf_arr=conf_arr.astype(float)\n",
      "    \n",
      "    sums = conf_arr.sum(axis=0)\n",
      "    #print sums\n",
      "    for i in range(len(labels)):\n",
      "        conf_arr[:,i] /= sums[i]\n",
      "    #print conf_arr\n",
      "    #fig = plt.figure()\n",
      "    #plt.clf()\n",
      "    #ax = fig.add_subplot(111)\n",
      "    #ax.set_aspect(1)\n",
      "    res = ax.imshow(np.array(conf_arr), cmap=plt.cm.jet, interpolation='nearest')\n",
      "\n",
      "    width = len(conf_arr)\n",
      "    height = len(conf_arr[0])\n",
      "\n",
      "    for x in xrange(width):\n",
      "        for y in xrange(height):\n",
      "            ax.annotate(str(conf_arr[x][y])[:4], xy=(y, x), \n",
      "                        horizontalalignment='center',\n",
      "                        verticalalignment='center')\n",
      "\n",
      "    #cb = fig.colorbar(res)\n",
      "    plt.xticks(range(width), labels[:width])\n",
      "    plt.yticks(range(height), labels[:height])\n",
      "    #plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ComplexCLF(X,y,clf_class1,clf_class2,n_folds,test_size,dates,datesDF):\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    \n",
      "    labels = list(set(y))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        #Split train - test\n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        #**************************************\n",
      "        \n",
      "        #Train first classifier\n",
      "        newX=pd.DataFrame()\n",
      "        clf1_pool =[]\n",
      "        for l in labels:\n",
      "            clf1 = clf_class1()\n",
      "            clf1.fit(Xtrain,ytrain==l)\n",
      "            newX[l] = clf1.predict(Xtrain)        \n",
      "            clf1_pool.append(clf1)\n",
      "        #**************************************\n",
      "        \n",
      "        #Train second classifier\n",
      "        clf2 = clf_class2()\n",
      "        clf2.fit(newX,ytrain)\n",
      "        #**************************************\n",
      "        \n",
      "        ypredTrain = clf2.predict(newX)\n",
      "        train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "           \n",
      "        #Get prediction  \n",
      "        newX=pd.DataFrame()\n",
      "        for i in range(len(labels)):\n",
      "            newX[labels[i]] = clf1_pool[i].predict(Xtest)\n",
      "        ypred = clf2.predict(newX)\n",
      "        #**************************************\n",
      "        \n",
      "        test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds        \n",
      "            \n",
      "    test_pr = Precision_Recall(test_cm)\n",
      "    train_pr = Precision_Recall(train_cm)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n",
      "def TwoModelsResults(clf_class1,clf_class2, input,target,ERRORS,dates,datesDF):\n",
      "    fig1 = plt.figure(figsize=(15, 5))\n",
      "    plt.clf()\n",
      "    ax1 = fig1.add_subplot(1,3,1)\n",
      "    trainError, testError, cm = ComplexCLF(input,target,clf_class1,clf_class2,20,1,dates,datesDF)\n",
      "    draw_confusion_matrix(cm, [0,1,-1], fig1, ax1)\n",
      "    ERRORS.loc[ERRORS.shape[0]] =\\\n",
      "    [str(clf_class1).split('.')[-1].strip('>') + ' + ' + str(clf_class2).split('.')[-1].strip('>'),\\\n",
      "     trainError,testError]\n",
      "    pr = Precision_Recall(cm)\n",
      "    print 'Precision - %s, Recall - %s, F_Score - %s' % (pr[0],pr[1],pr[2])\n",
      "\n",
      "    \n",
      "    #Show learning curves\n",
      "    TrainError=[]\n",
      "    TestError=[]\n",
      "    nDays = len(dates)\n",
      "    testRange = range(nDays-1)\n",
      "    for i in testRange: \n",
      "        trainError, testError, cm = ComplexCLF(input,target,clf_class1,clf_class2,20,i,dates,datesDF)\n",
      "        TrainError.append(trainError)\n",
      "        TestError.append(testError)\n",
      "\n",
      "    LearningCurves = pd.DataFrame()\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index']+= 1\n",
      "    LearningCurves['TrainError'] = TrainError\n",
      "    LearningCurves['TestError'] = TestError\n",
      "    LearningCurves['Index'] = nDays-LearningCurves['Index']\n",
      "    LearningCurves = pd.melt(LearningCurves, id_vars = 'Index', value_vars = ['TestError','TrainError'])\n",
      "\n",
      "\n",
      "    g = ggplot(LearningCurves, aes('Index', 'value', color = 'variable')) + geom_step() + \\\n",
      "    ggtitle('Learning curves') + xlab(\"% of data sent to train\") + ylab(\"Error\")\n",
      "    \n",
      "    return g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_signals2(imbalanceMsg,X,y,clf_class1,clf_class2,dates,datesDF):  \n",
      "    import numpy\n",
      "    labels = list(set(y))\n",
      "    \n",
      "    Signals = imbalanceMsg[['Timestamp','Symbol','Ask_P','Bid_P']]\n",
      "    Signals['Side'] = numpy.zeros((Signals.shape[0],1))\n",
      "    Signals['Price'] = Signals.Ask_P   \n",
      "    \n",
      "    for i in range(int(datesDF.index.max())+1):  \n",
      "        train_days = range(len(dates))\n",
      "        test_days = i \n",
      "        train_days.remove(i)\n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        clf1_pool =[]\n",
      "        newX=pd.DataFrame()\n",
      "        for l in labels:\n",
      "            clf1 = clf_class1()\n",
      "            clf1.fit(Xtrain,ytrain==l)\n",
      "            newX[l] = clf1.predict(Xtrain)        \n",
      "            clf1_pool.append(clf1)\n",
      "        \n",
      "        clf2 = clf_class2()\n",
      "        clf2.fit(newX,ytrain)\n",
      "               \n",
      "        newX=pd.DataFrame()\n",
      "        for i in range(len(labels)):\n",
      "            newX[labels[i]] = clf1_pool[i].predict(Xtest)\n",
      "\n",
      "        Signals.Side[datesDF.ix[test_days]] = clf2.predict(newX)\n",
      "        \n",
      "    Signals.Price[Signals['Side']==1] = Signals.Ask_P[Signals['Side']==1]\n",
      "    Signals.Price[Signals['Side']==-1] = Signals.Bid_P[Signals['Side']==-1]\n",
      "    Signals = Signals[Signals.Side!=0]\n",
      "    Signals = Signals[['Timestamp','Symbol','Price','Side']] \n",
      "    Signals.index = Signals.Timestamp\n",
      "    return Signals\n",
      "\n",
      "def get_signals1(imbalanceMsg,X,y,clf_class,dates,datesDF,**kwargs):  \n",
      "    import numpy\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    labels = list(set(y))\n",
      "    \n",
      "    Signals = imbalanceMsg[['Timestamp','Symbol','Ask_P','Bid_P']]\n",
      "    Signals['Side'] = numpy.zeros((Signals.shape[0],1))\n",
      "    Signals['Price'] = Signals.Ask_P   \n",
      "    \n",
      "    for i in range(int(datesDF.index.max())+1):  \n",
      "        train_days = range(len(dates))\n",
      "        test_days = i \n",
      "        train_days.remove(i)\n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        if clf_class!='B':            \n",
      "            if not kwargs.has_key('n_ensembles'):\n",
      "                \n",
      "                if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "                    clf = clf_class(class_weight='auto')\n",
      "                else:\n",
      "                    clf = clf_class()\n",
      "                \n",
      "                clf.fit(Xtrain,ytrain)\n",
      "\n",
      "                Signals.Side[datesDF.ix[test_days]] = clf.predict(Xtest)\n",
      "            else:\n",
      "                n_ensembles = kwargs['n_ensembles']\n",
      "                test_size_ensemble = kwargs['test_size_ensemble']\n",
      "                \n",
      "                ypred = ytest.copy(); ypred[:] = 0\n",
      "                for j in range(n_ensembles):  \n",
      "                    Xtrain_sub, Xtest_sub, ytrain_sub, ytest_sub = train_test_split(Xtrain, ytrain, test_size=test_size_ensemble)\n",
      "\n",
      "                    if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "                        clf = clf_class(class_weight='auto')\n",
      "                    else:\n",
      "                        clf = clf_class()\n",
      "                        \n",
      "                    clf.fit(Xtrain_sub,ytrain_sub)\n",
      "                    \n",
      "                    ypred += clf.predict(Xtest).astype(float)/n_ensembles\n",
      "\n",
      "\n",
      "                #Averaging of assemblies results\n",
      "                ypred[ypred>0.5] = 1\n",
      "                ypred[ypred<-0.5] = -1\n",
      "                ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "\n",
      "                Signals.Side[datesDF.ix[test_days]] = ypred\n",
      "        else:\n",
      "            ypred = ytest.copy(); ypred[:] = 0\n",
      "            #ypred[(Xtest.a14>0)] = 1\n",
      "            #ypred[(Xtest.a14<0)] = -1\n",
      "            ypred[(Xtest.a14>0) & (Xtest.D5>=0)] = 1\n",
      "            ypred[(Xtest.a14<0) & (Xtest.D4>=0)] = -1\n",
      "            Signals.Side[datesDF.ix[test_days]] = ypred\n",
      "        \n",
      "        \n",
      "        \n",
      "    Signals.Price[Signals['Side']==1] = Signals.Ask_P[Signals['Side']==1]\n",
      "    Signals.Price[Signals['Side']==-1] = Signals.Bid_P[Signals['Side']==-1]\n",
      "    Signals = Signals[Signals.Side!=0]\n",
      "    Signals = Signals[['Timestamp','Symbol','Price','Side']] \n",
      "    Signals.index = Signals.Timestamp\n",
      "    return Signals\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_performance(Signals,df,days,SymbolsInd,T,TN,add=0):\n",
      "    days = sorted(list(set(Signals.index.date)))\n",
      "    \n",
      "    PNL=[]\n",
      "    SDict=dict()\n",
      "    for day in days:\n",
      "        dayPnl=[]\n",
      "        #print '----------------------------------'\n",
      "        #print day\n",
      "        #print '----------------------------------'\n",
      "        curr_day_signals = Signals[day.strftime(\"%Y-%m-%d\")]\n",
      "        data = df[day.strftime(\"%Y-%m-%d\")]\n",
      "        buys = curr_day_signals[curr_day_signals.Side==1]\n",
      "        buys = buys.sort(['Symbol'])\n",
      "        sells = curr_day_signals[curr_day_signals.Side==-1]\n",
      "        sells = sells.sort(['Symbol'])\n",
      "        \n",
      "        endTimestamp = pd.Timestamp('09:30:01')\n",
      "        \n",
      "        #print 'BUY'\n",
      "        for count, row in buys.iterrows():\n",
      "            startTimestamp = row[0]\n",
      "            \n",
      "            symbol = row[1]\n",
      "            price = row[2]+add\n",
      "\n",
      "            curr_symbol_data=data[data.Symbol==symbol].between_time(startTimestamp,endTimestamp)\n",
      "            \n",
      "            #AskPrices = dict()\n",
      "            #for i in range(curr_symbol_data.shape[0]):\n",
      "            #    if curr_symbol_data.Ask_P[i]>price: continue\n",
      "            #    if (not AskPrices.has_key(curr_symbol_data.Ask_P[i])):\n",
      "            #        AskPrices[curr_symbol_data.Ask_P[i]] = curr_symbol_data.Ask_S[i]\n",
      "                    \n",
      "            volumeTraded = 1#min(abs(curr_symbol_data.ImbShares[0]),curr_symbol_data.Ask_S[0])\n",
      "                           \n",
      "            OPC = curr_symbol_data.tPrice[(curr_symbol_data.Reason=='OPG')]\n",
      "            #print OPC\n",
      "            #continue\n",
      "            pnl = volumeTraded*(OPC[0]-price)\n",
      "            \n",
      "            if SDict.has_key(symbol):\n",
      "                SDict[symbol]+=pnl\n",
      "            else:\n",
      "                SDict[symbol]=pnl\n",
      "            \n",
      "            dayPnl.append(pnl)\n",
      "            #if pnl<0:\n",
      "            #    print ' BUY   %s %s shares at %s SELL at %s PNL %s' % ( symbol,volumeTraded,price,OPC[0],pnl)\n",
      "            \n",
      "            for s in buys.Symbol:\n",
      "                T[SymbolsInd[symbol],SymbolsInd[s]]+=1.0\n",
      "            for s in sells.Symbol:\n",
      "                T[SymbolsInd[symbol],SymbolsInd[s]]-=1.0\n",
      "            \n",
      "        #print 'SELL'    \n",
      "        for count, row in sells.iterrows():\n",
      "            startTimestamp = row[0]\n",
      "\n",
      "            symbol = row[1]\n",
      "            price = row[2]-add\n",
      "\n",
      "            curr_symbol_data=data[data.Symbol==symbol].between_time(startTimestamp,endTimestamp)\n",
      "            \n",
      "            #BidPrices = dict()\n",
      "            #for i in range(curr_symbol_data.shape[0]):\n",
      "            #    if curr_symbol_data.Bid_P[i]<price: continue\n",
      "            #    if (not BidPrices.has_key(curr_symbol_data.Bid_P[i])):\n",
      "            #        BidPrices[curr_symbol_data.Bid_P[i]] = curr_symbol_data.Bid_S[i]\n",
      "            \n",
      "            volumeTraded = 1#min(abs(curr_symbol_data.ImbShares[0]),curr_symbol_data.Bid_S[0])\n",
      "            \n",
      "            OPC = curr_symbol_data.tPrice[curr_symbol_data.Reason=='OPG']\n",
      "            #print OPC\n",
      "            #continue\n",
      "            pnl = volumeTraded*(price-OPC[0])\n",
      "            \n",
      "            if SDict.has_key(symbol):\n",
      "                SDict[symbol]+=pnl\n",
      "            else:\n",
      "                SDict[symbol]=pnl\n",
      "                \n",
      "            dayPnl.append(pnl)\n",
      "            #if pnl<0:\n",
      "            #    print ' SELL  %s %s shares at %s BUY as %s PNL %s' % ( symbol,volumeTraded,price,OPC[0],pnl) \n",
      "            \n",
      "            for s in sells.Symbol:\n",
      "                T[SymbolsInd[symbol],SymbolsInd[s]]+=1.0\n",
      "            for s in buys.Symbol:\n",
      "                T[SymbolsInd[symbol],SymbolsInd[s]]-=1.0\n",
      "                \n",
      "        PNL.append(np.sum(dayPnl))\n",
      "        print '%s %s' % (day,np.sum(dayPnl))\n",
      "        \n",
      "    for i in range(T.shape[0]):\n",
      "        for j in range(T.shape[0]):\n",
      "            TN[i,j]=2.0*T[i,j]/(T[i,i]+T[j,j])\n",
      "      \n",
      "    result = pd.DataFrame()\n",
      "    result['Date'] = days\n",
      "    result['Pnl'] = PNL\n",
      "    print '----------------------------------'\n",
      "    keys = sorted(SDict, key=SDict.__getitem__)\n",
      "    for key in keys[-10:]:\n",
      "        print '%s %s' % (key, SDict[key])\n",
      "    print '----------------------------------'\n",
      "    print np.sum(PNL)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Tree2Txt(t,fileName):\n",
      "    f = open(fileName, 'w+')\n",
      "    f.write(str(t.n_classes[0])+'\\n');\n",
      "    f.write(str(t.n_features)+'\\n');\n",
      "    f.write(str(t.capacity)+'\\n');\n",
      "    for i in range(t.capacity):\n",
      "        s= '%d;%f;' % (t.feature[i],t.threshold[i])\n",
      "        for j in range(t.n_classes[0]):\n",
      "            Sum = sum(t.value[i][0])\n",
      "            if Sum>0:\n",
      "                s +='%s;' %  str(t.value[i][0][j]/Sum)\n",
      "            else:\n",
      "                 s +='%s;' % '0'\n",
      "        f.write(s+'\\n')\n",
      "    f.close()\n",
      "\n",
      "def TreeTest2Txt(clf,X,fileName):\n",
      "    f = open(fileName, 'w+')\n",
      "    proba = clf.predict_proba(X)\n",
      "    for i in range(X.shape[0]):\n",
      "        s= ''\n",
      "        for j in range(X.shape[1]):\n",
      "            s +='%s;' %  str(X.ix[i,j])\n",
      "        for j in range(proba.shape[1]):\n",
      "            s +='%s;' %  str(proba[i,j])\n",
      "        f.write(s+'\\n')\n",
      "    f.close()\n",
      "    \n",
      "def Forest2Txt(clf,X,Dir):\n",
      "    for i in range(clf.n_estimators):\n",
      "        Tree2Txt(clf.estimators_[i].tree_,Dir + '/%u.t' % i)\n",
      "    TreeTest2Txt(clf,X,Dir + '/test.u')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def visualize_tree(clf):\n",
      "    t=clf.estimators_[0].tree_\n",
      "    from sklearn.externals.six import StringIO  \n",
      "    import pydot\n",
      "    from sklearn import tree\n",
      "    out = StringIO() \n",
      "    tree.export_graphviz(t, out_file=out) \n",
      "    #print out.getvalue()\n",
      "    graph = pydot.graph_from_dot_data(out.getvalue()) \n",
      "    graph.write_pdf(\"t.pdf\") "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}