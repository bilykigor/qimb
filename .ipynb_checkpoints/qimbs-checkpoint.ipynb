{
 "metadata": {
  "name": "",
  "signature": "sha256:3e46a1e62a5a9aae528bc6a9bc0db6205ee1a5c1f276f31492205f1f06c439a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import datetime\n",
      "from ggplot import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def import_month(month):\n",
      "    import os.path\n",
      "    df=pd.DataFrame()\n",
      "    \n",
      "    if month<10:\n",
      "        m = '0%s' % month\n",
      "    else:\n",
      "        m = '%s' % month\n",
      "    \n",
      "    #Read data for the month\n",
      "    for i in range (1,32):  \n",
      "        if i<10:\n",
      "            d = '0%s' % i\n",
      "        else:\n",
      "            d = '%s' % i\n",
      "        \n",
      "        f = '/home/user1/PyProjects/data_old/2014-%s-%s/CommonAggr_2014-%s-%s.csv' % (m,d,m,d)\n",
      "        \n",
      "        if (not os.path.isfile(f)): continue\n",
      "            \n",
      "        if (df.shape[0]==0):\n",
      "            df = pd.read_csv(f, low_memory=False)\n",
      "        else:\n",
      "            df=df.append(pd.read_csv(f, low_memory=False))\n",
      "    \n",
      "    #Set target columns\n",
      "    target_cols = ['Date','Time','Fracs','Symbol','Reason','tSide','tPrice','tShares',\n",
      "                    'Bid_P', 'Bid_S', 'Ask_P', 'Ask_S', \n",
      "                    'ImbRef','ImbCBC', 'ImbFar', 'ImbShares', 'ImbPaired']\n",
      "\n",
      "    #Get target columts from the data\n",
      "    df = df[target_cols]\n",
      "    df.index = range(df.shape[0])\n",
      "    \n",
      "    return df\n",
      "\n",
      "def import_month2(month):\n",
      "    import os.path\n",
      "    df=pd.DataFrame()\n",
      "    \n",
      "    if month<10:\n",
      "        m = '0%s' % month\n",
      "    else:\n",
      "        m = '%s' % month\n",
      "    \n",
      "    #Read data for the month\n",
      "    for i in range (1,32):  \n",
      "        if i<10:\n",
      "            d = '0%s' % i\n",
      "        else:\n",
      "            d = '%s' % i\n",
      "        \n",
      "        f = '/home/user1/PyProjects/data/AggrCommon_2014-%s-%s.csv' % (m,d)\n",
      "        \n",
      "        if (not os.path.isfile(f)): continue\n",
      "            \n",
      "        if (df.shape[0]==0):\n",
      "            df = pd.read_csv(f, low_memory=False)\n",
      "        else:\n",
      "            df=df.append(pd.read_csv(f, low_memory=False))\n",
      "    \n",
      "    #Set target columns\n",
      "    target_cols = ['Date','Time','Fracs','Symbol','Reason','tType','tVenue','tSide','tPrice','tShares',\n",
      "                    'Bid_P', 'Bid_S', 'Ask_P', 'Ask_S', 'nsdq_BP', 'nsdq_BS', 'nsdq_AP', 'nsdq_AS',\n",
      "                    'ImbRef','ImbCBC', 'ImbFar', 'ImbShares', 'ImbPaired', 'Bid2', 'Ask2']\n",
      "\n",
      "    #Get target columts from the data\n",
      "    df = df[target_cols]\n",
      "    df.index = range(df.shape[0])\n",
      "    \n",
      "    return df\n",
      "\n",
      "def import_file(f):\n",
      "    df = pd.read_csv('/home/user1/PyProjects/data/' + f, low_memory=False)\n",
      "    target_cols = ['Date','Time','Fracs','Symbol','Reason','tSide','tPrice','tShares',\n",
      "                    'Bid_P', 'Bid_S', 'Ask_P', 'Ask_S', \n",
      "                    'ImbRef','ImbCBC', 'ImbFar', 'ImbShares', 'ImbPaired']\n",
      "\n",
      "    df = df[target_cols]\n",
      "    df.index = range(df.shape[0])\n",
      "    \n",
      "    return df\n",
      "  \n",
      "def create_timestamp(df):\n",
      "    Timestamp = []\n",
      "    for i in range(df.shape[0]):\n",
      "        Timestamp.append(datetime.datetime.strptime(df.Date[i] +' '+df.Time[i]+' '+df.Fracs[i][0:3]+df.Fracs[i][4:7],'%Y-%m-%d %H:%M:%S %f'))\n",
      "\n",
      "    df['Timestamp'] = Timestamp\n",
      "    df = df.set_index(['Timestamp'])\n",
      "    df = df.drop(['Date','Time','Fracs'],1)\n",
      "    \n",
      "    return df\n",
      "\n",
      "def sigmoid(x):\n",
      "    import numpy\n",
      "    return 1/(1+numpy.exp(-x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Visualization of features\n",
      "from sklearn import preprocessing\n",
      "def visualize(fdf,Features,f,binwidth,scaled):\n",
      "    fdf_new = fdf.copy()\n",
      "    if scaled:\n",
      "        fdf_new[f] = preprocessing.scale(fdf_new[f])\n",
      "    g=ggplot(fdf_new[fdf_new.Move<0],aes(x=f)) + \\\n",
      "    geom_histogram(color='red',binwidth = binwidth,alpha=0.25,\\\n",
      "                   fill = 'red') + \\\n",
      "    geom_histogram(fdf_new[fdf_new.Move>0],aes(x=f), \\\n",
      "                   color='green',fill = 'green',\\\n",
      "                   binwidth = binwidth,alpha=0.25) + \\\n",
      "    ggtitle(Features[f]) \n",
      "    #xlim(-1,1)+ ylim(-20,20)\n",
      "    return g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/scipy/stats/distributions.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
        "  import vonmises_cython\n",
        "/usr/lib/python2.7/dist-packages/scipy/stats/distributions.py:30: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  import vonmises_cython\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_imbelanceMSG(df,nImb):\n",
      "    (startTime, endTime) = getImbTime(nImb)\n",
      "    \n",
      "    imbalanceMsg = df[df.Reason == 'Imbalance'].between_time(startTime,endTime)\n",
      "    #.between_time('9:29:52','9:29:57')\n",
      "    imbalanceMsg = imbalanceMsg[\n",
      "    (imbalanceMsg.Bid_P>0.01) & \n",
      "    (imbalanceMsg.Ask_P<199999.99) & \n",
      "    (imbalanceMsg.ImbRef>0) & \n",
      "    (imbalanceMsg.ImbCBC>0) &\n",
      "    (imbalanceMsg.ImbFar>0) &\n",
      "    (imbalanceMsg.ImbShares!=0)\n",
      "    ]\n",
      "\n",
      "    imbalanceMsg = imbalanceMsg[['Symbol','Bid_P','Bid_S','Ask_P','Ask_S','ImbRef','ImbCBC','ImbFar','ImbShares','ImbPaired']]\n",
      "    imbalanceMsg['Date'] = imbalanceMsg.index.date\n",
      "    imbalanceMsg['Timestamp'] = imbalanceMsg.index\n",
      "        \n",
      "    #Getting additional info about previous day\n",
      "    OPC = df[df.Reason == 'OPG']\n",
      "    OPC = OPC[['Symbol','tPrice']]\n",
      "    OPC.columns = ['Symbol','OPC_P']\n",
      "    OPC['Date'] = OPC.index.date\n",
      "\n",
      "    prev_OPC = df[df.Reason == 'OPG']\n",
      "    prev_OPC = prev_OPC[['Symbol','tPrice','tShares']]\n",
      "    prev_OPC.columns = ['Symbol','PrevOPC_P','PrevOPC_S']\n",
      "    prev_OPC['Date'] = prev_OPC.index.date\n",
      "    for i in range(prev_OPC.shape[0]):\n",
      "        if prev_OPC.Date[i].weekday()==4:\n",
      "            prev_OPC.Date[i]+=datetime.timedelta(days=3)\n",
      "        else:\n",
      "            prev_OPC.Date[i]+=datetime.timedelta(days=1)\n",
      "\n",
      "    prev_CLC = df[df.tSide == 'YDAY']\n",
      "    prev_CLC = prev_CLC[['Symbol','tPrice','tShares']]\n",
      "    prev_CLC.columns = ['Symbol','PrevCLC_P','PrevCLC_S']\n",
      "    prev_CLC['Date'] = prev_CLC.index.date\n",
      "\n",
      "    #Adding prev day info to imbalance information\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_CLC, on=['Symbol','Date'])\n",
      "\n",
      "    #Filtering data with no prev OPC or prev CLC\n",
      "    imbalanceMsg = imbalanceMsg[(imbalanceMsg.OPC_P>0) & (imbalanceMsg.PrevOPC_P>0)]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])\n",
      "    \n",
      "    #Adding new feature which reflects price move direction\n",
      "    imbalanceMsg['Move'] = imbalanceMsg.Bid_P\n",
      "    imbalanceMsg.Move = 0\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P>imbalanceMsg.Ask_P] = 1\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P<imbalanceMsg.Bid_P] = -1\n",
      "    \n",
      "    return imbalanceMsg   \n",
      "    \n",
      "def create_features(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.Move\n",
      "    Features['Move'] = '1:OpenCross>Ask(9.28); -1:OpenCross<Bid(9.28); 0:otherwise'\n",
      "    \n",
      "    fdf['Pnl'] = (imbalanceMsg.Move==-1)*(imbalanceMsg.OPC_P-imbalanceMsg.Ask_P)+\\\n",
      "                 (imbalanceMsg.Move==1)*(imbalanceMsg.Bid_P-imbalanceMsg.OPC_P)\n",
      "\n",
      "    fdf['Spread'] = (imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)/imbalanceMsg.PrevCLC_P\n",
      "    Features['Spread'] = '(Ask-Bid) at 9.28'\n",
      "\n",
      "    fdf['D1'] = 100*(imbalanceMsg.PrevCLC_P/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D1'] = 'Asset growth a day before'\n",
      "\n",
      "    fdf['D2'] = 100*(0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D2'] = 'Mid(9.28)/OPC(day before)-1'\n",
      "\n",
      "    fdf['D3'] = 100*(0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)/imbalanceMsg.PrevCLC_P-1)\n",
      "    Features['D3'] = 'Mid(9.28)/CloseCross(day before)-1'\n",
      "\n",
      "    \n",
      "    \n",
      "    fdf['D4'] = 100*(imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/imbalanceMsg.PrevCLC_P\n",
      "    Features['D4'] = '(Bid(9.28)-ImbRef(9.28))/CloseCross(day before)'\n",
      "\n",
      "    fdf['D5'] = 100*(imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/imbalanceMsg.PrevCLC_P\n",
      "    Features['D5'] = '(ImbRef(9.28)-Ask(9.28))/CloseCross(day before)'\n",
      "    \n",
      "    \n",
      "    fdf['D44'] = 100*(imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/imbalanceMsg.PrevOPC_P\n",
      "    Features['D44'] = '(Bid(9.28)-ImbRef(9.28))/OpenCross(day before)'\n",
      "\n",
      "    fdf['D55'] = 100*(imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/imbalanceMsg.PrevOPC_P\n",
      "    Features['D55'] = '(ImbRef(9.28)-Ask(9.28))/OpenCross(day before)'\n",
      "    \n",
      "    \n",
      "    fdf['D444'] = (imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/(1+imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['D444'] = '(Bid(9.28)-ImbRef(9.28))/1+Spread'\n",
      "\n",
      "    fdf['D555'] = (imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/(1+imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['D555'] = '(ImbRef(9.28)-Ask(9.28))/1+Spread'\n",
      "    \n",
      "\n",
      "    fdf['D6'] = 100*(imbalanceMsg.ImbRef/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D6'] = 'ImbRef(9.28)/OpenCross(day before)-1'\n",
      "\n",
      "    fdf['D7'] = 100*(imbalanceMsg.ImbRef/imbalanceMsg.PrevCLC_P-1)\n",
      "    Features['D7'] = 'ImbRef(9.28)/CloseCross(day before)-1'\n",
      "    \n",
      "    fdf['D66'] = 100*(2*imbalanceMsg.ImbRef/(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)-1)\n",
      "    Features['D66'] = 'ImbRef(9.28)/Mid-1'\n",
      "    \n",
      "    \n",
      "\n",
      "    fdf['V1'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/(100*numpy.sign(imbalanceMsg.ImbShares)+imbalanceMsg.ImbShares)\n",
      "    Features['V1'] = '(Ask_S-Bid_S) at 9.28/Imbalance(9.28)'\n",
      "    \n",
      "    fdf['V11'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V11'] = '(Ask_S-Bid_S) at 9.28/PairedS(9.28)'\n",
      "\n",
      "    fdf['V2'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/imbalanceMsg.PrevOPC_S\n",
      "    Features['V2'] = '(Ask_S-Bid_S) at 9.28/OpenCross(day before)'\n",
      "\n",
      "    fdf['V3'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/imbalanceMsg.PrevCLC_S\n",
      "    Features['V3'] = '(Ask_S-Bid_S) at 9.28/CloseCross(day before)'\n",
      "\n",
      "    fdf['V4'] = imbalanceMsg.ImbShares/imbalanceMsg.PrevOPC_S\n",
      "    Features['V4'] = 'ImbalanceS(9.28)/OpenCrossS(day before)'\n",
      "\n",
      "    fdf['V5'] = imbalanceMsg.ImbShares/imbalanceMsg.PrevCLC_S\n",
      "    Features['V5'] = 'ImbalanceS(9.28)/CloseCrossS(day before)'\n",
      "\n",
      "    fdf['V6'] = imbalanceMsg.ImbPaired/imbalanceMsg.PrevOPC_S\n",
      "    Features['V6'] = 'PairedS(9.28)/OpenCrossS(day before)'\n",
      "\n",
      "    fdf['V7'] = imbalanceMsg.ImbPaired/imbalanceMsg.PrevCLC_S\n",
      "    Features['V7'] = 'PairedS(9.28)/CloseCrossS(day before)'\n",
      "    \n",
      "    fdf['V8'] = imbalanceMsg.ImbShares/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V8'] = 'ImbalanceS(9.28)/PairedS(9.28)'\n",
      "    \n",
      "    fdf['V9'] = imbalanceMsg.PrevOPC_S/(100+imbalanceMsg.PrevCLC_S)\n",
      "    Features['V9'] = 'OpenCrossS(day before)/CloseCrossS(day before)'\n",
      "\n",
      "\n",
      "    fdf['a1'] = fdf['D1']*fdf['D2']\n",
      "    Features['a1'] = Features['D1'] + ' Multiply ' + Features['D2']\n",
      "    \n",
      "    fdf['a2'] = fdf['D2']*fdf['D3']\n",
      "    Features['a2'] = Features['D3'] + ' Multiply ' + Features['D2']\n",
      "    \n",
      "    fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "    fdf['a4'] = fdf['D5']*fdf['D4']\n",
      "    Features['a4'] = Features['D5'] + ' Multiply ' + Features['D4']\n",
      "    \n",
      "    fdf['a5'] = fdf['D5']*fdf['D6']\n",
      "    fdf['a6'] = fdf['D1']*fdf['D6']\n",
      "    Features['a6'] = Features['D1'] + ' Multiply ' + Features['D6']\n",
      "    \n",
      "    fdf['a7'] = fdf['V1']*fdf['V2']\n",
      "    Features['a7'] = Features['V1'] + ' Multiply ' + Features['V2']\n",
      "    \n",
      "    fdf['a8'] = fdf['V2']*fdf['V3']\n",
      "    fdf['a9'] = fdf['V3']*fdf['V4']\n",
      "    Features['a9'] = Features['V3'] + ' Multiply ' + Features['V4']\n",
      "    \n",
      "    fdf['a10'] = fdf['V5']*fdf['V4']\n",
      "    fdf['a11'] = fdf['V5']*fdf['V6']\n",
      "    Features['a11'] = Features['V5'] + ' Multiply ' + Features['V6']\n",
      "    \n",
      "    fdf['a12'] = fdf['V7']*fdf['V6']\n",
      "    fdf['a13'] = fdf['V7']*fdf['V1']\n",
      "    Features['a13'] = Features['V1'] + ' Multiply ' + Features['V7']\n",
      "    \n",
      "    fdf['a14'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    Features['a14'] = 'Sign of Imbalance'\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features\n",
      "\n",
      "def create_features2(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.OPC_P/imbalanceMsg.ImbRef-1   \n",
      "    Features['Move'] = 'OpenCross/RefPrice(9.28)-1'\n",
      "    \n",
      "    fdf['Pnl'] = imbalanceMsg.OPC_P-imbalanceMsg.ImbRef\n",
      "    Features['Pnl'] = 'OpenCross/RefPrice(9.28)'\n",
      "    \n",
      "    fdf['Bid'] = imbalanceMsg.Bid_P/imbalanceMsg.ImbRef-1\n",
      "    Features['Bid'] = 'Bid(9.28)'\n",
      "    \n",
      "    fdf['Ask'] = imbalanceMsg.Ask_P/imbalanceMsg.ImbRef-1\n",
      "    Features['Ask'] = 'Ask(9.28)'\n",
      "    \n",
      "    fdf['Ref'] = imbalanceMsg.ImbRef\n",
      "    Features['Ref'] = 'Ref(9.28)'\n",
      "    \n",
      "    fdf['Near'] = imbalanceMsg.ImbCBC/imbalanceMsg.ImbRef-1\n",
      "    Features['Near'] = 'Near(9.28)'\n",
      "    \n",
      "    fdf['Far'] = imbalanceMsg.ImbFar/imbalanceMsg.ImbRef-1\n",
      "    Features['Far'] = 'Far(9.28)'\n",
      "    \n",
      "    fdf['PrevOPC'] = imbalanceMsg.PrevOPC_P/imbalanceMsg.ImbRef-1\n",
      "    Features['PrevOPC'] = 'PrevOPC'\n",
      "    \n",
      "    fdf['PrevCLC'] = imbalanceMsg.PrevCLC_P/imbalanceMsg.ImbRef-1\n",
      "    Features['PrevCLC'] = 'PrevCLC'\n",
      "\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features\n",
      "\n",
      "def create_features3(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    midP = 0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)\n",
      "    bid = imbalanceMsg.Bid_P#nsdq_BP #\n",
      "    bidS = imbalanceMsg.Bid_S#nsdq_BS#\n",
      "    ref = imbalanceMsg.ImbRef\n",
      "    ask = imbalanceMsg.Ask_P#nsdq_AP#\n",
      "    askS = imbalanceMsg.Ask_S#nsdq_AS#\n",
      "    near = imbalanceMsg.ImbCBC\n",
      "    far = imbalanceMsg.ImbFar\n",
      "    closeP = imbalanceMsg.PrevCLC_P\n",
      "    \n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.Move\n",
      "    Features['Move'] = 'Move'\n",
      "       \n",
      "    fdf['Bid'] = bid/ref-1\n",
      "    Features['Bid'] = 'Bid(9.28)'\n",
      "    \n",
      "    fdf['Ask'] = ask/ref-1\n",
      "    Features['Ask'] = 'Ask(9.28)'\n",
      "       \n",
      "    fdf['Near'] = near/ref-1\n",
      "    Features['Near'] = 'Near(9.28)'\n",
      "    \n",
      "    fdf['Far'] = far/ref-1\n",
      "    Features['Far'] = 'Far(9.28)'\n",
      "        \n",
      "    fdf['PrevCLC'] = closeP/ref-1\n",
      "    Features['PrevCLC'] = 'PrevCLC'\n",
      "    \n",
      "    fdf['Spread'] = (ask - bid)/ref\n",
      "    Features['Spread'] = '(Ask-Bid) at 9.28'\n",
      "\n",
      "    fdf['D3'] = 100*(midP/closeP-1)\n",
      "    Features['D3'] = 'Mid(9.28)/CloseCross(day before)-1'\n",
      "    \n",
      "    fdf['D4'] = 100*(bid-ref)/closeP\n",
      "    Features['D4'] = '(Bid(9.28)-ImbRef(9.28))/CloseCross(day before)'\n",
      "\n",
      "    fdf['D5'] = 100*(ref-ask)/closeP\n",
      "    Features['D5'] = '(ImbRef(9.28)-Ask(9.28))/CloseCross(day before)'       \n",
      "    \n",
      "    fdf['D444'] = (bid-ref)/(1+ask - bid)\n",
      "    Features['D444'] = '(Bid(9.28)-ImbRef(9.28))/1+Spread'\n",
      "\n",
      "    fdf['D555'] = (ref-ask)/(1+ask - bid)\n",
      "    Features['D555'] = '(ImbRef(9.28)-Ask(9.28))/1+Spread'\n",
      "    \n",
      "    fdf['D7'] = 100*(ref/closeP-1)\n",
      "    Features['D7'] = 'ImbRef(9.28)/CloseCross(day before)-1'\n",
      "    \n",
      "    fdf['D66'] = 100*(ref/midP-1)\n",
      "    Features['D66'] = 'ImbRef(9.28)/Mid-1'\n",
      "\n",
      "    fdf['V1'] = (askS - bidS)/(100*numpy.sign(imbalanceMsg.ImbShares)+imbalanceMsg.ImbShares)\n",
      "    Features['V1'] = '(Ask_S-Bid_S) at 9.28/Imbalance(9.28)'\n",
      "    \n",
      "    fdf['V11'] = (askS - bidS)/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V11'] = '(Ask_S-Bid_S) at 9.28/PairedS(9.28)'\n",
      "    \n",
      "    fdf['V8'] = imbalanceMsg.ImbShares/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V8'] = 'ImbalanceS(9.28)/PairedS(9.28)'\n",
      "         \n",
      "    fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "    \n",
      "    fdf['a4'] = fdf['D5']*fdf['D4']\n",
      "    Features['a4'] = Features['D5'] + ' Multiply ' + Features['D4']\n",
      "            \n",
      "    fdf['a14'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    Features['a14'] = 'Sign of Imbalance'\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features\n",
      "\n",
      "def create_features33(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "\n",
      "    midP = 0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)\n",
      "    bid = imbalanceMsg.Bid_P\n",
      "    bidS = imbalanceMsg.Bid_S    \n",
      "    min3 = imbalanceMsg[['ImbRef','ImbCBC','ImbFar']].apply(min,axis=1)\n",
      "    max3 = imbalanceMsg[['ImbRef','ImbCBC','ImbFar']].apply(max,axis=1)\n",
      "    \n",
      "    f = lambda x: int(x[3]>0)*max(x[0],x[1])+\\\n",
      "                  int(x[3]<0)*min(x[0],x[1])+\\\n",
      "                  int(x[3]==0)*(x[0]+x[1])*0.5\n",
      "            \n",
      "    f = lambda x:2.0*x[0]*x[1]/(x[0]+x[1])\n",
      "    \n",
      "    f = lambda x: int(x[3]>0)*(0.85*min(x[0],x[1])+0.15*max(x[0],x[1]))+\\\n",
      "                  int(x[3]<0)*(0.15*min(x[0],x[1])+0.85*max(x[0],x[1]))+\\\n",
      "                  int(x[3]==0)*(x[0]+x[1])*0.5\n",
      "            \n",
      "    f = lambda x:  (x[0] + x[1] +  0.5*(x[4] + x[5]))/3.0\n",
      "    \n",
      "    f = lambda x:  int(x[3]>0)*\\\n",
      "                   (\n",
      "                   (min(x[0],x[1])> x[4])*(x[0]+x[1])*0.5+\\\n",
      "                   (min(x[0],x[1])<=x[4])*(0.85*min(x[0],x[1])+0.15*max(x[0],x[1])))+\\\n",
      "                   int(x[3]<0)*\\\n",
      "                   ((max(x[0],x[1])<x[4])*(x[0]+x[1])*0.5+\\\n",
      "                   (max(x[0],x[1])>=x[4])*(0.15*min(x[0],x[1])+0.85*max(x[0],x[1])))+\\\n",
      "                   int(x[3]==0)*(x[0]+x[1])*0.5\n",
      "    \n",
      "    imbalanceMsg['Mid_P'] = 0.5*( imbalanceMsg.Ask_P +  imbalanceMsg.Bid_P)\n",
      "    ref = imbalanceMsg[['ImbRef','ImbCBC','ImbFar','ImbShares','Mid_P']].apply(f,axis=1)\n",
      "    #ref = imbalanceMsg.ImbRef\n",
      "    ask = imbalanceMsg.Ask_P\n",
      "    askS = imbalanceMsg.Ask_S\n",
      "    near = imbalanceMsg.ImbCBC\n",
      "    far = imbalanceMsg.ImbFar\n",
      "    closeP = imbalanceMsg.PrevCLC_P\n",
      "    spread = ask - bid\n",
      "    \n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    \n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "        \n",
      "    fdf['OPC_P'] = imbalanceMsg.OPC_P\n",
      "    \n",
      "    fdf['Ask_P'] = ask\n",
      "    \n",
      "    fdf['Bid_P'] = bid\n",
      "    \n",
      "    fdf['Mid_P'] = midP\n",
      "    #---------------------------------\n",
      "        \n",
      "    fdf['Bid'] = ref/bid-1\n",
      "    \n",
      "    fdf['Ask'] = ask/ref-1   \n",
      "        \n",
      "    fdf['BidD'] = bid - ref\n",
      "    \n",
      "    fdf['AskD'] = ref - ask\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['Near'] = near/ref-1\n",
      "    \n",
      "    fdf['Far'] = far/ref-1\n",
      "    \n",
      "    fdf['Spread'] = spread/ref\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['D4'] = 100*(bid-ref)/closeP\n",
      "\n",
      "    fdf['D5'] = 100*(ref-ask)/closeP\n",
      "    #---------------------------------\n",
      "        \n",
      "    fdf['D444'] = (bid-ref)/(1+spread)\n",
      "\n",
      "    fdf['D555'] = (ref-ask)/(1+spread)\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['D66'] = 100*(ref/midP-1)\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['V1'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/(100+np.abs(imbalanceMsg.ImbShares))\n",
      "    \n",
      "    fdf['V1n'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/((askS + bidS)/2+np.abs(imbalanceMsg.ImbShares))\n",
      "    \n",
      "    fdf['V11'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/(100+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V11n'] =numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['V8'] = imbalanceMsg.ImbShares/(100+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V8n'] = imbalanceMsg.ImbShares/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V8nn'] = (imbalanceMsg.ImbShares-(askS - bidS))/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "    #---------------------------------\n",
      "        \n",
      "    fdf['a1'] = fdf['Bid']*fdf['Ask']\n",
      "\n",
      "    fdf['a4'] = fdf['D5']*fdf['D4']\n",
      "    \n",
      "    fdf['a5'] = fdf['D444']*fdf['D555']\n",
      "    #---------------------------------\n",
      "       \n",
      "    fdf['a14'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    \n",
      "    fdf['y'] = 1*(imbalanceMsg.OPC_P>ask) -  1*(imbalanceMsg.OPC_P<bid)\n",
      "        \n",
      "    fdf['PrevCLC'] = closeP/ref-1   \n",
      "\n",
      "    fdf['D3'] = 100*(midP/closeP-1)\n",
      "        \n",
      "    fdf['D7'] = 100*(ref/closeP-1)\n",
      "    \n",
      "    fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "       \n",
      "    fdf['a6'] = fdf['D444']*fdf['D444']\n",
      "    \n",
      "    fdf['a7'] = fdf['D555']*fdf['D555']\n",
      "    \n",
      "    fdf['p'] = numpy.floor(fdf['Mid_P']/50)\n",
      "    \n",
      "    #fdf = fdf[max3-min3<0.5*ref]\n",
      "        \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_features4(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.Move\n",
      "    Features['Move'] = 'Move'\n",
      "    \n",
      "    fdf['CMove'] = imbalanceMsg.Move\n",
      "    fdf.CMove = 0\n",
      "    fdf.CMove[imbalanceMsg.OPC_P-imbalanceMsg.Ask_P>0.1] = 3\n",
      "    fdf.CMove[(imbalanceMsg.OPC_P-imbalanceMsg.Ask_P>0.02) & \n",
      "              (imbalanceMsg.OPC_P-imbalanceMsg.Ask_P<=0.1)] = 2\n",
      "    fdf.CMove[(imbalanceMsg.OPC_P-imbalanceMsg.Ask_P>0)\n",
      "              & (imbalanceMsg.OPC_P-imbalanceMsg.Ask_P<=0.02)] = 1\n",
      "    fdf.CMove[(imbalanceMsg.Bid_P-imbalanceMsg.OPC_P>0.1)] = -3\n",
      "    fdf.CMove[(imbalanceMsg.Bid_P-imbalanceMsg.OPC_P>0.02)\n",
      "              & (imbalanceMsg.Bid_P-imbalanceMsg.OPC_P<=0.1)] = -2\n",
      "    fdf.CMove[(imbalanceMsg.Bid_P-imbalanceMsg.OPC_P>0)\n",
      "              & (imbalanceMsg.Bid_P-imbalanceMsg.OPC_P<=0.02)] = -1\n",
      "    Features['CMove'] = 'CMove'\n",
      "    \n",
      "    \n",
      "    \n",
      "    fdf['0'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    Features['0'] = 'Side'\n",
      "       \n",
      "    fdf['1'] = imbalanceMsg.Bid_P-(imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['1'] = 'Bid-Spread'\n",
      "    \n",
      "    fdf['2'] = imbalanceMsg.Bid_P\n",
      "    Features['2'] = 'Bid'\n",
      "       \n",
      "    fdf['3'] = imbalanceMsg.Ask_P\n",
      "    Features['3'] = 'Ask'\n",
      "    \n",
      "    fdf['4'] = imbalanceMsg.Ask_P + (imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['4'] = 'Ask+Spread'\n",
      "    \n",
      "    fdf['5'] = imbalanceMsg.ImbRef\n",
      "    Features['5'] = 'Ref'\n",
      "    \n",
      "    fdf['6'] = imbalanceMsg.ImbCBC\n",
      "    Features['6'] = 'Near'\n",
      "    \n",
      "    fdf['7'] = imbalanceMsg.ImbFar\n",
      "    Features['7'] = 'Far'\n",
      "    \n",
      "    fdf['8'] = imbalanceMsg.PrevCLC_P\n",
      "    Features['8'] = 'Close'\n",
      "    \n",
      "    fdf['n2'] = imbalanceMsg.nsdq_BP\n",
      "    Features['n2'] = 'nBid'\n",
      "       \n",
      "    fdf['n3'] = imbalanceMsg.nsdq_AP\n",
      "    Features['n3'] = 'nAsk'\n",
      "    \n",
      "    fdf['2_2'] = imbalanceMsg.Bid2\n",
      "    Features['2_2'] = 'Bid2'\n",
      "       \n",
      "    fdf['3_2'] = imbalanceMsg.Ask2\n",
      "    Features['3_2'] = 'Ask2'  \n",
      "    \n",
      "    fdf['9'] = imbalanceMsg.ImbRef-0.05\n",
      "    Features['9'] = 'Ref-1'\n",
      "    \n",
      "    fdf['10'] = imbalanceMsg.ImbRef+0.05\n",
      "    Features['10'] = 'Ref+1'\n",
      "    \n",
      "    fdf['11'] = imbalanceMsg.PrevCLC_P-0.05\n",
      "    Features['11'] = 'Close-1'\n",
      "    \n",
      "    fdf['12'] = imbalanceMsg.PrevCLC_P+0.05\n",
      "    Features['12'] = 'Close+1'\n",
      "    \n",
      "    fdf['13'] = imbalanceMsg.Bid_P-0.05\n",
      "    Features['13'] = 'Bid-1'\n",
      "    \n",
      "    fdf['14'] = imbalanceMsg.Bid_P+0.05\n",
      "    Features['14'] = 'Bid+1'\n",
      "    \n",
      "    fdf['15'] = imbalanceMsg.Ask_P-0.05\n",
      "    Features['15'] = 'Ask-1'\n",
      "    \n",
      "    fdf['16'] = imbalanceMsg.Ask_P+0.05\n",
      "    Features['16'] = 'Ask+1'\n",
      "    \n",
      "    fdf['17'] = imbalanceMsg.ImbRef+(imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['17'] = 'Ref+Spread'\n",
      "    \n",
      "    fdf['18'] = imbalanceMsg.ImbRef-(imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['18'] = 'Ref-Spread'\n",
      "    \n",
      "    fdf['19'] = imbalanceMsg.ImbRef-0.02\n",
      "    Features['19'] = 'Ref-1'\n",
      "    \n",
      "    fdf['20'] = imbalanceMsg.ImbRef+0.02\n",
      "    Features['20'] = 'Ref+1'\n",
      "    \n",
      "    fdf['21'] = imbalanceMsg.PrevCLC_P-0.02\n",
      "    Features['21'] = 'Close-1'\n",
      "    \n",
      "    fdf['22'] = imbalanceMsg.PrevCLC_P+0.02\n",
      "    Features['22'] = 'Close+1'\n",
      "    \n",
      "    fdf['23'] = imbalanceMsg.Bid_P-0.02\n",
      "    Features['23'] = 'Bid-1'\n",
      "    \n",
      "    fdf['24'] = imbalanceMsg.Bid_P+0.02\n",
      "    Features['24'] = 'Bid+1'\n",
      "    \n",
      "    fdf['25'] = imbalanceMsg.Ask_P-0.02\n",
      "    Features['25'] = 'Ask-1'\n",
      "    \n",
      "    fdf['26'] = imbalanceMsg.Ask_P+0.02\n",
      "    Features['26'] = 'Ask+1'\n",
      "    \n",
      "    return fdf, Features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getImbTime(nImb):\n",
      "    startTime = '9:27:58'\n",
      "    endTime = '9:28:03'\n",
      "    if nImb==2:\n",
      "        startTime = '9:28:03'\n",
      "        endTime = '9:28:08'\n",
      "    elif nImb==3:\n",
      "        startTime = '9:28:08'\n",
      "        endTime = '9:28:12'\n",
      "    elif nImb==4:\n",
      "        startTime = '9:28:12'\n",
      "        endTime = '9:28:18'\n",
      "    elif nImb==5:\n",
      "        startTime = '9:28:18'\n",
      "        endTime = '9:28:22'\n",
      "    elif nImb==6:\n",
      "        startTime = '9:28:22'\n",
      "        endTime = '9:28:28'\n",
      "    elif nImb==7:\n",
      "        startTime = '9:28:28'\n",
      "        endTime = '9:28:32'\n",
      "    elif nImb==8:\n",
      "        startTime = '9:28:32'\n",
      "        endTime = '9:28:38'\n",
      "    elif nImb==9:\n",
      "        startTime = '9:28:38'\n",
      "        endTime = '9:28:42'\n",
      "    elif nImb==10:\n",
      "        startTime = '9:28:42'\n",
      "        endTime = '9:28:48'\n",
      "    elif nImb==11:\n",
      "        startTime = '9:28:48'\n",
      "        endTime = '9:28:52'\n",
      "    elif nImb==12:\n",
      "        startTime = '9:28:52'\n",
      "        endTime = '9:28:58'\n",
      "    elif nImb==13:\n",
      "        startTime = '9:28:58'\n",
      "        endTime = '9:29:02'\n",
      "    elif nImb==14:\n",
      "        startTime = '9:29:02'\n",
      "        endTime = '9:29:08'\n",
      "    elif nImb==15:\n",
      "        startTime = '9:29:08'\n",
      "        endTime = '9:29:12'\n",
      "    elif nImb==16:\n",
      "        startTime = '9:29:12'\n",
      "        endTime = '9:29:18'\n",
      "    elif nImb==17:\n",
      "        startTime = '9:29:18'\n",
      "        endTime = '9:29:22'\n",
      "    elif nImb==18:\n",
      "        startTime = '9:29:22'\n",
      "        endTime = '9:29:28'\n",
      "    elif nImb==19:\n",
      "        startTime = '9:29:28'\n",
      "        endTime = '9:29:32'\n",
      "    elif nImb==20:\n",
      "        startTime = '9:29:32'\n",
      "        endTime = '9:29:38'\n",
      "    elif nImb==21:\n",
      "        startTime = '9:29:38'\n",
      "        endTime = '9:29:42'\n",
      "    elif nImb==22:\n",
      "        startTime = '9:29:42'\n",
      "        endTime = '9:29:48'\n",
      "    elif nImb==23:\n",
      "        startTime = '9:29:48'\n",
      "        endTime = '9:29:52'\n",
      "    elif nImb==24:\n",
      "        startTime = '9:29:52'\n",
      "        endTime = '9:29:58'\n",
      "    return (startTime,endTime)\n",
      "\n",
      "def get_imbalanceMSG2(df,nImb):\n",
      "    (startTime,endTime) = getImbTime(nImb)\n",
      "    \n",
      "    imbalanceMsg = df[df.Reason == 'Imbalance']\n",
      "    imbalanceMsg = imbalanceMsg[\n",
      "    (imbalanceMsg.ImbRef>0) & \n",
      "    (imbalanceMsg.ImbCBC>0) &\n",
      "    (imbalanceMsg.ImbFar>0) &\n",
      "    (imbalanceMsg.Ask_P>0) &\n",
      "    (imbalanceMsg.Bid_P>0) #&\n",
      "    #(imbalanceMsg.ImbShares!=0)\n",
      "    ]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])\n",
      "\n",
      "    Timestamp = []\n",
      "    for i in range(imbalanceMsg.shape[0]):\n",
      "        Timestamp.append(datetime.datetime.strptime(imbalanceMsg.Time[i],'%H:%M:%S'))\n",
      "\n",
      "    imbalanceMsg['Timestamp'] = Timestamp\n",
      "    del Timestamp\n",
      "    imbalanceMsg = imbalanceMsg.set_index(['Timestamp'])\n",
      "    imbalanceMsg = imbalanceMsg.between_time(startTime,endTime)\n",
      "    \n",
      "    imbalanceMsg = imbalanceMsg[['Date','Symbol','Bid_P','Bid_S','Ask_P','Ask_S','ImbRef','ImbCBC','ImbFar','ImbShares','ImbPaired']]\n",
      "    imbalanceMsg['Timestamp'] = imbalanceMsg.index\n",
      "         \n",
      "    #Getting additional info about previous day\n",
      "    OPC = df[df.Reason == 'OPG']\n",
      "    OPC = OPC[['Date','Symbol','tPrice']]\n",
      "    OPC.columns = ['Date','Symbol','OPC_P']\n",
      "    \n",
      "    prev_CLC = df[df.tSide == 'YDAY']\n",
      "    prev_CLC = prev_CLC[['Date','Symbol','tPrice','tShares']]\n",
      "    prev_CLC.columns = ['Date','Symbol','PrevCLC_P','PrevCLC_S']\n",
      "    \n",
      "    #Adding OPC\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_CLC, on=['Symbol','Date'])\n",
      "\n",
      "    #Filtering data with no prev OPC\n",
      "    imbalanceMsg = imbalanceMsg[imbalanceMsg.OPC_P>0]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])    \n",
      "    \n",
      "    #Adding new feature which reflects price move direction\n",
      "    imbalanceMsg['Move'] = imbalanceMsg.Bid_P\n",
      "    imbalanceMsg.Move = 0\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P>imbalanceMsg.Ask_P] = 1\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P<imbalanceMsg.Bid_P] = -1\n",
      "    imbalanceMsg.Bid_S = imbalanceMsg.Bid_S.astype(float)\n",
      "    imbalanceMsg.PrevCLC_P = imbalanceMsg.PrevCLC_P.astype(float)\n",
      "       \n",
      "    return imbalanceMsg   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_imbelanceMSG3(df,nImb):\n",
      "    (startTime,endTime) = getImbTime(nImb)\n",
      "    \n",
      "    imbalanceMsg = df[df.Reason == 'Imbalance']\n",
      "    imbalanceMsg = imbalanceMsg[\n",
      "    (imbalanceMsg.ImbRef>0) & \n",
      "    (imbalanceMsg.ImbCBC>0) &\n",
      "    (imbalanceMsg.ImbFar>0) &\n",
      "    (imbalanceMsg.ImbShares!=0)\n",
      "    ]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])\n",
      "    \n",
      "    Timestamp = []\n",
      "    for i in range(imbalanceMsg.shape[0]):\n",
      "        Timestamp.append(datetime.datetime.strptime(imbalanceMsg.Time[i],'%H:%M:%S'))\n",
      "\n",
      "    imbalanceMsg['Timestamp'] = Timestamp\n",
      "    del Timestamp\n",
      "    imbalanceMsg = imbalanceMsg.set_index(['Timestamp'])\n",
      "    imbalanceMsg = imbalanceMsg.between_time(startTime,endTime)\n",
      "\n",
      "    imbalanceMsg = imbalanceMsg[['Date','Symbol','Bid_P','Bid_S','Ask_P','Ask_S',\n",
      "                             'ImbRef','ImbCBC','ImbFar','ImbShares','ImbPaired',\n",
      "                             'nsdq_BP', 'nsdq_BS', 'nsdq_AP', 'nsdq_AS','Bid2','Ask2']]\n",
      "    imbalanceMsg['Timestamp'] = imbalanceMsg.index\n",
      "         \n",
      "    #Getting additional info about previous day\n",
      "    OPC = df[df.tType == 'OPG']\n",
      "    OPC = OPC[['Date','Symbol','tPrice']]\n",
      "    OPC.columns = ['Date','Symbol','OPC_P']\n",
      "    \n",
      "    prev_CLC = df[df.tType == 'YDAY']\n",
      "    prev_CLC = prev_CLC[['Date','Symbol','tVenue','tPrice']]\n",
      "    prev_CLC.columns = ['Date','Symbol','PrevCLC_P','PrevCLC_S']\n",
      "    \n",
      "    #Adding OPC\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_CLC, on=['Symbol','Date'])\n",
      "\n",
      "    #Filtering data with no prev OPC\n",
      "    imbalanceMsg = imbalanceMsg[imbalanceMsg.OPC_P>0]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])    \n",
      "    \n",
      "    #Adding new feature which reflects price move direction\n",
      "    imbalanceMsg['Move'] = imbalanceMsg.Bid_P\n",
      "    imbalanceMsg.Move = 0\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P>imbalanceMsg.Ask_P] = 1\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P<imbalanceMsg.Bid_P] = -1\n",
      "    imbalanceMsg.Bid_S = imbalanceMsg.Bid_S.astype(float)\n",
      "    imbalanceMsg.PrevCLC_P = imbalanceMsg.PrevCLC_P.astype(float)\n",
      "       \n",
      "    return imbalanceMsg   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Precision_Recall(cm, labels):\n",
      "    m = cm.shape[0]\n",
      "    sums1 = cm.sum(axis=1);\n",
      "    sums2 = cm.sum(axis=0);\n",
      "    precision = 0\n",
      "    s1 = 0\n",
      "    s2 = 0\n",
      "    for i in range(m):\n",
      "        if labels[i] == 0: continue;\n",
      "        precision +=  cm[i,i]\n",
      "        s1 += sums1[i]\n",
      "        s2 += sums2[i]\n",
      "\n",
      "    return precision/s2, precision/s1, 2*(precision/s1 * precision/s2)/(precision/s2 + precision/s1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_cv_proba(X,y,clf_class,n_folds,test_size,dates,datesDF,**kwargs):\n",
      "    import pandas\n",
      "    import numpy\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import RandomForestClassifier as RF\n",
      "    import numpy\n",
      "    \n",
      "    labels =  numpy.sort(list(set(y)))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    \n",
      "    CLF_BEST = clf_class()\n",
      "    TEST_F_Score = 0\n",
      "    \n",
      "    for i in range(n_folds): \n",
      "        #======Get test_train_split=============\n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "\n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]] \n",
      "        \n",
      "        Xtrain.index = range(Xtrain.shape[0])\n",
      "        Xtest.index = range(Xtest.shape[0])\n",
      "        ytrain.index = range(ytrain.shape[0])\n",
      "        ytest.index = range(ytest.shape[0])\n",
      "        #========================================        \n",
      "            \n",
      "        if clf_class=='NN':    \n",
      "            from pybrain.tools.shortcuts import buildNetwork\n",
      "            from pybrain.datasets import SupervisedDataSet\n",
      "            from pybrain.datasets import ClassificationDataSet\n",
      "            from pybrain.structure.modules   import SoftmaxLayer\n",
      "\n",
      "            #Create dataset\n",
      "            #ds = SupervisedDataSet(Xtrain.shape[1], 1)\n",
      "            ds = ClassificationDataSet(Xtrain.shape[1], 1, nb_classes=2)\n",
      "            for j in range(Xtrain.shape[0]):\n",
      "                ds.addSample(Xtrain.ix[j,:], ytrain.ix[j,:])\n",
      "            ds._convertToOneOfMany( )\n",
      "\n",
      "            #Create net\n",
      "            #net = buildNetwork(ds.indim, ds.indim*2, ds.outdim, outclass=SoftmaxLayer)\n",
      "\n",
      "            #varsion1\n",
      "            #from pybrain.structure import FeedForwardNetwork\n",
      "            #net = FeedForwardNetwork()\n",
      "            from pybrain.structure import LinearLayer, SigmoidLayer\n",
      "            #inLayer = LinearLayer(ds.indim)\n",
      "            #hiddenLayer = SigmoidLayer(ds.indim)\n",
      "            #outLayer = SoftmaxLayer(ds.outdim)\n",
      "            #net.addInputModule(inLayer)\n",
      "            #net.addModule(hiddenLayer)\n",
      "            #net.addOutputModule(outLayer)\n",
      "            from pybrain.structure import FullConnection\n",
      "            #in_to_hidden = FullConnection(inLayer, hiddenLayer)\n",
      "            #hidden_to_out = FullConnection(hiddenLayer, outLayer)\n",
      "            #net.addConnection(in_to_hidden)\n",
      "            #net.addConnection(hidden_to_out)\n",
      "            #net.sortModules()\n",
      "            \n",
      "            #varsion2\n",
      "            from pybrain.structure import RecurrentNetwork\n",
      "            net = RecurrentNetwork()\n",
      "            net.addInputModule(LinearLayer(ds.indim, name='inLayer'))\n",
      "            net.addModule(SigmoidLayer(ds.indim, name='hiddenLayer'))\n",
      "            net.addOutputModule(SoftmaxLayer(ds.outdim, name='outLayer'))\n",
      "            net.addConnection(FullConnection(net['inLayer'], net['hiddenLayer'], name='in_to_hidden'))\n",
      "            net.addConnection(FullConnection(net['hiddenLayer'], net['outLayer'], name='hidden_to_out'))\n",
      "            net.addRecurrentConnection(FullConnection(net['hiddenLayer'], net['hiddenLayer'], name='hidden_to_hidden'))\n",
      "            net.sortModules()\n",
      "\n",
      "            #Train net\n",
      "            from pybrain.supervised.trainers import BackpropTrainer\n",
      "            trainer = BackpropTrainer(net, ds, momentum=0.1, verbose=True, weightdecay=0.01)\n",
      "            trainer.train()\n",
      "            #trainer.trainUntilConvergence(dataset=ds,maxEpochs=10)\n",
      "            \n",
      "            if False:#combination of NN and COMB\n",
      "                #get new features\n",
      "                Xtrain_new= numpy.zeros((Xtrain.shape[0],hiddenLayer.dim),float)\n",
      "                Xtest_new= numpy.zeros((Xtest.shape[0],hiddenLayer.dim),float)\n",
      "\n",
      "                for j in range(Xtrain.shape[0]):\n",
      "                    to_hidden=numpy.dot(in_to_hidden.params.reshape(hiddenLayer.dim,inLayer.dim),\\\n",
      "                                        Xtrain.ix[j,:].as_matrix())\n",
      "                    Xtrain_new[j,:] = hiddenLayer.activate(to_hidden)\n",
      "                for j in range(Xtest.shape[0]):\n",
      "                    to_hidden=numpy.dot(in_to_hidden.params.reshape(hiddenLayer.dim,inLayer.dim),\\\n",
      "                                        Xtest.ix[j,:].as_matrix())\n",
      "                    Xtest_new[j,:] = hiddenLayer.activate(to_hidden)\n",
      "\n",
      "                #Work with new features\n",
      "                clf1 = RF(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05, criterion = 'entropy')\n",
      "                clf2 = GBC(init='zero')\n",
      "\n",
      "                clf1.fit(Xtrain_new,ytrain)\n",
      "                clf2.fit(Xtrain_new,ytrain)\n",
      "\n",
      "                probaTest1=clf1.predict_proba(Xtest_new).astype(float)\n",
      "                probaTest2=clf2.predict_proba(Xtest_new).astype(float)\n",
      "                for i in range(probaTest1.shape[0]):\n",
      "                    for j in range(probaTest1.shape[1]):\n",
      "                         probaTest1[i,j]=0.5*(probaTest1[i,j]+probaTest2[i,j])\n",
      "\n",
      "\n",
      "                probaTrain1=clf1.predict_proba(Xtrain_new).astype(float)\n",
      "                probaTrain2=clf2.predict_proba(Xtrain_new).astype(float)\n",
      "                for i in range(probaTrain1.shape[0]):\n",
      "                    for j in range(probaTrain1.shape[1]):\n",
      "                        probaTrain1[i,j]=0.5*(probaTrain1[i,j]+probaTrain2[i,j])\n",
      "\n",
      "                ypred = clf1.classes_[numpy.argmax(probaTest1,axis=1)]\n",
      "                ypredTrain = clf1.classes_[numpy.argmax(probaTrain1,axis=1)] \n",
      "            else:\n",
      "                ypred = ytest.copy()\n",
      "                ypredTrain = ytrain.copy()\n",
      "\n",
      "                for j in range(Xtrain.shape[0]):\n",
      "                    ypredTrain.ix[j]=net.activate(Xtrain.ix[j,:])[1]>0.5\n",
      "                for j in range(Xtest.shape[0]):\n",
      "                    ypred.ix[j]=net.activate(Xtest.ix[j,:])[1]>0.5\n",
      "                \n",
      "            test_cm += confusion_matrix(ytest.astype(bool),ypred.astype(bool),labels).astype(float)/n_folds\n",
      "            train_cm += confusion_matrix(ytrain.astype(bool),ypredTrain.astype(bool),labels).astype(float)/n_folds\n",
      "             \n",
      "            continue;    \n",
      "            \n",
      "        if clf_class=='B':\n",
      "            ypred = ytest.copy(); ypred[:] = 0\n",
      "            ypredTrain = ytrain.copy(); ypredTrain[:] = 0\n",
      "            if (any(Xtest.columns=='D4')):\n",
      "                ypred[(Xtest.D4>=0)] = 1\n",
      "                ypredTrain[(Xtrain.D4>=0)] = 1\n",
      "            if (any(Xtest.columns=='D5')):\n",
      "                ypred[(Xtest.D5>=0)] = 1\n",
      "                ypredTrain[(Xtrain.D5>=0)] = 1\n",
      "            \n",
      "            continue;        \n",
      "            \n",
      "        if (clf_class=='COMB'):\n",
      "                clf1 = RF(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05, criterion = 'entropy')\n",
      "                clf2 = GBC(min_samples_split = Xtrain.shape[0]*0.05,init='zero')# learning_rate=0.1\n",
      "                \n",
      "                #z = float(len(ytrain[ytrain==0]))\n",
      "                #nall = float(len(ytrain))\n",
      "                #sample_weight = np.array([(nall-z)/nall if i == 0 else z/nall for i in ytrain])\n",
      "                clf1.fit(Xtrain,ytrain)\n",
      "                clf2.fit(Xtrain,ytrain)\n",
      "                \n",
      "                probaTest1=clf1.predict_proba(Xtest).astype(float)\n",
      "                probaTest2=clf2.predict_proba(Xtest).astype(float)\n",
      "                for i in range(probaTest1.shape[0]):\n",
      "                    for j in range(probaTest1.shape[1]):\n",
      "                        probaTest1[i,j]=0.5*(probaTest1[i,j]+probaTest2[i,j])\n",
      "\n",
      "                        \n",
      "                probaTrain1=clf1.predict_proba(Xtrain).astype(float)\n",
      "                probaTrain2=clf2.predict_proba(Xtrain).astype(float)\n",
      "                for i in range(probaTrain1.shape[0]):\n",
      "                    for j in range(probaTrain1.shape[1]):\n",
      "                        probaTrain1[i,j]=0.5*(probaTrain1[i,j]+probaTrain2[i,j])\n",
      "                                 \n",
      "                ypred = clf1.classes_[numpy.argmax(probaTest1,axis=1)]\n",
      "                ypredTrain = clf1.classes_[numpy.argmax(probaTrain1,axis=1)]  \n",
      "\n",
      "                test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "                train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "            \n",
      "                continue;\n",
      "            \n",
      "        else: \n",
      "                if (type(clf_class()) ==  type(LR())) :\n",
      "                    clf = clf_class(class_weight='auto',C=0.1)\n",
      "                if (type(clf_class()) ==  type(SVC())):\n",
      "                    clf = clf_class(class_weight='auto',probability=True)\n",
      "                if (type(clf_class()) ==  type(RF())):\n",
      "                    #print 1\n",
      "                    clf = clf_class(n_jobs=4,min_samples_split = Xtrain.shape[0]*0.05, \\\n",
      "                                   criterion = 'entropy', n_estimators = 10)# min_samples_leaf = Xtrain.shape[0]*0.05,\n",
      "                if (type(clf_class()) ==  type(GBC())):\n",
      "                    clf = clf_class(min_samples_split = Xtrain.shape[0]*0.05,init='zero')#min_samples_split = Xtrain.shape[0]*0.05\n",
      "                if (type(clf_class()) ==  type(GBR())):\n",
      "                    clf = clf_class(init='zero')\n",
      "\n",
      "                clf.fit(Xtrain,ytrain)\n",
      "                #print type(clf)\n",
      "            \n",
      "                if (type(clf_class()) !=  type(GBR())):\n",
      "                    probaTest = clf.predict_proba(Xtest).astype(float)\n",
      "                    probaTrain = clf.predict_proba(Xtrain).astype(float)\n",
      "\n",
      "                    ypred = clf.classes_[numpy.argmax(probaTest,axis=1)]\n",
      "                    ypredTrain = clf.classes_[numpy.argmax(probaTrain,axis=1)]  \n",
      "\n",
      "                    test_cm_tmp = confusion_matrix(ytest,ypred,labels).astype(float)\n",
      "                    test_cm += test_cm_tmp/n_folds\n",
      "                    train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "                    \n",
      "                else:\n",
      "                    probaTest = clf.predict(Xtest).astype(float)\n",
      "                    probaTrain = clf.predict(Xtrain).astype(float)\n",
      "\n",
      "                    ypred = probaTest>0.5\n",
      "                    ypredTrain = probaTrain>0.5  \n",
      "\n",
      "                    test_cm_tmp = confusion_matrix(ytest,ypred,labels).astype(float)\n",
      "                    test_cm += test_cm_tmp/n_folds\n",
      "                    train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds \n",
      "                    \n",
      "                pr =  Precision_Recall(test_cm_tmp, labels)\n",
      "                #print pr\n",
      "                if (pr[2]>TEST_F_Score):\n",
      "                     TEST_F_Score =  pr[2]\n",
      "                     CLF_BEST = clf  \n",
      "    \n",
      "    \n",
      "    #print TEST_ERRORS\n",
      "    print \"max F_Score \",TEST_F_Score\n",
      "    \n",
      "    #print CLF_BEST\n",
      "\n",
      "    test_pr = Precision_Recall(test_cm, labels)\n",
      "    train_pr = Precision_Recall(train_cm, labels)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm, CLF_BEST, TEST_F_Score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dates_tmp_df(fdf):\n",
      "    import numpy\n",
      "    \n",
      "    datesDF = pd.DataFrame()\n",
      "    datesDF['Date'] = fdf.Date\n",
      "    datesDF['newIndex'] = numpy.zeros((datesDF.shape[0],1))\n",
      "    datesDF.index = range(datesDF.shape[0])\n",
      "\n",
      "    dates = sorted(list(set(fdf.Date)))\n",
      "    for i in range(datesDF.shape[0]):\n",
      "        for j in range(len(dates)):\n",
      "            if (datesDF.Date[i]==dates[j]):            \n",
      "                datesDF.newIndex[i] = j\n",
      "            \n",
      "    datesDF.index = datesDF.newIndex \n",
      "    datesDF.newIndex = range(datesDF.shape[0])\n",
      "    datesDF = datesDF['newIndex']\n",
      "    \n",
      "    return datesDF\n",
      "\n",
      "def run_cv2(X,y,clf_class,n_folds,test_size,dates,datesDF,**kwargs):\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn import preprocessing\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    from sklearn.ensemble import RandomForestRegressor as RFR\n",
      "    import numpy\n",
      "    \n",
      "    if (type(clf_class()) !=  type(RFR())):\n",
      "        labels =  numpy.sort(list(set(y)))\n",
      "    else:\n",
      "        labels =  numpy.sort(list(set(np.sign(y))))\n",
      "        \n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        if clf_class!='B':\n",
      "            if not kwargs.has_key('n_ensembles'):\n",
      "                n_ensembles = 1\n",
      "                test_size_ensemble = 0\n",
      "            else:\n",
      "                n_ensembles = kwargs['n_ensembles']\n",
      "                test_size_ensemble = kwargs['test_size_ensemble']\n",
      "                \n",
      "            ypred = ytest.copy(); ypred[:] = 0\n",
      "            ypredTrain = ytrain.copy(); ypredTrain[:] = 0\n",
      "            for j in range(n_ensembles):  \n",
      "                Xtrain_sub, Xtest_sub, ytrain_sub, ytest_sub = train_test_split(Xtrain, ytrain, test_size=test_size_ensemble)\n",
      "\n",
      "                if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "                    clf = clf_class(class_weight='auto')\n",
      "                else:\n",
      "                    clf = clf_class(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05)\n",
      "                    \n",
      "                clf.fit(Xtrain_sub,ytrain_sub)\n",
      "\n",
      "                ypred += clf.predict(Xtest).astype(float)/n_ensembles\n",
      "                ypredTrain += clf.predict(Xtrain).astype(float)/n_ensembles\n",
      "\n",
      "            #Averaging of assemblies results\n",
      "            if (type(clf_class()) !=  type(RFR())):\n",
      "                ypred[ypred>0.5] = 1\n",
      "                ypred[ypred<-0.5] = -1\n",
      "                ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "\n",
      "                ypredTrain[ypredTrain>0.5] = 1\n",
      "                ypredTrain[ypredTrain<-0.5] = -1\n",
      "                ypredTrain[(ypredTrain!=1) & (ypredTrain!=-1)] = 0\n",
      "        else:\n",
      "            ypred = ytest.copy(); ypred[:] = 0\n",
      "            ypredTrain = ytrain.copy(); ypredTrain[:] = 0\n",
      "            ypred[(Xtest.a14>0) & (Xtest.D5>=0)] = 1\n",
      "            ypred[(Xtest.a14<0) & (Xtest.D4>=0)] = -1\n",
      "            ypredTrain[(Xtrain.a14>0) & (Xtrain.D5>=0)] = 1\n",
      "            ypredTrain[(Xtrain.a14<0) & (Xtrain.D4>=0)] = -1\n",
      "        \n",
      "        if (clf_class=='B'):\n",
      "            test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "            train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        else:\n",
      "            if (type(clf_class()) ==  type(RFR())):\n",
      "                plt.scatter(ytest,ypred)\n",
      "                test_cm += confusion_matrix(np.sign(ytest),np.sign(ypred),labels).astype(float)/n_folds\n",
      "                train_cm += confusion_matrix(np.sign(ytrain),np.sign(ypredTrain),labels).astype(float)/n_folds\n",
      "            else:\n",
      "                test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "                train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        \n",
      "    test_pr = Precision_Recall(test_cm, labels)\n",
      "    train_pr = Precision_Recall(train_cm, labels)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n",
      "def OneModelResults(clf_class, input,target,ERRORS,dates,datesDF,**kwargs):\n",
      "    import numpy\n",
      "    fig1 = plt.figure(figsize=(15, 5))\n",
      "    plt.clf()\n",
      "    ax1 = fig1.add_subplot(1,3,1)\n",
      "    trainError, testError, cm, clf, fscore = run_cv_proba(input,target,clf_class,30,1,dates,datesDF,**kwargs)\n",
      "    draw_confusion_matrix(cm,  numpy.sort(list(set(target))), fig1, ax1)\n",
      "    ERRORS.loc[ERRORS.shape[0]] =[str(clf_class).split('.')[-1].strip('>'),trainError,testError]\n",
      "    pr = Precision_Recall(cm,numpy.sort(list(set(target))))\n",
      "    cm2return=cm\n",
      "    print 'Precision - %s, Recall - %s, F_Score - %s' % (pr[0],pr[1],pr[2])\n",
      "\n",
      "    #if clf_class=='NN':\n",
      "    return cm2return\n",
      "    \n",
      "    #Show learning curves\n",
      "    TrainError=[]\n",
      "    TestError=[]\n",
      "    nDays = len(dates)\n",
      "    testRange = range(nDays-1)\n",
      "    for i in testRange: \n",
      "        trainError, testError, cm, clf, fscore = run_cv_proba(input,target,clf_class,5,i+1,dates,datesDF,**kwargs)\n",
      "        #print i,testError\n",
      "        TrainError.append(trainError)\n",
      "        TestError.append(testError)\n",
      "\n",
      "    LearningCurves = pd.DataFrame()\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index']+= 1\n",
      "    LearningCurves['TrainError'] = TrainError\n",
      "    LearningCurves['TestError'] = TestError\n",
      "    LearningCurves['Index'] = nDays-LearningCurves['Index']\n",
      "    LearningCurves = pd.melt(LearningCurves, id_vars = 'Index', value_vars = ['TestError','TrainError'])\n",
      "\n",
      "    g = ggplot(LearningCurves, aes('Index', 'value', color = 'variable')) + geom_step() + \\\n",
      "    ggtitle('Learning curves') + xlab(\"% of data sent to train\") + ylab(\"Error\")\n",
      "    \n",
      "    return g,cm2return\n",
      "\n",
      "def Regression(clf_class, input,target,dates,datesDF,side):\n",
      "    import numpy\n",
      "    trainError, testError = run_reg(input,target,clf_class,5,1,dates,datesDF,side)\n",
      "    print 'TrainError - %s, TestError - %s' % (trainError, testError)\n",
      "    #Show learning curves\n",
      "    TrainError=[]\n",
      "    TestError=[]\n",
      "    nDays = len(dates)\n",
      "    testRange = range(5,nDays/2-1)\n",
      "    for i in testRange: \n",
      "        trainError, testError = run_reg(input,target,clf_class,5,i+1,dates,datesDF,side)\n",
      "        TrainError.append(trainError)\n",
      "        TestError.append(testError)\n",
      "\n",
      "    LearningCurves = pd.DataFrame()\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index']+= 1\n",
      "    LearningCurves['TrainError'] = TrainError\n",
      "    LearningCurves['TestError'] = TestError\n",
      "    LearningCurves['Index'] = nDays-LearningCurves['Index']\n",
      "    LearningCurves = pd.melt(LearningCurves, id_vars = 'Index', value_vars = ['TestError','TrainError'])\n",
      "\n",
      "    g = ggplot(LearningCurves, aes('Index', 'value', color = 'variable')) + geom_step() + \\\n",
      "    ggtitle('Learning curves') + xlab(\"% of data sent to train\") + ylab(\"Error\")\n",
      "    \n",
      "    return g\n",
      "\n",
      "def GetNEstimators(clf_class, input,target,dates,datesDF,side):\n",
      "    TrainError=[]\n",
      "    TestError=[]\n",
      "    nDays = len(dates)\n",
      "    testRange = range(90)\n",
      "    \n",
      "    for i in testRange: \n",
      "        trainError, testError = run_reg_2(input,target,clf_class,1,nDays/10,dates,datesDF,side,i)\n",
      "        TrainError.append(trainError)\n",
      "        TestError.append(testError)\n",
      "\n",
      "    LearningCurves = pd.DataFrame()\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index']+= 1\n",
      "    LearningCurves['TrainError'] = TrainError\n",
      "    LearningCurves['TestError'] = TestError\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index'] = 100+LearningCurves['Index']*10\n",
      "    LearningCurves = pd.melt(LearningCurves, id_vars = 'Index', value_vars = ['TestError','TrainError'])\n",
      "\n",
      "    g = ggplot(LearningCurves, aes('Index', 'value', color = 'variable')) + geom_step() + \\\n",
      "    ggtitle('Learning curves') + xlab(\"% of data sent to train\") + ylab(\"Error\")\n",
      "    \n",
      "    return g\n",
      "\n",
      "def run_reg_2(X,y,clf_class,n_folds,test_size,dates,datesDF,side,nest):\n",
      "    import numpy\n",
      "    from sklearn import metrics\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import RandomForestRegressor as RFR\n",
      "    from sklearn.neighbors import KNeighborsRegressor as KNR\n",
      "    \n",
      "    X.index = range(X.shape[0])\n",
      "    y.index = range(y.shape[0])\n",
      "    \n",
      "    test_pr = 0.0;\n",
      "    train_pr = 0.0;\n",
      "    \n",
      "    for i in range(n_folds): \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "\n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "            \n",
      "        if side>0:\n",
      "            f1 = ytrain>0\n",
      "            f2 = ytest>0\n",
      "        else:\n",
      "            f1 = ytrain<0\n",
      "            f2 = ytest<0\n",
      "        \n",
      "        clf = clf_class(loss = 'huber',n_estimators=100+nest*10)\n",
      "\n",
      "        clf.fit(Xtrain[f1], ytrain[f1])\n",
      "\n",
      "        ypred = clf.predict(Xtest[f2])\n",
      "        ypredTrain = clf.predict(Xtrain[f1])\n",
      "\n",
      "        test_pr += metrics.r2_score(ytest[f2], ypred)/n_folds\n",
      "        train_pr += metrics.r2_score(ytrain[f1], ypredTrain)/n_folds\n",
      "    \n",
      "    return 1-train_pr, 1-test_pr\n",
      "\n",
      "def run_reg(X,y,clf_class,n_folds,test_size,dates,datesDF,side):\n",
      "    import numpy\n",
      "    from sklearn import metrics\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import RandomForestRegressor as RFR\n",
      "    from sklearn.neighbors import KNeighborsRegressor as KNR\n",
      "    \n",
      "    X.index = range(X.shape[0])\n",
      "    y.index = range(y.shape[0])\n",
      "    \n",
      "    test_pr = 0.0;\n",
      "    train_pr = 0.0;\n",
      "    \n",
      "    for i in range(n_folds): \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "\n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "            \n",
      "        if side>0:\n",
      "            f1 = ytrain>0\n",
      "            f2 = ytest>0\n",
      "        else:\n",
      "            f1 = ytrain<0\n",
      "            f2 = ytest<0\n",
      "        \n",
      "        if (clf_class!='COMB'):\n",
      "            if (type(clf_class()) ==  type(GBR())):\n",
      "                clf = clf_class(loss = 'huber')#learning_rate=0.1,\n",
      "            if (type(clf_class()) ==  type(KNR())):\n",
      "                clf = clf_class(weights = 'uniform',n_neighbors=20)\n",
      "            else:\n",
      "                clf = clf_class()\n",
      "\n",
      "            clf.fit(Xtrain[f1], ytrain[f1])\n",
      "\n",
      "            ypred = clf.predict(Xtest[f2])\n",
      "            ypredTrain = clf.predict(Xtrain[f1])\n",
      "        else:\n",
      "            clf1 = GBR(loss = 'huber',min_samples_split = ytrain[f1].shape[0]*0.05)\n",
      "            clf2 = RFR(min_samples_split = ytrain[f1].shape[0]*0.05)\n",
      "            clf1.fit(Xtrain[f1], ytrain[f1])\n",
      "            clf2.fit(Xtrain[f1], ytrain[f1])\n",
      "            \n",
      "            ypred = 0.5*(clf1.predict(Xtest[f2])+clf2.predict(Xtest[f2]))\n",
      "            ypredTrain =0.5*( clf1.predict(Xtrain[f1])+ clf2.predict(Xtrain[f1]))\n",
      "\n",
      "        test_pr += metrics.r2_score(ytest[f2], ypred)/n_folds\n",
      "        train_pr += metrics.r2_score(ytrain[f1], ypredTrain)/n_folds\n",
      "    \n",
      "    return 1-train_pr, 1-test_pr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_cvNN(X,y,n_folds,test_size,**kwargs):\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn import preprocessing\n",
      "    import neurolab as nl\n",
      "    \n",
      "    lb = preprocessing.LabelBinarizer()\n",
      "    lb.fit(y)\n",
      "    \n",
      "    labels =  sort(list(set(y)))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
      "        \n",
      "        input = scaler.transform(Xtrain)  \n",
      "        \n",
      "        net = nl.net.newff(nl.tool.minmax(input), **kwargs)\n",
      "        error = net.train(input, lb.transform(ytrain),show=500)\n",
      "        \n",
      "        ypred = lb.inverse_transform(net.sim(scaler.transform(Xtest)))\n",
      "        ypredTrain = lb.inverse_transform(net.sim(input))\n",
      "        \n",
      "        ypred = clf.predict(Xtest)\n",
      "        ypredTrain = clf.predict(Xtrain)\n",
      "\n",
      "        test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "        train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        \n",
      "    test_pr = Precision_Recall(test_cm)\n",
      "    train_pr = Precision_Recall(train_cm)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n",
      "\n",
      "def run_cvNN2(X,y,n_folds,threshold,test_size,**kwargs):\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn import preprocessing\n",
      "    import neurolab as nl\n",
      "    \n",
      "    lb = preprocessing.LabelBinarizer()\n",
      "    lb.fit(y)\n",
      "    \n",
      "    labels =  sort(list(set(y)))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
      "        \n",
      "        input = scaler.transform(Xtrain)  \n",
      "        \n",
      "        net = nl.net.newff(nl.tool.minmax(input), **kwargs)\n",
      "        error = net.train(input, ytrain.reshape(len(ytrain),1),show=500)\n",
      "        \n",
      "        ypred = net.sim(scaler.transform(Xtest)).flatten()\n",
      "        ypred[ypred>threshold] = 1\n",
      "        ypred[ypred<-threshold] = -1\n",
      "        ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "        \n",
      "        ypredTrain = net.sim(input).flatten()\n",
      "        ypredTrain[ypredTrain>threshold] = 1\n",
      "        ypredTrain[ypredTrain<-threshold] = -1\n",
      "        ypredTrain[(ypredTrain!=1) & (ypredTrain!=-1)] = 0\n",
      "        \n",
      "        test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "        train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        \n",
      "    test_pr = Precision_Recall(test_cm)\n",
      "    train_pr = Precision_Recall(train_cm)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_confusion_matrix(conf_arr, labels, fig, ax):  \n",
      "    #print conf_arr\n",
      "    conf_arr=conf_arr.astype(float)\n",
      "    \n",
      "    sums = conf_arr.sum(axis=0)\n",
      "    #print sums\n",
      "    for i in range(len(labels)):\n",
      "        conf_arr[:,i] /= sums[i]\n",
      "    #print conf_arr\n",
      "    #fig = plt.figure()\n",
      "    #plt.clf()\n",
      "    #ax = fig.add_subplot(111)\n",
      "    #ax.set_aspect(1)\n",
      "    res = ax.imshow(np.array(conf_arr), cmap=plt.cm.jet, interpolation='nearest')\n",
      "\n",
      "    width = len(conf_arr)\n",
      "    height = len(conf_arr[0])\n",
      "\n",
      "    for x in xrange(width):\n",
      "        for y in xrange(height):\n",
      "            ax.annotate(str(conf_arr[x][y])[:4], xy=(y, x), \n",
      "                        horizontalalignment='center',\n",
      "                        verticalalignment='center')\n",
      "\n",
      "    #cb = fig.colorbar(res)\n",
      "    plt.xticks(range(width), labels[:width])\n",
      "    plt.yticks(range(height), labels[:height])\n",
      "    #plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_signals1(imbalanceMsg,X,y,clf_class,dates,datesDF,**kwargs):  \n",
      "    import numpy\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    labels = numpy.sort(list(set(y)))\n",
      "    \n",
      "    Signals = imbalanceMsg[['Date','Timestamp','Symbol','Ask_P','Bid_P']]\n",
      "    Signals['Side'] = numpy.zeros((Signals.shape[0],1))\n",
      "    Signals['Price'] = Signals.Ask_P   \n",
      "    \n",
      "    \n",
      "    if clf_class!='B':\n",
      "        for i in range(int(datesDF.index.max())+1):  \n",
      "            train_days = range(len(dates))\n",
      "            test_days = i \n",
      "            train_days.remove(i)\n",
      "\n",
      "            Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "            Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "            ytrain = y.ix[datesDF.ix[train_days]]\n",
      "            ytest = y.ix[datesDF.ix[test_days]]\n",
      "               \n",
      "            if not kwargs.has_key('n_ensembles'):\n",
      "                \n",
      "                if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "                    clf = clf_class(class_weight='auto')\n",
      "                else:\n",
      "                    clf = clf_class(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05)\n",
      "                \n",
      "                clf.fit(Xtrain,ytrain)\n",
      "\n",
      "                Signals.Side[datesDF.ix[test_days]] = clf.predict(Xtest)\n",
      "            else:\n",
      "                n_ensembles = kwargs['n_ensembles']\n",
      "                test_size_ensemble = kwargs['test_size_ensemble']\n",
      "                \n",
      "                ypred = ytest.copy(); ypred[:] = 0\n",
      "                for j in range(n_ensembles):  \n",
      "                    Xtrain_sub, Xtest_sub, ytrain_sub, ytest_sub = train_test_split(Xtrain, ytrain, test_size=test_size_ensemble)\n",
      "\n",
      "                    if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "                        clf = clf_class(class_weight='auto')\n",
      "                    else:\n",
      "                        clf = clf_class(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05)\n",
      "                        \n",
      "                    clf.fit(Xtrain_sub,ytrain_sub)\n",
      "                    \n",
      "                    ypred += clf.predict(Xtest).astype(float)/n_ensembles\n",
      "\n",
      "\n",
      "                #Averaging of assemblies results\n",
      "                ypred[ypred>0.5] = 1\n",
      "                ypred[ypred<-0.5] = -1\n",
      "                ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "                \n",
      "\n",
      "                Signals.Side[datesDF.ix[test_days]] = ypred\n",
      "            \n",
      "            Signals.Side[(Signals.Side!=0) & (X.a14>0)] = 1\n",
      "            Signals.Side[(Signals.Side!=0) & (X.a14<0)] = -1\n",
      "    else:\n",
      "        ypred = y.copy(); ypred[:] = 0\n",
      "        ypred[(X.a14>0) & (X.D5>=0)] = 1\n",
      "        ypred[(X.a14<0) & (X.D4>=0)] = -1\n",
      "        Signals.Side = ypred\n",
      "        \n",
      "        \n",
      "    Signals.Price[Signals['Side']==1] = Signals.Ask_P[Signals['Side']==1]\n",
      "    Signals.Price[Signals['Side']==-1] = Signals.Bid_P[Signals['Side']==-1]\n",
      "    Signals = Signals[Signals.Side!=0]\n",
      "    Signals = Signals[['Date','Timestamp','Symbol','Price','Side']] \n",
      "    Signals.index = Signals.Timestamp\n",
      "    return Signals\n",
      "\n",
      "def get_signals_clf(imbalanceMsg,X,y,clf,dates,datesDF,**kwargs):  \n",
      "    import numpy\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    labels = numpy.sort(list(set(y)))\n",
      "    \n",
      "    Signals = imbalanceMsg[['Date','Timestamp','Symbol','Ask_P','Bid_P']]\n",
      "    Signals['Side'] = numpy.zeros((Signals.shape[0],1))\n",
      "    Signals['Price'] = Signals.Ask_P   \n",
      "                       \n",
      "    ypred = clf.predict(X).astype(float)\n",
      "\n",
      "    ypred[ypred>0.5] = 1\n",
      "    ypred[ypred<-0.5] = -1\n",
      "    ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "\n",
      "    Signals.Side = ypred      \n",
      "       \n",
      "    Signals.Price[Signals['Side']==1] = Signals.Ask_P[Signals['Side']==1]\n",
      "    Signals.Price[Signals['Side']==-1] = Signals.Bid_P[Signals['Side']==-1]\n",
      "    Signals = Signals[Signals.Side!=0]\n",
      "    Signals = Signals[['Date','Timestamp','Symbol','Price','Side']] \n",
      "    Signals.index = Signals.Timestamp\n",
      "    return Signals\n",
      "\n",
      "def get_signals_proba(imbalanceMsg,X,y,clf_class,dates,datesDF,**kwargs):  \n",
      "    import numpy\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    labels = numpy.sort(list(set(y)))\n",
      "    \n",
      "    Signals = imbalanceMsg[['Date','Timestamp','Symbol','Ask_P','Bid_P']]\n",
      "    Signals['Side'] = numpy.zeros((Signals.shape[0],1))\n",
      "    Signals['Price'] = Signals.Ask_P   \n",
      "    \n",
      "    for i in range(int(datesDF.index.max())+1):  \n",
      "        train_days = range(len(dates))\n",
      "        test_days = i \n",
      "        train_days.remove(i)\n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "                       \n",
      "        if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "            clf = clf_class(class_weight='auto')\n",
      "        else:\n",
      "            clf = clf_class(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05)\n",
      "                \n",
      "        clf.fit(Xtrain,ytrain)\n",
      "\n",
      "        Signals.Side[datesDF.ix[test_days]] = clf.classes_[numpy.argmax(clf.predict_proba(Xtest),axis=1)]\n",
      "              \n",
      "    #Signals.Side[Signals.Side==1] = 0\n",
      "    #Signals.Side[Signals.Side==-1] = 0\n",
      "    Signals.Side[Signals.Side>0] = 1\n",
      "    Signals.Side[Signals.Side<0] = -1\n",
      "    \n",
      "    Signals.Price[Signals['Side']==1] = Signals.Ask_P[Signals['Side']==1]\n",
      "    Signals.Price[Signals['Side']==-1] = Signals.Bid_P[Signals['Side']==-1]\n",
      "    Signals = Signals[Signals.Side!=0]\n",
      "    Signals = Signals[['Date','Timestamp','Symbol','Price','Side']] \n",
      "    Signals.index = Signals.Timestamp\n",
      "    return Signals\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_performance(Signals,df,days,add=0):\n",
      "    #days = sorted(list(set(Signals.index.date)))\n",
      "    \n",
      "    PNL=[]\n",
      "    NEGPNL=[]\n",
      "    SDict=dict()\n",
      "    for day in days:\n",
      "        dayPnl=[]\n",
      "        negdayPnl=[]\n",
      "        #print '----------------------------------'\n",
      "        #print day\n",
      "        #print '----------------------------------'\n",
      "        curr_day_signals = Signals[Signals.Date==day]\n",
      "        data = df[df.Date==day]\n",
      "        buys = curr_day_signals[curr_day_signals.Side==1]\n",
      "        buys = buys.sort(['Symbol'])\n",
      "        sells = curr_day_signals[curr_day_signals.Side==-1]\n",
      "        sells = sells.sort(['Symbol'])\n",
      "        \n",
      "        #endTimestamp = pd.Timestamp('09:30:01')\n",
      "        #print 'BUY'\n",
      "        for count, row in buys.iterrows():\n",
      "            symbol = row[2]\n",
      "            price = row[3]+add\n",
      "            curr_symbol_data=data[data.Symbol==symbol]#.between_time(startTimestamp,endTimestamp)\n",
      "\n",
      "            #AskPrices = dict()\n",
      "            #for i in range(curr_symbol_data.shape[0]):\n",
      "            #    if curr_symbol_data.Ask_P[i]>price: continue\n",
      "            #    if (not AskPrices.has_key(curr_symbol_data.Ask_P[i])):\n",
      "            #        AskPrices[curr_symbol_data.Ask_P[i]] = curr_symbol_data.Ask_S[i]\n",
      "                    \n",
      "            volumeTraded = 1#min(abs(curr_symbol_data.ImbShares[0]),curr_symbol_data.Ask_S[0]       \n",
      "            OPC = curr_symbol_data.tPrice[(curr_symbol_data.tType=='OPG')]\n",
      "            pnl = volumeTraded*(OPC.values[0]-price)    \n",
      "            dayPnl.append(pnl)\n",
      "            if pnl<0:\n",
      "                negdayPnl.append(pnl)\n",
      "            \n",
      "            #if pnl<0:\n",
      "            #    print ' BUY   %s %s shares at %s SELL at %s PNL %s' % ( symbol,volumeTraded,price,OPC.values[0],pnl)\n",
      "             \n",
      "        for count, row in sells.iterrows():\n",
      "            symbol = row[2]\n",
      "            price = row[3]-add\n",
      "            curr_symbol_data=data[data.Symbol==symbol]#.between_time(startTimestamp,endTimestamp)\n",
      "            \n",
      "            #BidPrices = dict()\n",
      "            #for i in range(curr_symbol_data.shape[0]):\n",
      "            #    if curr_symbol_data.Bid_P[i]<price: continue\n",
      "            #    if (not BidPrices.has_key(curr_symbol_data.Bid_P[i])):\n",
      "            #        BidPrices[curr_symbol_data.Bid_P[i]] = curr_symbol_data.Bid_S[i]\n",
      "            \n",
      "            volumeTraded = 1#min(abs(curr_symbol_data.ImbShares[0]),curr_symbol_data.Bid_S[0])\n",
      "            OPC = curr_symbol_data.tPrice[curr_symbol_data.tType=='OPG']\n",
      "            pnl = volumeTraded*(price-OPC.values[0])\n",
      "            dayPnl.append(pnl)\n",
      "            if pnl<0:\n",
      "                negdayPnl.append(pnl)\n",
      "                \n",
      "            #if pnl<0:\n",
      "            #    print ' SELL  %s %s shares at %s BUY as %s PNL %s' % ( symbol,volumeTraded,price,OPC.values[0],pnl)        \n",
      "            \n",
      "        PNL.append(np.sum(dayPnl))\n",
      "        NEGPNL.append(np.sum(negdayPnl))\n",
      "        print '%s %s' % (day,np.sum(dayPnl))\n",
      "      \n",
      "    result = pd.DataFrame()\n",
      "    result['Date'] = days\n",
      "    result['Pnl'] = PNL\n",
      "    print '%s %s' % (np.sum(NEGPNL),np.sum(PNL))\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Tree2Txt(clf,t,fileName):\n",
      "    f = open(fileName, 'w+')\n",
      "    f.write(str(t.n_classes[0])+'\\n');\n",
      "    f.write(str(t.n_features)+'\\n');\n",
      "    f.write(str(t.capacity)+'\\n');\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    if (type(clf) !=  type(GBR())):\n",
      "        for i in range(t.capacity):\n",
      "            s= '%d;%.19f;' % (t.feature[i],t.threshold[i])\n",
      "            if t.n_classes[0]==1:\n",
      "                s +='%s;' % str(t.value[i][0][0])\n",
      "            else:\n",
      "                for j in range(t.n_classes[0]):\n",
      "                    Sum = sum(t.value[i][0])\n",
      "                    if Sum>0:\n",
      "                        s +='%s;' %  str(t.value[i][0][j]/Sum)\n",
      "                    else:\n",
      "                         s +='%s;' % '0'\n",
      "            f.write(s+'\\n')\n",
      "    else:\n",
      "        for i in range(t.capacity):\n",
      "            s= '%d;%.19f;' % (t.feature[i],t.threshold[i])\n",
      "            s +='%s;' % str(t.value[i][0][0]*clf.learning_rate*clf.n_estimators)\n",
      "            f.write(s+'\\n')\n",
      "    f.close()\n",
      "    \n",
      "def Tree2Sql(clf,t,RFID,ID, datatypes,con):\n",
      "    data = np.zeros((t.capacity+3,7))\n",
      "    data[:,0] = RFID\n",
      "    data[:,1] = ID\n",
      "    dataID = datatypes[datatypes.Name=='data'].ID\n",
      "    data[3:,2] = dataID\n",
      "    \n",
      "    data[0,2:] = [datatypes[datatypes.Name=='n_classes'].ID,t.n_classes[0],0,0,0]\n",
      "    data[1,2:] = [datatypes[datatypes.Name=='n_features'].ID,t.n_features,0,0,0]\n",
      "    data[2,2:] = [datatypes[datatypes.Name=='capacity'].ID,t.capacity,0,0,0]\n",
      "    \n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    if (type(clf) !=  type(GBR())):\n",
      "        for i in range(t.capacity):\n",
      "            data[i+3,3] = i\n",
      "            data[i+3,4] = t.feature[i]\n",
      "            data[i+3,5] = t.threshold[i]\n",
      "            if t.n_classes[0]==1:\n",
      "                data[i+3,6] = t.value[i][0][0]\n",
      "            else:\n",
      "                Sum = sum(t.value[i][0])\n",
      "\n",
      "                if Sum>0:\n",
      "                    data[i+3,6] = t.value[i][0][0]/Sum\n",
      "                else:\n",
      "                    data[i+3,6] = 0 \n",
      "\n",
      "                if (data[i+3,6]>1):\n",
      "                    print data[i+3,6]\n",
      "    else:\n",
      "        for i in range(t.capacity):\n",
      "            data[i+3,3] = i\n",
      "            data[i+3,4] = t.feature[i]\n",
      "            data[i+3,5] = t.threshold[i]   \n",
      "            data[i+3,6] = t.value[i][0][0]*clf.learning_rate*clf.n_estimators\n",
      "    \n",
      "    df = pd.DataFrame(data,columns=['RFID','TreeID','DataTypeID','Ind','Feature','Threshold','Probability'])\n",
      "    df.to_sql('RFdata',con,index=False,if_exists='append')  \n",
      "    con.commit()\n",
      "    #return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def TreeTest2Txt(clf,X,fileName):\n",
      "    f = open(fileName, 'w+')\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
      "    if (type(clf) ==  type(GBR())):\n",
      "        proba = clf.predict(X)\n",
      "        for i in range(X.shape[0]):\n",
      "            s= ''\n",
      "            for j in range(X.shape[1]):\n",
      "                s +='%s;' %  str(X.ix[i,j])\n",
      "            s +='%s;' %  str(proba[i])\n",
      "            f.write(s+'\\n')\n",
      "        f.close()\n",
      "        return\n",
      "    \n",
      "    if (type(clf) ==  type(GBC())):\n",
      "        proba = clf.predict_proba(X)\n",
      "        for i in range(X.shape[0]):\n",
      "            s= ''\n",
      "            for j in range(X.shape[1]):\n",
      "                s +='%s;' %  str(X.ix[i,j])\n",
      "            for j in range(proba.shape[1]):\n",
      "                s +='%s;' %  str(proba[i,j])\n",
      "            f.write(s+'\\n')\n",
      "        f.close()\n",
      "        return\n",
      "\n",
      "    #regression\n",
      "    if (clf.estimators_[0].tree_.n_classes[0]==1):\n",
      "        proba = clf.predict(X)\n",
      "        for i in range(X.shape[0]):\n",
      "            s= ''\n",
      "            for j in range(X.shape[1]):\n",
      "                s +='%s;' %  str(X.ix[i,j])\n",
      "            s +='%s;' %  str(proba[i])\n",
      "            f.write(s+'\\n')\n",
      "        f.close()\n",
      "        return\n",
      "    \n",
      "    #classification\n",
      "    proba = clf.predict_proba(X)\n",
      "    for i in range(X.shape[0]):\n",
      "        s= ''\n",
      "        for j in range(X.shape[1]):\n",
      "            s +='%s;' %  str(X.ix[i,j])\n",
      "        for j in range(proba.shape[1]):\n",
      "            s +='%s;' %  str(proba[i,j])\n",
      "        f.write(s+'\\n')\n",
      "    f.close()\n",
      "    return\n",
      "\n",
      "def TreeTest2Sql(clf,X,RFID,Type,Side,con):\n",
      "    if (Type==0):\n",
      "        proba = clf.predict_proba(X)\n",
      "        df = pd.DataFrame(proba[:,0], columns = ['Probability'])\n",
      "    else:\n",
      "        proba = clf.predict(X)\n",
      "        df = pd.DataFrame(proba, columns = ['Probability'])\n",
      "    df[\"RFID\"] = RFID\n",
      "    df[\"Side\"] = Side\n",
      "    df[\"Ind\"] = range(X.shape[0])\n",
      "    df.to_sql('TestResults',con,index=False,if_exists='append')\n",
      "    con.commit()\n",
      "    \n",
      "def TestData2Sql(side,X,y,db):\n",
      "    import sqlite3 as lite\n",
      "    import sys\n",
      "        \n",
      "    con = None\n",
      "    \n",
      "    try:\n",
      "        con = lite.connect(db, timeout=10)\n",
      "        cur = con.cursor()    \n",
      "        cur.execute('SELECT SQLITE_VERSION()')\n",
      "        con.commit()\n",
      "        data = cur.fetchone()\n",
      "        print \"SQLite version: %s\" % data  \n",
      "        \n",
      "    except lite.Error, e:\n",
      "        print \"Error %s:\" % e.args[0]\n",
      "        con.close()\n",
      "        return     \n",
      "        \n",
      "    df = X.copy()\n",
      "    df.columns = ['F0','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12','F13','F14','F15','F16','F17']\n",
      "    df[\"Side\"] = side\n",
      "    df[\"YSide\"] = 0\n",
      "    df.YSide[y>0] = 1\n",
      "    df.YSide[y<0] = -1\n",
      "    df[\"Ind\"] = range(df.shape[0])\n",
      "    df[\"IndPos\"] = -1\n",
      "    df[\"IndNeg\"] = -1\n",
      "    df.IndPos[(df.Side==1)  & (df.YSide==-1)] = range(df.YSide[(df.Side==1)  & (df.YSide==-1)].shape[0])\n",
      "    df.IndNeg[(df.Side==-1) & (df.YSide==-1)] = range(df.YSide[(df.Side==-1) & (df.YSide==-1)].shape[0])\n",
      "    df.to_sql('TestFeatures',con,index=False,if_exists='append')\n",
      "    con.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Forest2Txt(clf,X,Dir):\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
      "    if ((type(clf) ==  type(GBR())) | (type(clf) ==  type(GBC()))):\n",
      "        for i in range(clf.n_estimators):\n",
      "            Tree2Txt(clf,clf.estimators_[i][0].tree_,Dir + '/%u.t' % i)\n",
      "    else:\n",
      "        for i in range(clf.n_estimators):\n",
      "            Tree2Txt(clf,clf.estimators_[i].tree_,Dir + '/%u.t' % i)\n",
      "    TreeTest2Txt(clf,X,Dir + '/test.u')\n",
      "    \n",
      "def Forest2Sql(clf,X,Type,Side,Advantage,Precision,db):\n",
      "    #Create connection\n",
      "    import sqlite3 as lite\n",
      "    import sys\n",
      "    import pandas as pd\n",
      "    import time\n",
      "        \n",
      "    con = None\n",
      "    \n",
      "    try:\n",
      "        con = lite.connect(db, timeout=10)\n",
      "        cur = con.cursor()    \n",
      "        cur.execute('SELECT SQLITE_VERSION()')\n",
      "        con.commit()\n",
      "        data = cur.fetchone()\n",
      "        print \"SQLite version: %s\" % data  \n",
      "        \n",
      "    except lite.Error, e:\n",
      "        print \"Error %s:\" % e.args[0]\n",
      "        con.close()\n",
      "        return     \n",
      "        \n",
      "    #Clear data for this RF\n",
      "    datatypes = pd.read_sql(\"SELECT * FROM RFdatatypes\", con)\n",
      "    con.commit()\n",
      "\n",
      "    df = pd.read_sql(\"SELECT * FROM RFnames\", con)\n",
      "    con.commit()\n",
      "      \n",
      "    if df.shape[0]>0:\n",
      "        RFID = df.ID.max()+1\n",
      "    else: \n",
      "        RFID = 0\n",
      "        \n",
      "    df = pd.DataFrame(columns=['ID','Type','Side','NTrees','Advantage'])\n",
      "    \n",
      "    #regression\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
      "    if (type(clf) ==  type(GBR())):\n",
      "        Type = 1\n",
      "        Advantage = 0\n",
      "    else:\n",
      "        if (clf.estimators_[0].tree_.n_classes[0]==1):\n",
      "            Type = 1\n",
      "            Advantage = 0\n",
      "        #classification\n",
      "        else:\n",
      "            Type = 0\n",
      "    \n",
      "    df = df.append({'ID':RFID,'Type':Type,'Side':Side,'NTrees':clf.n_estimators,'Advantage':Advantage,'Precision':Precision},ignore_index=True) \n",
      "    df.to_sql('RFnames',con,index=False,if_exists='append')\n",
      "    con.commit()\n",
      "        \n",
      "    #Write RF data \n",
      "    if ((type(clf) ==  type(GBR())) | (type(clf) ==  type(GBC()))):\n",
      "        for i in range(clf.n_estimators):\n",
      "            Tree2Sql(clf,clf.estimators_[i][0].tree_,RFID, i,datatypes,con)\n",
      "    else:\n",
      "        for i in range(clf.n_estimators):\n",
      "            Tree2Sql(clf,clf.estimators_[i].tree_,RFID, i, datatypes,con)\n",
      "    \n",
      "    TreeTest2Sql(clf,X,RFID,Type,Side,con)\n",
      "    \n",
      "    con.commit()\n",
      "    con.close()   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def DropDB(db):\n",
      "    import sqlite3 as lite\n",
      "    import sys\n",
      "        \n",
      "    con = None\n",
      "    \n",
      "    try:\n",
      "        con = lite.connect(db, timeout=10)\n",
      "        cur = con.cursor()    \n",
      "        cur.execute('SELECT SQLITE_VERSION()')\n",
      "        con.commit()\n",
      "        data = cur.fetchone()\n",
      "        print \"SQLite version: %s\" % data  \n",
      "        \n",
      "    except lite.Error, e:\n",
      "        print \"Error %s:\" % e.args[0]\n",
      "        con.close()\n",
      "        return     \n",
      "    \n",
      "    cur = con.execute(\"DELETE FROM RFdata\")\n",
      "    con.commit()\n",
      "    cur = con.execute(\"DELETE FROM RFnames\")\n",
      "    con.commit()\n",
      "    cur = con.execute(\"DELETE FROM TestFeatures\")\n",
      "    con.commit()\n",
      "    cur = con.execute(\"DELETE FROM TestResults\")\n",
      "    con.commit()\n",
      "    con.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def visualize_tree(clf):\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    if (type(clf) !=  type(GBR())):\n",
      "        t=clf.estimators_[9].tree_\n",
      "    else:\n",
      "        t=clf.estimators_[9][0].tree_\n",
      "    from sklearn.externals.six import StringIO  \n",
      "    import pydot\n",
      "    from sklearn import tree\n",
      "    out = StringIO() \n",
      "    tree.export_graphviz(t, out_file=out) \n",
      "    #print out.getvalue()\n",
      "    graph = pydot.graph_from_dot_data(out.getvalue()) \n",
      "    graph.write_pdf(\"t.pdf\") "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_featuresCumulative(df,nImb):\n",
      "    import pandas as pd\n",
      "    import numpy \n",
      "    \n",
      "    stocks = set(df.Symbol)\n",
      "    dates = set(df.Date)\n",
      "    \n",
      "    #fdf = pd.DataFrame(columns=['Ask','AskD','Near','Far','Spread',\n",
      "    #'D5', 'D555', 'D66', 'V1','V1n', 'V11', 'V11n',\n",
      "    #'V8','V8n','V8nn', 'a1','a4','a5','a14','y'])\n",
      "    \n",
      "    fdf = numpy.zeros((len(stocks)*len(dates),20))\n",
      "    \n",
      "    n = 0\n",
      "    for date in dates:\n",
      "        print date\n",
      "        for stock in stocks:\n",
      "            \n",
      "            #if (n>10):\n",
      "            #   return fdf  \n",
      "            \n",
      "            #print stock\n",
      "            \n",
      "            stockData = df[(df.Symbol==stock) & (df.Date==date)]\n",
      "    \n",
      "            closeP = np.array(stockData[stockData.tSide=='YDAY'].tPrice)\n",
      "            if (len(closeP)==0):\n",
      "                continue;\n",
      "            else:\n",
      "                closeP = closeP[0]\n",
      "            \n",
      "            openP = np.array(stockData[stockData.Reason=='OPG'].tPrice)\n",
      "            if (len(openP)==0):\n",
      "                continue;\n",
      "            else:\n",
      "                openP = openP[0]\n",
      "            \n",
      "            if (closeP==0):  \n",
      "                continue;\n",
      "            if (openP==0):   \n",
      "                continue;\n",
      "\n",
      "            bid = np.array(stockData[stockData.Reason=='Imbalance'].Bid_P)\n",
      "            if (len(bid)!=24):\n",
      "                if (len(bid)!=0):\n",
      "                    print stock, len(bid)\n",
      "                continue;\n",
      "                                \n",
      "            ask = np.array(stockData[stockData.Reason=='Imbalance'].Ask_P)    \n",
      "            midP = 0.5*(bid + ask)\n",
      "            spread = ask - bid\n",
      "            bidS = np.array(stockData[stockData.Reason=='Imbalance'].Bid_S)\n",
      "            askS = np.array(stockData[stockData.Reason=='Imbalance'].Ask_S)  \n",
      "            spreadS = askS - bidS\n",
      "            midS = 0.5*(bidS + askS)\n",
      "\n",
      "            ref = np.array(stockData[stockData.Reason=='Imbalance'].ImbRef)  \n",
      "            near = np.array(stockData[stockData.Reason=='Imbalance'].ImbCBC)  \n",
      "            far = np.array(stockData[stockData.Reason=='Imbalance'].ImbFar) \n",
      "            \n",
      "            imbShares = np.array(stockData[stockData.Reason=='Imbalance'].ImbShares)  \n",
      "            imbPaired = np.array(stockData[stockData.Reason=='Imbalance'].ImbPaired)  \n",
      "            #====================================================================\n",
      "            #Creating features\n",
      "            #====================================================================\n",
      "            \n",
      "            if (ref[nImb]<=0):                  continue;\n",
      "            if (near[nImb]<=0):                  continue;   \n",
      "            if (far[nImb]<=0):                  continue;  \n",
      "            if (ask[nImb]<=0):                  continue;    \n",
      "            if (bid[nImb]<=0):                  continue;    \n",
      "    \n",
      "            \n",
      "            tmpBid = bid[nImb]/ref[nImb]-1\n",
      "               \n",
      "            tmpAsk = ask[nImb]/ref[nImb]-1   \n",
      "\n",
      "            #fdf['BidD'] = bid-ref\n",
      "\n",
      "            tmpAskD = ask[nImb] - ref[nImb]   \n",
      "\n",
      "            tmpa1 = tmpBid*tmpAsk        \n",
      "\n",
      "            tmpNear = near[nImb]/ref[nImb]-1\n",
      "\n",
      "            tmpFar = far[nImb]/ref[nImb]-1\n",
      "\n",
      "            #fdf['PrevCLC'] = closeP/ref-1\n",
      "\n",
      "            tmpSpread = spread[nImb]/ref[nImb]\n",
      "\n",
      "            #fdf['D3'] = 100*(midP/closeP-1)\n",
      "\n",
      "            tmpD4 = 100*(bid[nImb]-ref[nImb])/closeP\n",
      "\n",
      "            tmpD5 = 100*(ref[nImb]-ask[nImb])/closeP\n",
      "\n",
      "            tmpD444 = (bid[nImb]-ref[nImb])/(1+spread[nImb])\n",
      "\n",
      "            tmpD555 = (ref[nImb]-ask[nImb])/(1+spread[nImb])\n",
      "\n",
      "            #fdf['D7'] = 100*(ref/closeP-1)\n",
      "\n",
      "            tmpD66 = 100*(ref[nImb]/midP[nImb]-1)\n",
      "\n",
      "            tmpV1 = numpy.sign(imbShares[nImb])*\\\n",
      "            (askS[nImb] - bidS[nImb])/(100+np.abs(imbShares[nImb]))\n",
      "\n",
      "            tmpV1n = numpy.sign(imbShares[nImb])*spreadS[nImb]/(midS[nImb]+np.abs(imbShares[nImb]))\n",
      "\n",
      "            tmpV11 = numpy.sign(imbShares[nImb])*spreadS[nImb]/(100+imbPaired[nImb])\n",
      "\n",
      "            tmpV11n =numpy.sign(imbShares[nImb])*spreadS[nImb]/(midS[nImb]+imbPaired[nImb])\n",
      "\n",
      "            tmpV8 = imbShares[nImb]/(100+imbPaired[nImb])\n",
      "\n",
      "            tmpV8n = imbShares[nImb]/(midS[nImb]+imbPaired[nImb])\n",
      "\n",
      "            tmpV8nn = (imbShares[nImb]-spreadS[nImb])/(midS[nImb]+imbPaired[nImb])\n",
      "\n",
      "            #fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "\n",
      "            tmpa4 = tmpD5*tmpD4\n",
      "\n",
      "            tmpa5 = tmpD444*tmpD555\n",
      "\n",
      "            #fdf['a6'] = fdf['D444']*fdf['D444']\n",
      "\n",
      "            #fdf['a7'] = fdf['D555']*fdf['D555']\n",
      "\n",
      "            tmpa14 = np.sign(imbShares[nImb])\n",
      "        \n",
      "            if (imbShares[nImb]>0):\n",
      "                tmpy = openP>ask[nImb]\n",
      "            else:\n",
      "                if (imbShares[nImb]<0):\n",
      "                    tmpy = openP<bid[nImb]\n",
      "                else:\n",
      "                    if (imbShares[nImb]==0):\n",
      "                        tmpy = 0\n",
      "        \n",
      "            fdf[n,:] = [tmpAsk,tmpAskD,tmpNear,tmpFar,tmpSpread,\\\n",
      "                        tmpD5,tmpD555,tmpD66,tmpV1,tmpV1n,\\\n",
      "                        tmpV11,tmpV11n,tmpV8,tmpV8n,tmpV8nn,\\\n",
      "                        tmpa1,tmpa4,tmpa5,tmpa14,tmpy]\n",
      "            \n",
      "            n+=1\n",
      "        \n",
      "            # &\n",
      "            #(imbalanceMsg.Ask_P - imbalanceMsg.Bid_P < \n",
      "            # 1.0 * (imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)*0.5) &\n",
      "            #(imbShares!=0)\n",
      "                \n",
      "            #X_pos=X_pos[['Ask','AskD','Near','Far','Spread',\n",
      "            # 'D5', 'D555', 'D66', 'V1','V1n', 'V11', 'V11n',\n",
      "            # 'V8','V8n','V8nn', 'a1','a4','a5']]\n",
      "            \n",
      "        return fdf[:n,:]   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_featuresCumulative2(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "\n",
      "    midP = 0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)\n",
      "    bid = imbalanceMsg.Bid_P\n",
      "    bidS = imbalanceMsg.Bid_S   \n",
      "    ref = imbalanceMsg.ImbRef\n",
      "    ask = imbalanceMsg.Ask_P\n",
      "    askS = imbalanceMsg.Ask_S\n",
      "    near = imbalanceMsg.ImbCBC\n",
      "    far = imbalanceMsg.ImbFar\n",
      "    closeP = imbalanceMsg.PrevCLC_P\n",
      "    \n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.Move\n",
      "    \n",
      "    fdf['Pnl'] = imbalanceMsg.OPC_P/imbalanceMsg.ImbRef-1\n",
      "    \n",
      "    fdf['MoveR'] = (imbalanceMsg.OPC_P>imbalanceMsg.ImbRef)*(imbalanceMsg.ImbShares>0)+\\\n",
      "     (imbalanceMsg.OPC_P<imbalanceMsg.ImbRef)*(imbalanceMsg.ImbShares<0)     \n",
      "    \n",
      "    fdf['CMoveR'] = imbalanceMsg.Move\n",
      "    fdf.CMoveR = 0\n",
      "    fdf.CMoveR[(imbalanceMsg.ImbShares>0) & (imbalanceMsg.OPC_P>imbalanceMsg.ImbRef)] = 2\n",
      "    fdf.CMoveR[(imbalanceMsg.ImbShares>0) & (imbalanceMsg.OPC_P<=imbalanceMsg.ImbRef)\\\n",
      "              & (imbalanceMsg.OPC_P>=imbalanceMsg.Ask_P)] = 1\n",
      "    fdf.CMoveR[(imbalanceMsg.ImbShares<0) & (imbalanceMsg.OPC_P<imbalanceMsg.ImbRef)] = -2\n",
      "    fdf.CMoveR[(imbalanceMsg.ImbShares<0) & (imbalanceMsg.OPC_P>=imbalanceMsg.ImbRef)\\\n",
      "              & (imbalanceMsg.OPC_P<=imbalanceMsg.Bid_P)] = -1   \n",
      "    \n",
      "    fdf['CMove'] = imbalanceMsg.Move\n",
      "    fdf.CMove = 0\n",
      "    fdf.CMove[imbalanceMsg.OPC_P-imbalanceMsg.Ask_P>0.1] = 2\n",
      "    fdf.CMove[(imbalanceMsg.OPC_P-imbalanceMsg.Ask_P>0)\n",
      "              & (imbalanceMsg.OPC_P-imbalanceMsg.Ask_P<=0.1)] = 1\n",
      "    fdf.CMove[(imbalanceMsg.Bid_P-imbalanceMsg.OPC_P>0.1)] = -2\n",
      "    fdf.CMove[(imbalanceMsg.Bid_P-imbalanceMsg.OPC_P>0)\n",
      "              & (imbalanceMsg.Bid_P-imbalanceMsg.OPC_P<=0.1)] = -1           \n",
      "        \n",
      "    fdf['Bid'] = bid/ref-1\n",
      "    \n",
      "    fdf['Ask'] = ask/ref-1   \n",
      "        \n",
      "    fdf['BidD'] = bid-ref\n",
      "    \n",
      "    fdf['AskD'] = ask - ref    \n",
      "    \n",
      "    fdf['a1'] = fdf['Bid']*fdf['Ask']        \n",
      "       \n",
      "    fdf['Near'] = near/ref-1\n",
      "    \n",
      "    fdf['Far'] = far/ref-1\n",
      "        \n",
      "    fdf['PrevCLC'] = closeP/ref-1\n",
      "    \n",
      "    fdf['Spread'] = (ask - bid)/ref\n",
      "\n",
      "    fdf['D3'] = 100*(midP/closeP-1)\n",
      "    \n",
      "    fdf['D4'] = 100*(bid-ref)/closeP\n",
      "\n",
      "    fdf['D5'] = 100*(ref-ask)/closeP\n",
      "    \n",
      "    fdf['D444'] = (bid-ref)/(1+ask - bid)\n",
      "\n",
      "    fdf['D555'] = (ref-ask)/(1+ask - bid)\n",
      "    \n",
      "    fdf['D7'] = 100*(ref/closeP-1)\n",
      "    \n",
      "    fdf['D66'] = 100*(ref/midP-1)\n",
      "\n",
      "    fdf['V1'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/(100+np.abs(imbalanceMsg.ImbShares))\n",
      "    \n",
      "    fdf['V1n'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/((askS + bidS)/2+np.abs(imbalanceMsg.ImbShares))\n",
      "    \n",
      "    fdf['V11'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/(100+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V11n'] =numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V8'] = imbalanceMsg.ImbShares/(100+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V8n'] = imbalanceMsg.ImbShares/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V8nn'] = (imbalanceMsg.ImbShares-(askS - bidS))/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "         \n",
      "    fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "    \n",
      "    fdf['a4'] = fdf['D5']*fdf['D4']\n",
      "    \n",
      "    fdf['a5'] = fdf['D444']*fdf['D555']\n",
      "    \n",
      "    fdf['a6'] = fdf['D444']*fdf['D444']\n",
      "    \n",
      "    fdf['a7'] = fdf['D555']*fdf['D555']\n",
      "            \n",
      "    fdf['a14'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createFeatures34(fdf):\n",
      "    import itertools\n",
      "    initNumFeatures = fdf.shape[1]\n",
      "    diffsInd = [x for x in itertools.combinations(range(initNumFeatures),2)]\n",
      "    d_fdf = pd.DataFrame()\n",
      "    for i in range(len(diffsInd)):\n",
      "        #print i, diffsInd[i]\n",
      "        d_fdf[\"d\"+str(i)] = fdf.ix[:,diffsInd[i][0]]-fdf.ix[:,diffsInd[i][1]]\n",
      "    return d_fdf\n",
      "def createFeatures35(X_pos):\n",
      "    dfdf=createFeatures34(X_pos)\n",
      "    df=pd.DataFrame()\n",
      "    for i in range(X_pos.shape[1]):\n",
      "        for j in range(dfdf.shape[1]):\n",
      "            tmp=X_pos.ix[:,i]\n",
      "            tmp.ix[tmp.ix[:]==0]=1\n",
      "            df[str(j)+str(i)]=dfdf.ix[:,j]/X_pos.ix[:,i]\n",
      "    return pd.concat([dfdf,df], axis=1)\n",
      "\n",
      "def createFeaturesBench(X_pos):\n",
      "    X_pos_Benchmark = pd.DataFrame()\n",
      "    X_pos_Benchmark['Ask'] = X_pos.Ask/X_pos.Ref-1\n",
      "    X_pos_Benchmark['Bid'] = X_pos.Bid/X_pos.Ref-1\n",
      "    X_pos_Benchmark['AskD'] = X_pos.Ask-X_pos.Ref\n",
      "    X_pos_Benchmark['Near'] = X_pos.Near/X_pos.Ref-1\n",
      "    X_pos_Benchmark['Far'] = X_pos.Far/X_pos.Ref-1\n",
      "    X_pos_Benchmark['Spread'] = X_pos.Ask-X_pos.Bid\n",
      "    X_pos_Benchmark['D4'] = 100*(X_pos.Bid-X_pos.Ref)/X_pos.CloseP\n",
      "    X_pos_Benchmark['D5'] = 100*(X_pos.Ref-X_pos.Ask)/X_pos.CloseP\n",
      "\n",
      "    X_pos_Benchmark['D444'] = (X_pos.Bid-X_pos.Ref)/(1+X_pos_Benchmark['Spread'])\n",
      "    X_pos_Benchmark['D555'] = (X_pos.Ref-X_pos.Ask)/(1+X_pos_Benchmark['Spread'])\n",
      "    X_pos_Benchmark['D66'] = 100*(X_pos.Ref/(0.5*(X_pos.Ask+X_pos.Bid))-1)\n",
      "    X_pos_Benchmark['a1'] = X_pos_Benchmark['Ask']*X_pos_Benchmark['Bid']\n",
      "    X_pos_Benchmark['a4'] = X_pos_Benchmark['D4']*X_pos_Benchmark['D5']\n",
      "    X_pos_Benchmark['a5'] = X_pos_Benchmark['D444']*X_pos_Benchmark['D555']\n",
      "    \n",
      "    X_pos_Benchmark['Spy1'] = (X_pos.BidSPY+X_pos.AskSPY)/X_pos.ClosePSPY\n",
      "    X_pos_Benchmark['Spy1'] /= (X_pos.Bid+X_pos.Ask)/X_pos.CloseP  \n",
      "    #X_pos_Benchmark['Spy1'] /= (X_pos.Bid-X_pos.Ask)\n",
      "    #X_pos_Benchmark['Spy1'] *= (X_pos.BidSPY-X_pos.AskSPY)\n",
      "\n",
      "    return X_pos_Benchmark\n",
      "\n",
      "def autocreateFeatures(X_pos,y_pos,ind):\n",
      "    from sklearn.ensemble import RandomForestClassifier as RF\n",
      "    clf = RF(min_samples_split = X_pos.shape[0]*0.05, criterion = 'entropy',n_estimators =10)\n",
      "    if ind==1:\n",
      "        newX_pos=createFeatures35(X_pos)\n",
      "    else:\n",
      "        newX_pos=createFeatures34(X_pos)\n",
      "    \n",
      "    clf.fit(newX_pos,y_pos)\n",
      "\n",
      "    fi = pd.DataFrame()\n",
      "    fi['Feature'] = list(newX_pos.columns)\n",
      "    fi['Impotrance'] = clf.feature_importances_\n",
      "    fi=fi.sort(columns=['Impotrance'],ascending=False)\n",
      "    fi['Index'] = range(newX_pos.shape[1])\n",
      "    fi.index = fi['Index']\n",
      "\n",
      "    for i in range(fi.shape[0]):\n",
      "        if (fi['Impotrance'][i]<0.005):\n",
      "            break\n",
      "        #print fi['Feature'][i]\n",
      "\n",
      "    newX_pos = newX_pos[fi['Feature'][:i]]\n",
      "\n",
      "    #Stage 2\n",
      "    poly = PolynomialFeatures(2)\n",
      "    newX_pos_2=pd.DataFrame(poly.fit_transform(newX_pos))\n",
      "    clf.fit(newX_pos_2,y_pos)\n",
      "\n",
      "    fi = pd.DataFrame()\n",
      "    fi['Feature'] = list(newX_pos_2.columns)\n",
      "    fi['Impotrance'] = clf.feature_importances_\n",
      "    fi=fi.sort(columns=['Impotrance'],ascending=False)\n",
      "    fi['Index'] = range(newX_pos_2.shape[1])\n",
      "    fi.index = fi['Index']\n",
      "\n",
      "    for i in range(fi.shape[0]):\n",
      "        if (fi['Impotrance'][i]<0.01):\n",
      "            break\n",
      "        #print fi['Feature'][i]\n",
      "\n",
      "    newX_pos_2 = newX_pos_2[fi['Feature'][:i]]\n",
      "\n",
      "    return newX_pos_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}