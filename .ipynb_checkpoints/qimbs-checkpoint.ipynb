{
 "metadata": {
  "name": "",
  "signature": "sha256:d86394758b59d18792cd18c5cf70b0530973d8b219e08c02610bde25fd3d6d00"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import datetime\n",
      "from ggplot import *\n",
      "from itertools import combinations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def import_month(month):\n",
      "    import os.path\n",
      "    df=pd.DataFrame()\n",
      "    \n",
      "    if month<10:\n",
      "        m = '0%s' % month\n",
      "    else:\n",
      "        m = '%s' % month\n",
      "    \n",
      "    #Read data for the month\n",
      "    for i in range (1,32):  \n",
      "        if i<10:\n",
      "            d = '0%s' % i\n",
      "        else:\n",
      "            d = '%s' % i\n",
      "        \n",
      "        f = '/home/user1/PyProjects/data_old/2014-%s-%s/CommonAggr_2014-%s-%s.csv' % (m,d,m,d)\n",
      "        \n",
      "        if (not os.path.isfile(f)): continue\n",
      "            \n",
      "        if (df.shape[0]==0):\n",
      "            df = pd.read_csv(f, low_memory=False)\n",
      "        else:\n",
      "            df=df.append(pd.read_csv(f, low_memory=False))\n",
      "    \n",
      "    #Set target columns\n",
      "    target_cols = ['Date','Time','Fracs','Symbol','Reason','tSide','tPrice','tShares',\n",
      "                    'Bid_P', 'Bid_S', 'Ask_P', 'Ask_S', \n",
      "                    'ImbRef','ImbCBC', 'ImbFar', 'ImbShares', 'ImbPaired']\n",
      "\n",
      "    #Get target columts from the data\n",
      "    df = df[target_cols]\n",
      "    df.index = range(df.shape[0])\n",
      "    \n",
      "    return df\n",
      "\n",
      "def import_month2(month):\n",
      "    import os.path\n",
      "    df=pd.DataFrame()\n",
      "    \n",
      "    if month<10:\n",
      "        m = '0%s' % month\n",
      "    else:\n",
      "        m = '%s' % month\n",
      "    \n",
      "    #Read data for the month\n",
      "    for i in range (1,32):  \n",
      "        if i<10:\n",
      "            d = '0%s' % i\n",
      "        else:\n",
      "            d = '%s' % i\n",
      "        \n",
      "        f = '/home/user1/PyProjects/data/AggrCommon_2014-%s-%s.csv' % (m,d)\n",
      "        \n",
      "        if (not os.path.isfile(f)): continue\n",
      "            \n",
      "        if (df.shape[0]==0):\n",
      "            df = pd.read_csv(f, low_memory=False)\n",
      "        else:\n",
      "            df=df.append(pd.read_csv(f, low_memory=False))\n",
      "    \n",
      "    #Set target columns\n",
      "    target_cols = ['Date','Time','Fracs','Symbol','Reason','tType','tVenue','tSide','tPrice','tShares',\n",
      "                    'Bid_P', 'Bid_S', 'Ask_P', 'Ask_S', 'nsdq_BP', 'nsdq_BS', 'nsdq_AP', 'nsdq_AS',\n",
      "                    'ImbRef','ImbCBC', 'ImbFar', 'ImbShares', 'ImbPaired', 'Bid2', 'Ask2']\n",
      "\n",
      "    #Get target columts from the data\n",
      "    df = df[target_cols]\n",
      "    df.index = range(df.shape[0])\n",
      "    \n",
      "    return df\n",
      "\n",
      "def import_file(f):\n",
      "    df = pd.read_csv('/home/user1/PyProjects/data/' + f, low_memory=False)\n",
      "    target_cols = ['Date','Time','Fracs','Symbol','Reason','tSide','tPrice','tShares',\n",
      "                    'Bid_P', 'Bid_S', 'Ask_P', 'Ask_S', \n",
      "                    'ImbRef','ImbCBC', 'ImbFar', 'ImbShares', 'ImbPaired']\n",
      "\n",
      "    df = df[target_cols]\n",
      "    df.index = range(df.shape[0])\n",
      "    \n",
      "    return df\n",
      "  \n",
      "def create_timestamp(df):\n",
      "    Timestamp = []\n",
      "    for i in range(df.shape[0]):\n",
      "        Timestamp.append(datetime.datetime.strptime(df.Date[i] +' '+df.Time[i]+' '+df.Fracs[i][0:3]+df.Fracs[i][4:7],'%Y-%m-%d %H:%M:%S %f'))\n",
      "\n",
      "    df['Timestamp'] = Timestamp\n",
      "    df = df.set_index(['Timestamp'])\n",
      "    df = df.drop(['Date','Time','Fracs'],1)\n",
      "    \n",
      "    return df\n",
      "\n",
      "def sigmoid(x):\n",
      "    import numpy\n",
      "    return 1/(1+numpy.exp(-x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Visualization of features\n",
      "from sklearn import preprocessing\n",
      "def visualize(fdf,Features,f,binwidth,scaled):\n",
      "    fdf_new = fdf.copy()\n",
      "    if scaled:\n",
      "        fdf_new[f] = preprocessing.scale(fdf_new[f])\n",
      "    g=ggplot(fdf_new[fdf_new.Move<0],aes(x=f)) + \\\n",
      "    geom_histogram(color='red',binwidth = binwidth,alpha=0.25,\\\n",
      "                   fill = 'red') + \\\n",
      "    geom_histogram(fdf_new[fdf_new.Move>0],aes(x=f), \\\n",
      "                   color='green',fill = 'green',\\\n",
      "                   binwidth = binwidth,alpha=0.25) + \\\n",
      "    ggtitle(Features[f]) \n",
      "    #xlim(-1,1)+ ylim(-20,20)\n",
      "    return g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/scipy/stats/distributions.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
        "  import vonmises_cython\n",
        "/usr/lib/python2.7/dist-packages/scipy/stats/distributions.py:30: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  import vonmises_cython\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_imbelanceMSG(df,nImb):\n",
      "    (startTime, endTime) = getImbTime(nImb)\n",
      "    \n",
      "    imbalanceMsg = df[df.Reason == 'Imbalance'].between_time(startTime,endTime)\n",
      "    #.between_time('9:29:52','9:29:57')\n",
      "    imbalanceMsg = imbalanceMsg[\n",
      "    (imbalanceMsg.Bid_P>0.01) & \n",
      "    (imbalanceMsg.Ask_P<199999.99) & \n",
      "    (imbalanceMsg.ImbRef>0) & \n",
      "    (imbalanceMsg.ImbCBC>0) &\n",
      "    (imbalanceMsg.ImbFar>0) &\n",
      "    (imbalanceMsg.ImbShares!=0)\n",
      "    ]\n",
      "\n",
      "    imbalanceMsg = imbalanceMsg[['Symbol','Bid_P','Bid_S','Ask_P','Ask_S','ImbRef','ImbCBC','ImbFar','ImbShares','ImbPaired']]\n",
      "    imbalanceMsg['Date'] = imbalanceMsg.index.date\n",
      "    imbalanceMsg['Timestamp'] = imbalanceMsg.index\n",
      "        \n",
      "    #Getting additional info about previous day\n",
      "    OPC = df[df.Reason == 'OPG']\n",
      "    OPC = OPC[['Symbol','tPrice']]\n",
      "    OPC.columns = ['Symbol','OPC_P']\n",
      "    OPC['Date'] = OPC.index.date\n",
      "\n",
      "    prev_OPC = df[df.Reason == 'OPG']\n",
      "    prev_OPC = prev_OPC[['Symbol','tPrice','tShares']]\n",
      "    prev_OPC.columns = ['Symbol','PrevOPC_P','PrevOPC_S']\n",
      "    prev_OPC['Date'] = prev_OPC.index.date\n",
      "    for i in range(prev_OPC.shape[0]):\n",
      "        if prev_OPC.Date[i].weekday()==4:\n",
      "            prev_OPC.Date[i]+=datetime.timedelta(days=3)\n",
      "        else:\n",
      "            prev_OPC.Date[i]+=datetime.timedelta(days=1)\n",
      "\n",
      "    prev_CLC = df[df.tSide == 'YDAY']\n",
      "    prev_CLC = prev_CLC[['Symbol','tPrice','tShares']]\n",
      "    prev_CLC.columns = ['Symbol','PrevCLC_P','PrevCLC_S']\n",
      "    prev_CLC['Date'] = prev_CLC.index.date\n",
      "\n",
      "    #Adding prev day info to imbalance information\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_CLC, on=['Symbol','Date'])\n",
      "\n",
      "    #Filtering data with no prev OPC or prev CLC\n",
      "    imbalanceMsg = imbalanceMsg[(imbalanceMsg.OPC_P>0) & (imbalanceMsg.PrevOPC_P>0)]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])\n",
      "    \n",
      "    #Adding new feature which reflects price move direction\n",
      "    imbalanceMsg['Move'] = imbalanceMsg.Bid_P\n",
      "    imbalanceMsg.Move = 0\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P>imbalanceMsg.Ask_P] = 1\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P<imbalanceMsg.Bid_P] = -1\n",
      "    \n",
      "    return imbalanceMsg   \n",
      "    \n",
      "def create_features(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.Move\n",
      "    Features['Move'] = '1:OpenCross>Ask(9.28); -1:OpenCross<Bid(9.28); 0:otherwise'\n",
      "    \n",
      "    fdf['Pnl'] = (imbalanceMsg.Move==-1)*(imbalanceMsg.OPC_P-imbalanceMsg.Ask_P)+\\\n",
      "                 (imbalanceMsg.Move==1)*(imbalanceMsg.Bid_P-imbalanceMsg.OPC_P)\n",
      "\n",
      "    fdf['Spread'] = (imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)/imbalanceMsg.PrevCLC_P\n",
      "    Features['Spread'] = '(Ask-Bid) at 9.28'\n",
      "\n",
      "    fdf['D1'] = 100*(imbalanceMsg.PrevCLC_P/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D1'] = 'Asset growth a day before'\n",
      "\n",
      "    fdf['D2'] = 100*(0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D2'] = 'Mid(9.28)/OPC(day before)-1'\n",
      "\n",
      "    fdf['D3'] = 100*(0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)/imbalanceMsg.PrevCLC_P-1)\n",
      "    Features['D3'] = 'Mid(9.28)/CloseCross(day before)-1'\n",
      "\n",
      "    \n",
      "    \n",
      "    fdf['D4'] = 100*(imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/imbalanceMsg.PrevCLC_P\n",
      "    Features['D4'] = '(Bid(9.28)-ImbRef(9.28))/CloseCross(day before)'\n",
      "\n",
      "    fdf['D5'] = 100*(imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/imbalanceMsg.PrevCLC_P\n",
      "    Features['D5'] = '(ImbRef(9.28)-Ask(9.28))/CloseCross(day before)'\n",
      "    \n",
      "    \n",
      "    fdf['D44'] = 100*(imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/imbalanceMsg.PrevOPC_P\n",
      "    Features['D44'] = '(Bid(9.28)-ImbRef(9.28))/OpenCross(day before)'\n",
      "\n",
      "    fdf['D55'] = 100*(imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/imbalanceMsg.PrevOPC_P\n",
      "    Features['D55'] = '(ImbRef(9.28)-Ask(9.28))/OpenCross(day before)'\n",
      "    \n",
      "    \n",
      "    fdf['D444'] = (imbalanceMsg.Bid_P-imbalanceMsg.ImbRef)/(1+imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['D444'] = '(Bid(9.28)-ImbRef(9.28))/1+Spread'\n",
      "\n",
      "    fdf['D555'] = (imbalanceMsg.ImbRef-imbalanceMsg.Ask_P)/(1+imbalanceMsg.Ask_P - imbalanceMsg.Bid_P)\n",
      "    Features['D555'] = '(ImbRef(9.28)-Ask(9.28))/1+Spread'\n",
      "    \n",
      "\n",
      "    fdf['D6'] = 100*(imbalanceMsg.ImbRef/imbalanceMsg.PrevOPC_P-1)\n",
      "    Features['D6'] = 'ImbRef(9.28)/OpenCross(day before)-1'\n",
      "\n",
      "    fdf['D7'] = 100*(imbalanceMsg.ImbRef/imbalanceMsg.PrevCLC_P-1)\n",
      "    Features['D7'] = 'ImbRef(9.28)/CloseCross(day before)-1'\n",
      "    \n",
      "    fdf['D66'] = 100*(2*imbalanceMsg.ImbRef/(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)-1)\n",
      "    Features['D66'] = 'ImbRef(9.28)/Mid-1'\n",
      "    \n",
      "    \n",
      "\n",
      "    fdf['V1'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/(100*numpy.sign(imbalanceMsg.ImbShares)+imbalanceMsg.ImbShares)\n",
      "    Features['V1'] = '(Ask_S-Bid_S) at 9.28/Imbalance(9.28)'\n",
      "    \n",
      "    fdf['V11'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V11'] = '(Ask_S-Bid_S) at 9.28/PairedS(9.28)'\n",
      "\n",
      "    fdf['V2'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/imbalanceMsg.PrevOPC_S\n",
      "    Features['V2'] = '(Ask_S-Bid_S) at 9.28/OpenCross(day before)'\n",
      "\n",
      "    fdf['V3'] = (imbalanceMsg.Ask_S - imbalanceMsg.Bid_S)/imbalanceMsg.PrevCLC_S\n",
      "    Features['V3'] = '(Ask_S-Bid_S) at 9.28/CloseCross(day before)'\n",
      "\n",
      "    fdf['V4'] = imbalanceMsg.ImbShares/imbalanceMsg.PrevOPC_S\n",
      "    Features['V4'] = 'ImbalanceS(9.28)/OpenCrossS(day before)'\n",
      "\n",
      "    fdf['V5'] = imbalanceMsg.ImbShares/imbalanceMsg.PrevCLC_S\n",
      "    Features['V5'] = 'ImbalanceS(9.28)/CloseCrossS(day before)'\n",
      "\n",
      "    fdf['V6'] = imbalanceMsg.ImbPaired/imbalanceMsg.PrevOPC_S\n",
      "    Features['V6'] = 'PairedS(9.28)/OpenCrossS(day before)'\n",
      "\n",
      "    fdf['V7'] = imbalanceMsg.ImbPaired/imbalanceMsg.PrevCLC_S\n",
      "    Features['V7'] = 'PairedS(9.28)/CloseCrossS(day before)'\n",
      "    \n",
      "    fdf['V8'] = imbalanceMsg.ImbShares/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V8'] = 'ImbalanceS(9.28)/PairedS(9.28)'\n",
      "    \n",
      "    fdf['V9'] = imbalanceMsg.PrevOPC_S/(100+imbalanceMsg.PrevCLC_S)\n",
      "    Features['V9'] = 'OpenCrossS(day before)/CloseCrossS(day before)'\n",
      "\n",
      "\n",
      "    fdf['a1'] = fdf['D1']*fdf['D2']\n",
      "    Features['a1'] = Features['D1'] + ' Multiply ' + Features['D2']\n",
      "    \n",
      "    fdf['a2'] = fdf['D2']*fdf['D3']\n",
      "    Features['a2'] = Features['D3'] + ' Multiply ' + Features['D2']\n",
      "    \n",
      "    fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "    fdf['a4'] = fdf['D5']*fdf['D4']\n",
      "    Features['a4'] = Features['D5'] + ' Multiply ' + Features['D4']\n",
      "    \n",
      "    fdf['a5'] = fdf['D5']*fdf['D6']\n",
      "    fdf['a6'] = fdf['D1']*fdf['D6']\n",
      "    Features['a6'] = Features['D1'] + ' Multiply ' + Features['D6']\n",
      "    \n",
      "    fdf['a7'] = fdf['V1']*fdf['V2']\n",
      "    Features['a7'] = Features['V1'] + ' Multiply ' + Features['V2']\n",
      "    \n",
      "    fdf['a8'] = fdf['V2']*fdf['V3']\n",
      "    fdf['a9'] = fdf['V3']*fdf['V4']\n",
      "    Features['a9'] = Features['V3'] + ' Multiply ' + Features['V4']\n",
      "    \n",
      "    fdf['a10'] = fdf['V5']*fdf['V4']\n",
      "    fdf['a11'] = fdf['V5']*fdf['V6']\n",
      "    Features['a11'] = Features['V5'] + ' Multiply ' + Features['V6']\n",
      "    \n",
      "    fdf['a12'] = fdf['V7']*fdf['V6']\n",
      "    fdf['a13'] = fdf['V7']*fdf['V1']\n",
      "    Features['a13'] = Features['V1'] + ' Multiply ' + Features['V7']\n",
      "    \n",
      "    fdf['a14'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    Features['a14'] = 'Sign of Imbalance'\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features\n",
      "\n",
      "def create_features2(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.OPC_P/imbalanceMsg.ImbRef-1   \n",
      "    Features['Move'] = 'OpenCross/RefPrice(9.28)-1'\n",
      "    \n",
      "    fdf['Pnl'] = imbalanceMsg.OPC_P-imbalanceMsg.ImbRef\n",
      "    Features['Pnl'] = 'OpenCross/RefPrice(9.28)'\n",
      "    \n",
      "    fdf['Bid'] = imbalanceMsg.Bid_P/imbalanceMsg.ImbRef-1\n",
      "    Features['Bid'] = 'Bid(9.28)'\n",
      "    \n",
      "    fdf['Ask'] = imbalanceMsg.Ask_P/imbalanceMsg.ImbRef-1\n",
      "    Features['Ask'] = 'Ask(9.28)'\n",
      "    \n",
      "    fdf['Ref'] = imbalanceMsg.ImbRef\n",
      "    Features['Ref'] = 'Ref(9.28)'\n",
      "    \n",
      "    fdf['Near'] = imbalanceMsg.ImbCBC/imbalanceMsg.ImbRef-1\n",
      "    Features['Near'] = 'Near(9.28)'\n",
      "    \n",
      "    fdf['Far'] = imbalanceMsg.ImbFar/imbalanceMsg.ImbRef-1\n",
      "    Features['Far'] = 'Far(9.28)'\n",
      "    \n",
      "    fdf['PrevOPC'] = imbalanceMsg.PrevOPC_P/imbalanceMsg.ImbRef-1\n",
      "    Features['PrevOPC'] = 'PrevOPC'\n",
      "    \n",
      "    fdf['PrevCLC'] = imbalanceMsg.PrevCLC_P/imbalanceMsg.ImbRef-1\n",
      "    Features['PrevCLC'] = 'PrevCLC'\n",
      "\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features\n",
      "\n",
      "def create_features3(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "    Features = dict()\n",
      "\n",
      "    midP = 0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)\n",
      "    bid = imbalanceMsg.Bid_P#nsdq_BP #\n",
      "    bidS = imbalanceMsg.Bid_S#nsdq_BS#\n",
      "    ref = imbalanceMsg.ImbRef\n",
      "    ask = imbalanceMsg.Ask_P#nsdq_AP#\n",
      "    askS = imbalanceMsg.Ask_S#nsdq_AS#\n",
      "    near = imbalanceMsg.ImbCBC\n",
      "    far = imbalanceMsg.ImbFar\n",
      "    closeP = imbalanceMsg.PrevCLC_P\n",
      "    \n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "\n",
      "    fdf['Move'] = imbalanceMsg.Move\n",
      "    Features['Move'] = 'Move'\n",
      "       \n",
      "    fdf['Bid'] = bid/ref-1\n",
      "    Features['Bid'] = 'Bid(9.28)'\n",
      "    \n",
      "    fdf['Ask'] = ask/ref-1\n",
      "    Features['Ask'] = 'Ask(9.28)'\n",
      "       \n",
      "    fdf['Near'] = near/ref-1\n",
      "    Features['Near'] = 'Near(9.28)'\n",
      "    \n",
      "    fdf['Far'] = far/ref-1\n",
      "    Features['Far'] = 'Far(9.28)'\n",
      "        \n",
      "    fdf['PrevCLC'] = closeP/ref-1\n",
      "    Features['PrevCLC'] = 'PrevCLC'\n",
      "    \n",
      "    fdf['Spread'] = (ask - bid)/ref\n",
      "    Features['Spread'] = '(Ask-Bid) at 9.28'\n",
      "\n",
      "    fdf['D3'] = 100*(midP/closeP-1)\n",
      "    Features['D3'] = 'Mid(9.28)/CloseCross(day before)-1'\n",
      "    \n",
      "    fdf['D4'] = 100*(bid-ref)/closeP\n",
      "    Features['D4'] = '(Bid(9.28)-ImbRef(9.28))/CloseCross(day before)'\n",
      "\n",
      "    fdf['D5'] = 100*(ref-ask)/closeP\n",
      "    Features['D5'] = '(ImbRef(9.28)-Ask(9.28))/CloseCross(day before)'       \n",
      "    \n",
      "    fdf['D444'] = (bid-ref)/(1+ask - bid)\n",
      "    Features['D444'] = '(Bid(9.28)-ImbRef(9.28))/1+Spread'\n",
      "\n",
      "    fdf['D555'] = (ref-ask)/(1+ask - bid)\n",
      "    Features['D555'] = '(ImbRef(9.28)-Ask(9.28))/1+Spread'\n",
      "    \n",
      "    fdf['D7'] = 100*(ref/closeP-1)\n",
      "    Features['D7'] = 'ImbRef(9.28)/CloseCross(day before)-1'\n",
      "    \n",
      "    fdf['D66'] = 100*(ref/midP-1)\n",
      "    Features['D66'] = 'ImbRef(9.28)/Mid-1'\n",
      "\n",
      "    fdf['V1'] = (askS - bidS)/(100*numpy.sign(imbalanceMsg.ImbShares)+imbalanceMsg.ImbShares)\n",
      "    Features['V1'] = '(Ask_S-Bid_S) at 9.28/Imbalance(9.28)'\n",
      "    \n",
      "    fdf['V11'] = (askS - bidS)/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V11'] = '(Ask_S-Bid_S) at 9.28/PairedS(9.28)'\n",
      "    \n",
      "    fdf['V8'] = imbalanceMsg.ImbShares/(100+imbalanceMsg.ImbPaired)\n",
      "    Features['V8'] = 'ImbalanceS(9.28)/PairedS(9.28)'\n",
      "         \n",
      "    fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "    \n",
      "    fdf['a4'] = fdf['D5']*fdf['D4']\n",
      "    Features['a4'] = Features['D5'] + ' Multiply ' + Features['D4']\n",
      "            \n",
      "    fdf['a14'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    Features['a14'] = 'Sign of Imbalance'\n",
      "    \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf, Features\n",
      "\n",
      "def create_features33(imbalanceMsg):  \n",
      "    #Creating features for algorithm\n",
      "    import numpy\n",
      "    fdf = pd.DataFrame()\n",
      "\n",
      "    midP = 0.5*(imbalanceMsg.Ask_P + imbalanceMsg.Bid_P)\n",
      "    bid = imbalanceMsg.Bid_P\n",
      "    bidS = imbalanceMsg.Bid_S    \n",
      "    min3 = imbalanceMsg[['ImbRef','ImbCBC','ImbFar']].apply(min,axis=1)\n",
      "    max3 = imbalanceMsg[['ImbRef','ImbCBC','ImbFar']].apply(max,axis=1)\n",
      "    \n",
      "    f1 = lambda x: int(x[3]>0)*max(x[0],x[1])+\\\n",
      "                  int(x[3]<0)*min(x[0],x[1])+\\\n",
      "                  int(x[3]==0)*(x[0]+x[1])*0.5\n",
      "            \n",
      "    f2 = lambda x:2.0*x[0]*x[1]/(x[0]+x[1])\n",
      "    \n",
      "    f3 = lambda x: int(x[3]>0)*(0.85*min(x[0],x[1])+0.15*max(x[0],x[1]))+\\\n",
      "                  int(x[3]<0)*(0.15*min(x[0],x[1])+0.85*max(x[0],x[1]))+\\\n",
      "                  int(x[3]==0)*(x[0]+x[1])*0.5\n",
      "            \n",
      "    f4 = lambda x:  (x[0] + x[1] +  0.5*(x[4] + x[5]))/3.0\n",
      "    \n",
      "    f5 = lambda x:  int(x[3]>0)*\\\n",
      "                   (\n",
      "                   (min(x[0],x[1])> x[4])*(x[0]+x[1])*0.5+\\\n",
      "                   (min(x[0],x[1])<=x[4])*(0.85*min(x[0],x[1])+0.15*max(x[0],x[1])))+\\\n",
      "                   int(x[3]<0)*\\\n",
      "                   ((max(x[0],x[1])<x[4])*(x[0]+x[1])*0.5+\\\n",
      "                   (max(x[0],x[1])>=x[4])*(0.15*min(x[0],x[1])+0.85*max(x[0],x[1])))+\\\n",
      "                   int(x[3]==0)*(x[0]+x[1])*0.5\n",
      "    \n",
      "    imbalanceMsg['Mid_P'] = 0.5*( imbalanceMsg.Ask_P +  imbalanceMsg.Bid_P)\n",
      "    ref = imbalanceMsg[['ImbRef','ImbCBC','ImbFar','ImbShares','Mid_P']].apply(f3,axis=1)\n",
      "    #ref = imbalanceMsg.ImbRef\n",
      "    ask = imbalanceMsg.Ask_P\n",
      "    askS = imbalanceMsg.Ask_S\n",
      "    near = imbalanceMsg.ImbCBC\n",
      "    far = imbalanceMsg.ImbFar\n",
      "    closeP = imbalanceMsg.PrevCLC_P\n",
      "    spread = ask - bid\n",
      "    \n",
      "    fdf['Symbol'] = imbalanceMsg.Symbol\n",
      "    \n",
      "    fdf['Date'] = imbalanceMsg.Date\n",
      "        \n",
      "    fdf['OPC_P'] = imbalanceMsg.OPC_P\n",
      "    \n",
      "    fdf['Ask_P'] = ask\n",
      "    \n",
      "    fdf['Bid_P'] = bid\n",
      "    \n",
      "    fdf['Mid_P'] = midP\n",
      "    #---------------------------------\n",
      "        \n",
      "    fdf['Bid'] = ref/bid-1\n",
      "    \n",
      "    fdf['Ask'] = ask/ref-1   \n",
      "        \n",
      "    fdf['BidD'] = bid - ref\n",
      "    \n",
      "    fdf['AskD'] = ref - ask\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['Near'] = near/ref-1\n",
      "    \n",
      "    fdf['Far'] = far/ref-1\n",
      "    \n",
      "    fdf['Spread'] = spread/ref\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['D4'] = 100*(bid-ref)/closeP\n",
      "\n",
      "    fdf['D5'] = 100*(ref-ask)/closeP\n",
      "    #---------------------------------\n",
      "        \n",
      "    fdf['D444'] = (bid-ref)/(1+spread)\n",
      "\n",
      "    fdf['D555'] = (ref-ask)/(1+spread)\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['D66'] = 100*(ref/midP-1)\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['V1'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/(100+np.abs(imbalanceMsg.ImbShares))\n",
      "    \n",
      "    fdf['V1n'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/((askS + bidS)/2+np.abs(imbalanceMsg.ImbShares))\n",
      "    \n",
      "    fdf['V11'] = numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/(100+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V11n'] =numpy.sign(imbalanceMsg.ImbShares)*(askS - bidS)/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "    #---------------------------------\n",
      "    \n",
      "    fdf['V8'] = imbalanceMsg.ImbShares/(100+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V8n'] = imbalanceMsg.ImbShares/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "    \n",
      "    fdf['V8nn'] = (imbalanceMsg.ImbShares-(askS - bidS))/((askS + bidS)/2+imbalanceMsg.ImbPaired)\n",
      "    #---------------------------------\n",
      "        \n",
      "    fdf['a1'] = fdf['Bid']*fdf['Ask']\n",
      "\n",
      "    fdf['a4'] = fdf['D5']*fdf['D4']\n",
      "    \n",
      "    fdf['a5'] = fdf['D444']*fdf['D555']\n",
      "    #---------------------------------\n",
      "       \n",
      "    fdf['a14'] = np.sign(imbalanceMsg.ImbShares)\n",
      "    \n",
      "    fdf['y'] = 1*(imbalanceMsg.OPC_P>ask) -  1*(imbalanceMsg.OPC_P<bid)\n",
      "        \n",
      "    fdf['PrevCLC'] = closeP/ref-1   \n",
      "\n",
      "    fdf['D3'] = 100*(midP/closeP-1)\n",
      "        \n",
      "    fdf['D7'] = 100*(ref/closeP-1)\n",
      "    \n",
      "    fdf['a3'] = fdf['D3']*fdf['D4']\n",
      "       \n",
      "    fdf['a6'] = fdf['D444']*fdf['D444']\n",
      "    \n",
      "    fdf['a7'] = fdf['D555']*fdf['D555']\n",
      "    \n",
      "    fdf['priceRange'] = numpy.floor(fdf['Mid_P']/10)\n",
      "    \n",
      "    fdf['imbInd'] = imbalanceMsg.ImbInd\n",
      "    fdf.imbInd[(fdf['imbInd']!=0) & (fdf['imbInd']!=23)]=1\n",
      "    fdf.imbInd[fdf['imbInd']==23]=2\n",
      "    \n",
      "    #fdf = fdf[max3-min3<0.5*ref]\n",
      "        \n",
      "    fdf.index = range(fdf.shape[0])\n",
      "    \n",
      "    return fdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getImbTime(nImb):\n",
      "    startTime = '9:27:58'\n",
      "    endTime = '9:28:03'\n",
      "    if nImb==2:\n",
      "        startTime = '9:28:03'\n",
      "        endTime = '9:28:08'\n",
      "    elif nImb==3:\n",
      "        startTime = '9:28:08'\n",
      "        endTime = '9:28:12'\n",
      "    elif nImb==4:\n",
      "        startTime = '9:28:12'\n",
      "        endTime = '9:28:18'\n",
      "    elif nImb==5:\n",
      "        startTime = '9:28:18'\n",
      "        endTime = '9:28:22'\n",
      "    elif nImb==6:\n",
      "        startTime = '9:28:22'\n",
      "        endTime = '9:28:28'\n",
      "    elif nImb==7:\n",
      "        startTime = '9:28:28'\n",
      "        endTime = '9:28:32'\n",
      "    elif nImb==8:\n",
      "        startTime = '9:28:32'\n",
      "        endTime = '9:28:38'\n",
      "    elif nImb==9:\n",
      "        startTime = '9:28:38'\n",
      "        endTime = '9:28:42'\n",
      "    elif nImb==10:\n",
      "        startTime = '9:28:42'\n",
      "        endTime = '9:28:48'\n",
      "    elif nImb==11:\n",
      "        startTime = '9:28:48'\n",
      "        endTime = '9:28:52'\n",
      "    elif nImb==12:\n",
      "        startTime = '9:28:52'\n",
      "        endTime = '9:28:58'\n",
      "    elif nImb==13:\n",
      "        startTime = '9:28:58'\n",
      "        endTime = '9:29:02'\n",
      "    elif nImb==14:\n",
      "        startTime = '9:29:02'\n",
      "        endTime = '9:29:08'\n",
      "    elif nImb==15:\n",
      "        startTime = '9:29:08'\n",
      "        endTime = '9:29:12'\n",
      "    elif nImb==16:\n",
      "        startTime = '9:29:12'\n",
      "        endTime = '9:29:18'\n",
      "    elif nImb==17:\n",
      "        startTime = '9:29:18'\n",
      "        endTime = '9:29:22'\n",
      "    elif nImb==18:\n",
      "        startTime = '9:29:22'\n",
      "        endTime = '9:29:28'\n",
      "    elif nImb==19:\n",
      "        startTime = '9:29:28'\n",
      "        endTime = '9:29:32'\n",
      "    elif nImb==20:\n",
      "        startTime = '9:29:32'\n",
      "        endTime = '9:29:38'\n",
      "    elif nImb==21:\n",
      "        startTime = '9:29:38'\n",
      "        endTime = '9:29:42'\n",
      "    elif nImb==22:\n",
      "        startTime = '9:29:42'\n",
      "        endTime = '9:29:48'\n",
      "    elif nImb==23:\n",
      "        startTime = '9:29:48'\n",
      "        endTime = '9:29:52'\n",
      "    elif nImb==24:\n",
      "        startTime = '9:29:52'\n",
      "        endTime = '9:29:58'\n",
      "    return (startTime,endTime)\n",
      "\n",
      "def get_imbalanceMSG2(df,nImb):\n",
      "    (startTime,endTime) = getImbTime(nImb)\n",
      "    \n",
      "    imbalanceMsg = df[df.Reason == 'Imbalance']\n",
      "    imbalanceMsg = imbalanceMsg[\n",
      "    (imbalanceMsg.ImbRef>0) & \n",
      "    (imbalanceMsg.ImbCBC>0) &\n",
      "    (imbalanceMsg.ImbFar>0) &\n",
      "    (imbalanceMsg.Ask_P>0) &\n",
      "    (imbalanceMsg.Bid_P>0) #&\n",
      "    #(imbalanceMsg.ImbShares!=0)\n",
      "    ]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])\n",
      "\n",
      "    Timestamp = []\n",
      "    for i in range(imbalanceMsg.shape[0]):\n",
      "        Timestamp.append(datetime.datetime.strptime(imbalanceMsg.Time[i],'%H:%M:%S'))\n",
      "\n",
      "    imbalanceMsg['Timestamp'] = Timestamp\n",
      "    del Timestamp\n",
      "    imbalanceMsg = imbalanceMsg.set_index(['Timestamp'])\n",
      "    imbalanceMsg = imbalanceMsg.between_time(startTime,endTime)\n",
      "    \n",
      "    imbalanceMsg = imbalanceMsg[['Date','Symbol','Bid_P','Bid_S','Ask_P','Ask_S','ImbRef','ImbCBC','ImbFar','ImbShares','ImbPaired']]\n",
      "    imbalanceMsg['Timestamp'] = imbalanceMsg.index\n",
      "         \n",
      "    #Getting additional info about previous day\n",
      "    OPC = df[df.Reason == 'OPG']\n",
      "    OPC = OPC[['Date','Symbol','tPrice']]\n",
      "    OPC.columns = ['Date','Symbol','OPC_P']\n",
      "    \n",
      "    prev_CLC = df[df.tSide == 'YDAY']\n",
      "    prev_CLC = prev_CLC[['Date','Symbol','tPrice','tShares']]\n",
      "    prev_CLC.columns = ['Date','Symbol','PrevCLC_P','PrevCLC_S']\n",
      "    \n",
      "    #Adding OPC\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_CLC, on=['Symbol','Date'])\n",
      "\n",
      "    #Filtering data with no prev OPC\n",
      "    imbalanceMsg = imbalanceMsg[imbalanceMsg.OPC_P>0]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])    \n",
      "    \n",
      "    #Adding new feature which reflects price move direction\n",
      "    imbalanceMsg['Move'] = imbalanceMsg.Bid_P\n",
      "    imbalanceMsg.Move = 0\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P>imbalanceMsg.Ask_P] = 1\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P<imbalanceMsg.Bid_P] = -1\n",
      "    imbalanceMsg.Bid_S = imbalanceMsg.Bid_S.astype(float)\n",
      "    imbalanceMsg.PrevCLC_P = imbalanceMsg.PrevCLC_P.astype(float)\n",
      "       \n",
      "    return imbalanceMsg   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_imbelanceMSG3(df,nImb):\n",
      "    (startTime,endTime) = getImbTime(nImb)\n",
      "    \n",
      "    imbalanceMsg = df[df.Reason == 'Imbalance']\n",
      "    imbalanceMsg = imbalanceMsg[\n",
      "    (imbalanceMsg.ImbRef>0) & \n",
      "    (imbalanceMsg.ImbCBC>0) &\n",
      "    (imbalanceMsg.ImbFar>0) &\n",
      "    (imbalanceMsg.ImbShares!=0)\n",
      "    ]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])\n",
      "    \n",
      "    Timestamp = []\n",
      "    for i in range(imbalanceMsg.shape[0]):\n",
      "        Timestamp.append(datetime.datetime.strptime(imbalanceMsg.Time[i],'%H:%M:%S'))\n",
      "\n",
      "    imbalanceMsg['Timestamp'] = Timestamp\n",
      "    del Timestamp\n",
      "    imbalanceMsg = imbalanceMsg.set_index(['Timestamp'])\n",
      "    imbalanceMsg = imbalanceMsg.between_time(startTime,endTime)\n",
      "\n",
      "    imbalanceMsg = imbalanceMsg[['Date','Symbol','Bid_P','Bid_S','Ask_P','Ask_S',\n",
      "                             'ImbRef','ImbCBC','ImbFar','ImbShares','ImbPaired',\n",
      "                             'nsdq_BP', 'nsdq_BS', 'nsdq_AP', 'nsdq_AS','Bid2','Ask2']]\n",
      "    imbalanceMsg['Timestamp'] = imbalanceMsg.index\n",
      "         \n",
      "    #Getting additional info about previous day\n",
      "    OPC = df[df.tType == 'OPG']\n",
      "    OPC = OPC[['Date','Symbol','tPrice']]\n",
      "    OPC.columns = ['Date','Symbol','OPC_P']\n",
      "    \n",
      "    prev_CLC = df[df.tType == 'YDAY']\n",
      "    prev_CLC = prev_CLC[['Date','Symbol','tVenue','tPrice']]\n",
      "    prev_CLC.columns = ['Date','Symbol','PrevCLC_P','PrevCLC_S']\n",
      "    \n",
      "    #Adding OPC\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, OPC, on=['Symbol','Date'])\n",
      "    imbalanceMsg = pd.merge(imbalanceMsg, prev_CLC, on=['Symbol','Date'])\n",
      "\n",
      "    #Filtering data with no prev OPC\n",
      "    imbalanceMsg = imbalanceMsg[imbalanceMsg.OPC_P>0]\n",
      "    imbalanceMsg.index = range(imbalanceMsg.shape[0])    \n",
      "    \n",
      "    #Adding new feature which reflects price move direction\n",
      "    imbalanceMsg['Move'] = imbalanceMsg.Bid_P\n",
      "    imbalanceMsg.Move = 0\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P>imbalanceMsg.Ask_P] = 1\n",
      "    imbalanceMsg.Move[imbalanceMsg.OPC_P<imbalanceMsg.Bid_P] = -1\n",
      "    imbalanceMsg.Bid_S = imbalanceMsg.Bid_S.astype(float)\n",
      "    imbalanceMsg.PrevCLC_P = imbalanceMsg.PrevCLC_P.astype(float)\n",
      "       \n",
      "    return imbalanceMsg   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_cv_proba(X,y,clf_class,n_folds,test_size,dates,datesDF,**kwargs):\n",
      "    import pandas\n",
      "    import numpy\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import RandomForestClassifier as RF\n",
      "    import numpy\n",
      "    import math\n",
      "    from mmll import draw_confusion_matrix\n",
      "    from mmll import Precision_Recall\n",
      "    \n",
      "    labels =  numpy.sort(list(set(y)))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    \n",
      "    if type(clf_class)!=str: \n",
      "        CLF_BEST = clf_class()\n",
      "    TEST_F_Score = 0\n",
      "    \n",
      "    for i in range(n_folds): \n",
      "        #======Get test_train_split=============\n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "\n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]] \n",
      "        \n",
      "        Xtrain.index = range(Xtrain.shape[0])\n",
      "        Xtest.index = range(Xtest.shape[0])\n",
      "        ytrain.index = range(ytrain.shape[0])\n",
      "        ytest.index = range(ytest.shape[0])\n",
      "        \n",
      "        if (len((pd.isnull(Xtrain)).all(1).nonzero()[0])>0):\n",
      "            nonanind = (~pd.isnull(Xtrain)).all(1).nonzero()[0]\n",
      "            ytrain = ytrain[nonanind]\n",
      "            Xtrain = Xtrain.ix[nonanind,:]\n",
      "            Xtrain.index = range(Xtrain.shape[0])\n",
      "            ytrain.index = range(ytrain.shape[0])\n",
      "            \n",
      "        if (len((pd.isnull(Xtest)).all(1).nonzero()[0])>0):\n",
      "            nonanind = (~pd.isnull(Xtest)).all(1).nonzero()[0]\n",
      "            ytest = ytest[nonanind]\n",
      "            Xtest = Xtest.ix[nonanind,:]\n",
      "            Xtest.index = range(Xtest.shape[0])\n",
      "            ytest.index = range(ytest.shape[0])           \n",
      "               \n",
      "        #========================================        \n",
      "            \n",
      "        if clf_class=='NN':    \n",
      "            from pybrain.tools.shortcuts import buildNetwork\n",
      "            from pybrain.datasets import SupervisedDataSet\n",
      "            from pybrain.datasets import ClassificationDataSet\n",
      "            from pybrain.structure.modules   import SoftmaxLayer\n",
      "\n",
      "            #Create dataset\n",
      "            #ds = SupervisedDataSet(Xtrain.shape[1], 1)\n",
      "            ds = ClassificationDataSet(Xtrain.shape[1], 1, nb_classes=2)\n",
      "            for j in range(Xtrain.shape[0]):\n",
      "                ds.addSample(Xtrain.ix[j,:], ytrain.ix[j,:])\n",
      "            ds._convertToOneOfMany( )\n",
      "\n",
      "            #Create net\n",
      "            #net = buildNetwork(ds.indim, ds.indim*2, ds.outdim, outclass=SoftmaxLayer)\n",
      "\n",
      "            #varsion1\n",
      "            #from pybrain.structure import FeedForwardNetwork\n",
      "            #net = FeedForwardNetwork()\n",
      "            from pybrain.structure import LinearLayer, SigmoidLayer\n",
      "            #inLayer = LinearLayer(ds.indim)\n",
      "            #hiddenLayer = SigmoidLayer(ds.indim)\n",
      "            #outLayer = SoftmaxLayer(ds.outdim)\n",
      "            #net.addInputModule(inLayer)\n",
      "            #net.addModule(hiddenLayer)\n",
      "            #net.addOutputModule(outLayer)\n",
      "            from pybrain.structure import FullConnection\n",
      "            #in_to_hidden = FullConnection(inLayer, hiddenLayer)\n",
      "            #hidden_to_out = FullConnection(hiddenLayer, outLayer)\n",
      "            #net.addConnection(in_to_hidden)\n",
      "            #net.addConnection(hidden_to_out)\n",
      "            #net.sortModules()\n",
      "            \n",
      "            #varsion2\n",
      "            from pybrain.structure import RecurrentNetwork\n",
      "            net = RecurrentNetwork()\n",
      "            net.addInputModule(LinearLayer(ds.indim, name='inLayer'))\n",
      "            net.addModule(SigmoidLayer(ds.indim, name='hiddenLayer'))\n",
      "            net.addOutputModule(SoftmaxLayer(ds.outdim, name='outLayer'))\n",
      "            net.addConnection(FullConnection(net['inLayer'], net['hiddenLayer'], name='in_to_hidden'))\n",
      "            net.addConnection(FullConnection(net['hiddenLayer'], net['outLayer'], name='hidden_to_out'))\n",
      "            net.addRecurrentConnection(FullConnection(net['hiddenLayer'], net['hiddenLayer'], name='hidden_to_hidden'))\n",
      "            net.sortModules()\n",
      "\n",
      "            #Train net\n",
      "            from pybrain.supervised.trainers import BackpropTrainer\n",
      "            trainer = BackpropTrainer(net, ds, momentum=0.1, verbose=True, weightdecay=0.01)\n",
      "            trainer.train()\n",
      "            #trainer.trainUntilConvergence(dataset=ds,maxEpochs=10)\n",
      "            \n",
      "            if False:#combination of NN and COMB\n",
      "                #get new features\n",
      "                Xtrain_new= numpy.zeros((Xtrain.shape[0],hiddenLayer.dim),float)\n",
      "                Xtest_new= numpy.zeros((Xtest.shape[0],hiddenLayer.dim),float)\n",
      "\n",
      "                for j in range(Xtrain.shape[0]):\n",
      "                    to_hidden=numpy.dot(in_to_hidden.params.reshape(hiddenLayer.dim,inLayer.dim),\\\n",
      "                                        Xtrain.ix[j,:].as_matrix())\n",
      "                    Xtrain_new[j,:] = hiddenLayer.activate(to_hidden)\n",
      "                for j in range(Xtest.shape[0]):\n",
      "                    to_hidden=numpy.dot(in_to_hidden.params.reshape(hiddenLayer.dim,inLayer.dim),\\\n",
      "                                        Xtest.ix[j,:].as_matrix())\n",
      "                    Xtest_new[j,:] = hiddenLayer.activate(to_hidden)\n",
      "\n",
      "                #Work with new features\n",
      "                clf1 = RF(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05, criterion = 'entropy')\n",
      "                clf2 = GBC(init='zero')\n",
      "\n",
      "                clf1.fit(Xtrain_new,ytrain)\n",
      "                clf2.fit(Xtrain_new,ytrain)\n",
      "\n",
      "                probaTest1=clf1.predict_proba(Xtest_new).astype(float)\n",
      "                probaTest2=clf2.predict_proba(Xtest_new).astype(float)\n",
      "                for i in range(probaTest1.shape[0]):\n",
      "                    for j in range(probaTest1.shape[1]):\n",
      "                         probaTest1[i,j]=0.5*(probaTest1[i,j]+probaTest2[i,j])\n",
      "\n",
      "\n",
      "                probaTrain1=clf1.predict_proba(Xtrain_new).astype(float)\n",
      "                probaTrain2=clf2.predict_proba(Xtrain_new).astype(float)\n",
      "                for i in range(probaTrain1.shape[0]):\n",
      "                    for j in range(probaTrain1.shape[1]):\n",
      "                        probaTrain1[i,j]=0.5*(probaTrain1[i,j]+probaTrain2[i,j])\n",
      "\n",
      "                ypred = clf1.classes_[numpy.argmax(probaTest1,axis=1)]\n",
      "                ypredTrain = clf1.classes_[numpy.argmax(probaTrain1,axis=1)] \n",
      "            else:\n",
      "                ypred = ytest.copy()\n",
      "                ypredTrain = ytrain.copy()\n",
      "\n",
      "                for j in range(Xtrain.shape[0]):\n",
      "                    ypredTrain.ix[j]=net.activate(Xtrain.ix[j,:])[1]>0.5\n",
      "                for j in range(Xtest.shape[0]):\n",
      "                    ypred.ix[j]=net.activate(Xtest.ix[j,:])[1]>0.5\n",
      "                \n",
      "            test_cm += confusion_matrix(ytest.astype(bool),ypred.astype(bool),labels).astype(float)/n_folds\n",
      "            train_cm += confusion_matrix(ytrain.astype(bool),ypredTrain.astype(bool),labels).astype(float)/n_folds\n",
      "             \n",
      "            continue;    \n",
      "            \n",
      "        if clf_class=='B':\n",
      "            ypred = ytest.copy(); ypred[:] = 0\n",
      "            ypredTrain = ytrain.copy(); ypredTrain[:] = 0\n",
      "            if (any(Xtest.columns=='D4')):\n",
      "                ypred[(Xtest.D4>=0)] = 1\n",
      "                ypredTrain[(Xtrain.D4>=0)] = 1\n",
      "            if (any(Xtest.columns=='D5')):\n",
      "                ypred[(Xtest.D5>=0)] = 1\n",
      "                ypredTrain[(Xtrain.D5>=0)] = 1\n",
      "            \n",
      "            continue;        \n",
      "            \n",
      "        if (clf_class=='COMB'):\n",
      "                clf1 = RF(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05, criterion = 'entropy')\n",
      "                clf2 = GBC(min_samples_split = Xtrain.shape[0]*0.05,init='zero')# learning_rate=0.1\n",
      "                \n",
      "                #z = float(len(ytrain[ytrain==0]))\n",
      "                #nall = float(len(ytrain))\n",
      "                #sample_weight = np.array([(nall-z)/nall if i == 0 else z/nall for i in ytrain])\n",
      "                clf1.fit(Xtrain,ytrain)\n",
      "                clf2.fit(Xtrain,ytrain)\n",
      "                \n",
      "                probaTest1=clf1.predict_proba(Xtest).astype(float)\n",
      "                probaTest2=clf2.predict_proba(Xtest).astype(float)\n",
      "                for i in range(probaTest1.shape[0]):\n",
      "                    for j in range(probaTest1.shape[1]):\n",
      "                        probaTest1[i,j]=0.5*(probaTest1[i,j]+probaTest2[i,j])\n",
      "\n",
      "                        \n",
      "                probaTrain1=clf1.predict_proba(Xtrain).astype(float)\n",
      "                probaTrain2=clf2.predict_proba(Xtrain).astype(float)\n",
      "                for i in range(probaTrain1.shape[0]):\n",
      "                    for j in range(probaTrain1.shape[1]):\n",
      "                        probaTrain1[i,j]=0.5*(probaTrain1[i,j]+probaTrain2[i,j])\n",
      "                                 \n",
      "                ypred = clf1.classes_[numpy.argmax(probaTest1,axis=1)]\n",
      "                ypredTrain = clf1.classes_[numpy.argmax(probaTrain1,axis=1)]  \n",
      "\n",
      "                test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "                train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "            \n",
      "                continue;\n",
      "            \n",
      "        else: \n",
      "                if (type(clf_class()) ==  type(LR())) :\n",
      "                    clf = clf_class(class_weight='auto',C=0.1)\n",
      "                if (type(clf_class()) ==  type(SVC())):\n",
      "                    clf = clf_class(class_weight='auto',probability=True)\n",
      "                if (type(clf_class()) ==  type(RF())):\n",
      "                    #print 1\n",
      "                    clf = clf_class(n_jobs=4,min_samples_split = Xtrain.shape[0]*0.05, \\\n",
      "                                   criterion = 'entropy', n_estimators = 10)# min_samples_leaf = Xtrain.shape[0]*0.05,\n",
      "                if (type(clf_class()) ==  type(GBC())):\n",
      "                    clf = clf_class(min_samples_split = Xtrain.shape[0]*0.05,init='zero')#min_samples_split = Xtrain.shape[0]*0.05\n",
      "                if (type(clf_class()) ==  type(GBR())):\n",
      "                    clf = clf_class(init='zero')\n",
      "\n",
      "                clf.fit(Xtrain,ytrain)\n",
      "                #print type(clf)\n",
      "            \n",
      "                if (type(clf_class()) !=  type(GBR())):\n",
      "                    probaTest = clf.predict_proba(Xtest).astype(float)\n",
      "                    probaTrain = clf.predict_proba(Xtrain).astype(float)\n",
      "\n",
      "                    ypred = clf.classes_[numpy.argmax(probaTest,axis=1)]\n",
      "                    ypredTrain = clf.classes_[numpy.argmax(probaTrain,axis=1)]  \n",
      "\n",
      "                    test_cm_tmp = confusion_matrix(ytest,ypred,labels).astype(float)\n",
      "                    test_cm += test_cm_tmp/n_folds\n",
      "                    train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "                    \n",
      "                else:\n",
      "                    probaTest = clf.predict(Xtest).astype(float)\n",
      "                    probaTrain = clf.predict(Xtrain).astype(float)\n",
      "\n",
      "                    ypred = probaTest>0.5\n",
      "                    ypredTrain = probaTrain>0.5  \n",
      "\n",
      "                    test_cm_tmp = confusion_matrix(ytest,ypred,labels).astype(float)\n",
      "                    test_cm += test_cm_tmp/n_folds\n",
      "                    train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds \n",
      "                    \n",
      "                pr =  Precision_Recall(test_cm_tmp, labels)\n",
      "                #print pr\n",
      "                if (pr[2]>TEST_F_Score):\n",
      "                     TEST_F_Score =  pr[2]\n",
      "                     CLF_BEST = clf  \n",
      "    \n",
      "    \n",
      "    #print TEST_ERRORS\n",
      "    print \"max F_Score \",TEST_F_Score\n",
      "    \n",
      "    #print CLF_BEST\n",
      "\n",
      "    test_pr = Precision_Recall(test_cm, labels)\n",
      "    train_pr = Precision_Recall(train_cm, labels)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm, CLF_BEST, TEST_F_Score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def OneModelResults(clf_class, input,target,ERRORS,dates,datesDF,**kwargs):\n",
      "    import numpy\n",
      "    from mmll import draw_confusion_matrix\n",
      "    from mmll import Precision_Recall\n",
      "    fig1 = plt.figure(figsize=(15, 5))\n",
      "    plt.clf()\n",
      "    ax1 = fig1.add_subplot(1,3,1)\n",
      "    trainError, testError, cm, clf, fscore = run_cv_proba(input,target,clf_class,30,5,dates,datesDF,**kwargs)\n",
      "    draw_confusion_matrix(cm,  numpy.sort(list(set(target))), fig1, ax1)\n",
      "    ERRORS.loc[ERRORS.shape[0]] =[str(clf_class).split('.')[-1].strip('>'),trainError,testError]\n",
      "    pr = Precision_Recall(cm,numpy.sort(list(set(target))))\n",
      "    cm2return=cm\n",
      "    print 'Precision - %s, Recall - %s, F_Score - %s' % (pr[0],pr[1],pr[2])\n",
      "\n",
      "    #if clf_class=='NN':\n",
      "    return cm2return\n",
      "    \n",
      "    #Show learning curves\n",
      "    TrainError=[]\n",
      "    TestError=[]\n",
      "    nDays = len(dates)\n",
      "    testRange = range(nDays-1)\n",
      "    for i in testRange: \n",
      "        trainError, testError, cm, clf, fscore = run_cv_proba(input,target,clf_class,5,i+1,dates,datesDF,**kwargs)\n",
      "        #print i,testError\n",
      "        TrainError.append(trainError)\n",
      "        TestError.append(testError)\n",
      "\n",
      "    LearningCurves = pd.DataFrame()\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index']+= 1\n",
      "    LearningCurves['TrainError'] = TrainError\n",
      "    LearningCurves['TestError'] = TestError\n",
      "    LearningCurves['Index'] = nDays-LearningCurves['Index']\n",
      "    LearningCurves = pd.melt(LearningCurves, id_vars = 'Index', value_vars = ['TestError','TrainError'])\n",
      "\n",
      "    g = ggplot(LearningCurves, aes('Index', 'value', color = 'variable')) + geom_step() + \\\n",
      "    ggtitle('Learning curves') + xlab(\"% of data sent to train\") + ylab(\"Error\")\n",
      "    \n",
      "    return g,cm2return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dates_tmp_df(fdf):\n",
      "    import numpy\n",
      "    \n",
      "    datesDF = pd.DataFrame()\n",
      "    datesDF['Date'] = fdf.Date\n",
      "    datesDF['newIndex'] = numpy.zeros((datesDF.shape[0],1))\n",
      "    datesDF.index = range(datesDF.shape[0])\n",
      "\n",
      "    dates = sorted(list(set(fdf.Date)))\n",
      "    for i in range(datesDF.shape[0]):\n",
      "        for j in range(len(dates)):\n",
      "            if (datesDF.Date[i]==dates[j]):            \n",
      "                datesDF.newIndex[i] = j\n",
      "            \n",
      "    datesDF.index = datesDF.newIndex \n",
      "    datesDF.newIndex = range(datesDF.shape[0])\n",
      "    datesDF = datesDF['newIndex']\n",
      "    \n",
      "    return datesDF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Regression(clf_class, input,target,dates,datesDF,side):\n",
      "    import numpy\n",
      "    trainError, testError = run_reg(input,target,clf_class,5,1,dates,datesDF,side)\n",
      "    print 'TrainError - %s, TestError - %s' % (trainError, testError)\n",
      "    #Show learning curves\n",
      "    TrainError=[]\n",
      "    TestError=[]\n",
      "    nDays = len(dates)\n",
      "    testRange = range(5,nDays/2-1)\n",
      "    for i in testRange: \n",
      "        trainError, testError = run_reg(input,target,clf_class,5,i+1,dates,datesDF,side)\n",
      "        TrainError.append(trainError)\n",
      "        TestError.append(testError)\n",
      "\n",
      "    LearningCurves = pd.DataFrame()\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index']+= 1\n",
      "    LearningCurves['TrainError'] = TrainError\n",
      "    LearningCurves['TestError'] = TestError\n",
      "    LearningCurves['Index'] = nDays-LearningCurves['Index']\n",
      "    LearningCurves = pd.melt(LearningCurves, id_vars = 'Index', value_vars = ['TestError','TrainError'])\n",
      "\n",
      "    g = ggplot(LearningCurves, aes('Index', 'value', color = 'variable')) + geom_step() + \\\n",
      "    ggtitle('Learning curves') + xlab(\"% of data sent to train\") + ylab(\"Error\")\n",
      "    \n",
      "    return g\n",
      "\n",
      "def GetNEstimators(clf_class, input,target,dates,datesDF,side):\n",
      "    TrainError=[]\n",
      "    TestError=[]\n",
      "    nDays = len(dates)\n",
      "    testRange = range(90)\n",
      "    \n",
      "    for i in testRange: \n",
      "        trainError, testError = run_reg_2(input,target,clf_class,1,nDays/10,dates,datesDF,side,i)\n",
      "        TrainError.append(trainError)\n",
      "        TestError.append(testError)\n",
      "\n",
      "    LearningCurves = pd.DataFrame()\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index']+= 1\n",
      "    LearningCurves['TrainError'] = TrainError\n",
      "    LearningCurves['TestError'] = TestError\n",
      "    LearningCurves['Index'] = testRange\n",
      "    LearningCurves['Index'] = 100+LearningCurves['Index']*10\n",
      "    LearningCurves = pd.melt(LearningCurves, id_vars = 'Index', value_vars = ['TestError','TrainError'])\n",
      "\n",
      "    g = ggplot(LearningCurves, aes('Index', 'value', color = 'variable')) + geom_step() + \\\n",
      "    ggtitle('Learning curves') + xlab(\"% of data sent to train\") + ylab(\"Error\")\n",
      "    \n",
      "    return g\n",
      "\n",
      "def run_reg_2(X,y,clf_class,n_folds,test_size,dates,datesDF,side,nest):\n",
      "    import numpy\n",
      "    from sklearn import metrics\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import RandomForestRegressor as RFR\n",
      "    from sklearn.neighbors import KNeighborsRegressor as KNR\n",
      "    \n",
      "    X.index = range(X.shape[0])\n",
      "    y.index = range(y.shape[0])\n",
      "    \n",
      "    test_pr = 0.0;\n",
      "    train_pr = 0.0;\n",
      "    \n",
      "    for i in range(n_folds): \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "\n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "            \n",
      "        if side>0:\n",
      "            f1 = ytrain>0\n",
      "            f2 = ytest>0\n",
      "        else:\n",
      "            f1 = ytrain<0\n",
      "            f2 = ytest<0\n",
      "        \n",
      "        clf = clf_class(loss = 'huber',n_estimators=100+nest*10)\n",
      "\n",
      "        clf.fit(Xtrain[f1], ytrain[f1])\n",
      "\n",
      "        ypred = clf.predict(Xtest[f2])\n",
      "        ypredTrain = clf.predict(Xtrain[f1])\n",
      "\n",
      "        test_pr += metrics.r2_score(ytest[f2], ypred)/n_folds\n",
      "        train_pr += metrics.r2_score(ytrain[f1], ypredTrain)/n_folds\n",
      "    \n",
      "    return 1-train_pr, 1-test_pr\n",
      "\n",
      "def run_reg(X,y,clf_class,n_folds,test_size,dates,datesDF,side):\n",
      "    import numpy\n",
      "    from sklearn import metrics\n",
      "    from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
      "    from sklearn.ensemble import RandomForestRegressor as RFR\n",
      "    from sklearn.neighbors import KNeighborsRegressor as KNR\n",
      "    \n",
      "    X.index = range(X.shape[0])\n",
      "    y.index = range(y.shape[0])\n",
      "    \n",
      "    test_pr = 0.0;\n",
      "    train_pr = 0.0;\n",
      "    \n",
      "    for i in range(n_folds): \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "\n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "            \n",
      "        if side>0:\n",
      "            f1 = ytrain>0\n",
      "            f2 = ytest>0\n",
      "        else:\n",
      "            f1 = ytrain<0\n",
      "            f2 = ytest<0\n",
      "        \n",
      "        if (clf_class!='COMB'):\n",
      "            if (type(clf_class()) ==  type(GBR())):\n",
      "                clf = clf_class(loss = 'huber')#learning_rate=0.1,\n",
      "            if (type(clf_class()) ==  type(KNR())):\n",
      "                clf = clf_class(weights = 'uniform',n_neighbors=20)\n",
      "            else:\n",
      "                clf = clf_class()\n",
      "\n",
      "            clf.fit(Xtrain[f1], ytrain[f1])\n",
      "\n",
      "            ypred = clf.predict(Xtest[f2])\n",
      "            ypredTrain = clf.predict(Xtrain[f1])\n",
      "        else:\n",
      "            clf1 = GBR(loss = 'huber',min_samples_split = ytrain[f1].shape[0]*0.05)\n",
      "            clf2 = RFR(min_samples_split = ytrain[f1].shape[0]*0.05)\n",
      "            clf1.fit(Xtrain[f1], ytrain[f1])\n",
      "            clf2.fit(Xtrain[f1], ytrain[f1])\n",
      "            \n",
      "            ypred = 0.5*(clf1.predict(Xtest[f2])+clf2.predict(Xtest[f2]))\n",
      "            ypredTrain =0.5*( clf1.predict(Xtrain[f1])+ clf2.predict(Xtrain[f1]))\n",
      "\n",
      "        test_pr += metrics.r2_score(ytest[f2], ypred)/n_folds\n",
      "        train_pr += metrics.r2_score(ytrain[f1], ypredTrain)/n_folds\n",
      "    \n",
      "    return 1-train_pr, 1-test_pr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_cvNN(X,y,n_folds,test_size,**kwargs):\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn import preprocessing\n",
      "    import neurolab as nl\n",
      "    \n",
      "    lb = preprocessing.LabelBinarizer()\n",
      "    lb.fit(y)\n",
      "    \n",
      "    labels =  sort(list(set(y)))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
      "        \n",
      "        input = scaler.transform(Xtrain)  \n",
      "        \n",
      "        net = nl.net.newff(nl.tool.minmax(input), **kwargs)\n",
      "        error = net.train(input, lb.transform(ytrain),show=500)\n",
      "        \n",
      "        ypred = lb.inverse_transform(net.sim(scaler.transform(Xtest)))\n",
      "        ypredTrain = lb.inverse_transform(net.sim(input))\n",
      "        \n",
      "        ypred = clf.predict(Xtest)\n",
      "        ypredTrain = clf.predict(Xtrain)\n",
      "\n",
      "        test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "        train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        \n",
      "    test_pr = Precision_Recall(test_cm)\n",
      "    train_pr = Precision_Recall(train_cm)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n",
      "\n",
      "def run_cvNN2(X,y,n_folds,threshold,test_size,**kwargs):\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn import preprocessing\n",
      "    import neurolab as nl\n",
      "    \n",
      "    lb = preprocessing.LabelBinarizer()\n",
      "    lb.fit(y)\n",
      "    \n",
      "    labels =  sort(list(set(y)))\n",
      "    test_cm = np.zeros((len(labels),len(labels)))\n",
      "    train_cm = np.zeros((len(labels),len(labels)))\n",
      "    testError = 0\n",
      "    trainError = 0\n",
      "    \n",
      "    for i in range(n_folds):  \n",
      "        r = range(len(dates))\n",
      "        np.random.shuffle(r)\n",
      "        test_days = r[:test_size] \n",
      "        train_days = r[test_size:] \n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "        \n",
      "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
      "        \n",
      "        input = scaler.transform(Xtrain)  \n",
      "        \n",
      "        net = nl.net.newff(nl.tool.minmax(input), **kwargs)\n",
      "        error = net.train(input, ytrain.reshape(len(ytrain),1),show=500)\n",
      "        \n",
      "        ypred = net.sim(scaler.transform(Xtest)).flatten()\n",
      "        ypred[ypred>threshold] = 1\n",
      "        ypred[ypred<-threshold] = -1\n",
      "        ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "        \n",
      "        ypredTrain = net.sim(input).flatten()\n",
      "        ypredTrain[ypredTrain>threshold] = 1\n",
      "        ypredTrain[ypredTrain<-threshold] = -1\n",
      "        ypredTrain[(ypredTrain!=1) & (ypredTrain!=-1)] = 0\n",
      "        \n",
      "        test_cm += confusion_matrix(ytest,ypred,labels).astype(float)/n_folds\n",
      "        train_cm += confusion_matrix(ytrain,ypredTrain,labels).astype(float)/n_folds\n",
      "        \n",
      "    test_pr = Precision_Recall(test_cm)\n",
      "    train_pr = Precision_Recall(train_cm)    \n",
      "    return 1-train_pr[2], 1-test_pr[2], test_cm\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_signals1(imbalanceMsg,X,y,clf_class,dates,datesDF,**kwargs):  \n",
      "    import numpy\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    labels = numpy.sort(list(set(y)))\n",
      "    \n",
      "    Signals = imbalanceMsg[['Date','Timestamp','Symbol','Ask_P','Bid_P']]\n",
      "    Signals['Side'] = numpy.zeros((Signals.shape[0],1))\n",
      "    Signals['Price'] = Signals.Ask_P   \n",
      "    \n",
      "    \n",
      "    if clf_class!='B':\n",
      "        for i in range(int(datesDF.index.max())+1):  \n",
      "            train_days = range(len(dates))\n",
      "            test_days = i \n",
      "            train_days.remove(i)\n",
      "\n",
      "            Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "            Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "            ytrain = y.ix[datesDF.ix[train_days]]\n",
      "            ytest = y.ix[datesDF.ix[test_days]]\n",
      "               \n",
      "            if not kwargs.has_key('n_ensembles'):\n",
      "                \n",
      "                if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "                    clf = clf_class(class_weight='auto')\n",
      "                else:\n",
      "                    clf = clf_class(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05)\n",
      "                \n",
      "                clf.fit(Xtrain,ytrain)\n",
      "\n",
      "                Signals.Side[datesDF.ix[test_days]] = clf.predict(Xtest)\n",
      "            else:\n",
      "                n_ensembles = kwargs['n_ensembles']\n",
      "                test_size_ensemble = kwargs['test_size_ensemble']\n",
      "                \n",
      "                ypred = ytest.copy(); ypred[:] = 0\n",
      "                for j in range(n_ensembles):  \n",
      "                    Xtrain_sub, Xtest_sub, ytrain_sub, ytest_sub = train_test_split(Xtrain, ytrain, test_size=test_size_ensemble)\n",
      "\n",
      "                    if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "                        clf = clf_class(class_weight='auto')\n",
      "                    else:\n",
      "                        clf = clf_class(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05)\n",
      "                        \n",
      "                    clf.fit(Xtrain_sub,ytrain_sub)\n",
      "                    \n",
      "                    ypred += clf.predict(Xtest).astype(float)/n_ensembles\n",
      "\n",
      "\n",
      "                #Averaging of assemblies results\n",
      "                ypred[ypred>0.5] = 1\n",
      "                ypred[ypred<-0.5] = -1\n",
      "                ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "                \n",
      "\n",
      "                Signals.Side[datesDF.ix[test_days]] = ypred\n",
      "            \n",
      "            Signals.Side[(Signals.Side!=0) & (X.a14>0)] = 1\n",
      "            Signals.Side[(Signals.Side!=0) & (X.a14<0)] = -1\n",
      "    else:\n",
      "        ypred = y.copy(); ypred[:] = 0\n",
      "        ypred[(X.a14>0) & (X.D5>=0)] = 1\n",
      "        ypred[(X.a14<0) & (X.D4>=0)] = -1\n",
      "        Signals.Side = ypred\n",
      "        \n",
      "        \n",
      "    Signals.Price[Signals['Side']==1] = Signals.Ask_P[Signals['Side']==1]\n",
      "    Signals.Price[Signals['Side']==-1] = Signals.Bid_P[Signals['Side']==-1]\n",
      "    Signals = Signals[Signals.Side!=0]\n",
      "    Signals = Signals[['Date','Timestamp','Symbol','Price','Side']] \n",
      "    Signals.index = Signals.Timestamp\n",
      "    return Signals\n",
      "\n",
      "def get_signals_clf(imbalanceMsg,X,y,clf,dates,datesDF,**kwargs):  \n",
      "    import numpy\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    labels = numpy.sort(list(set(y)))\n",
      "    \n",
      "    Signals = imbalanceMsg[['Date','Timestamp','Symbol','Ask_P','Bid_P']]\n",
      "    Signals['Side'] = numpy.zeros((Signals.shape[0],1))\n",
      "    Signals['Price'] = Signals.Ask_P   \n",
      "                       \n",
      "    ypred = clf.predict(X).astype(float)\n",
      "\n",
      "    ypred[ypred>0.5] = 1\n",
      "    ypred[ypred<-0.5] = -1\n",
      "    ypred[(ypred!=1) & (ypred!=-1)] = 0\n",
      "\n",
      "    Signals.Side = ypred      \n",
      "       \n",
      "    Signals.Price[Signals['Side']==1] = Signals.Ask_P[Signals['Side']==1]\n",
      "    Signals.Price[Signals['Side']==-1] = Signals.Bid_P[Signals['Side']==-1]\n",
      "    Signals = Signals[Signals.Side!=0]\n",
      "    Signals = Signals[['Date','Timestamp','Symbol','Price','Side']] \n",
      "    Signals.index = Signals.Timestamp\n",
      "    return Signals\n",
      "\n",
      "def get_signals_proba(imbalanceMsg,X,y,clf_class,dates,datesDF,**kwargs):  \n",
      "    import numpy\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn.svm import SVC\n",
      "    from sklearn.linear_model import LogisticRegression as LR\n",
      "    labels = numpy.sort(list(set(y)))\n",
      "    \n",
      "    Signals = imbalanceMsg[['Date','Timestamp','Symbol','Ask_P','Bid_P']]\n",
      "    Signals['Side'] = numpy.zeros((Signals.shape[0],1))\n",
      "    Signals['Price'] = Signals.Ask_P   \n",
      "    \n",
      "    for i in range(int(datesDF.index.max())+1):  \n",
      "        train_days = range(len(dates))\n",
      "        test_days = i \n",
      "        train_days.remove(i)\n",
      "               \n",
      "        Xtrain = X.ix[datesDF.ix[train_days],:]\n",
      "        Xtest = X.ix[datesDF.ix[test_days],:]\n",
      "        ytrain = y.ix[datesDF.ix[train_days]]\n",
      "        ytest = y.ix[datesDF.ix[test_days]]\n",
      "                       \n",
      "        if (type(clf_class()) ==  type(LR())) | (type(clf_class()) ==  type(SVC())):\n",
      "            clf = clf_class(class_weight='auto')\n",
      "        else:\n",
      "            clf = clf_class(n_jobs=2,min_samples_split = Xtrain.shape[0]*0.05)\n",
      "                \n",
      "        clf.fit(Xtrain,ytrain)\n",
      "\n",
      "        Signals.Side[datesDF.ix[test_days]] = clf.classes_[numpy.argmax(clf.predict_proba(Xtest),axis=1)]\n",
      "              \n",
      "    #Signals.Side[Signals.Side==1] = 0\n",
      "    #Signals.Side[Signals.Side==-1] = 0\n",
      "    Signals.Side[Signals.Side>0] = 1\n",
      "    Signals.Side[Signals.Side<0] = -1\n",
      "    \n",
      "    Signals.Price[Signals['Side']==1] = Signals.Ask_P[Signals['Side']==1]\n",
      "    Signals.Price[Signals['Side']==-1] = Signals.Bid_P[Signals['Side']==-1]\n",
      "    Signals = Signals[Signals.Side!=0]\n",
      "    Signals = Signals[['Date','Timestamp','Symbol','Price','Side']] \n",
      "    Signals.index = Signals.Timestamp\n",
      "    return Signals\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_performance(Signals,df,days,add=0):\n",
      "    #days = sorted(list(set(Signals.index.date)))\n",
      "    \n",
      "    PNL=[]\n",
      "    NEGPNL=[]\n",
      "    SDict=dict()\n",
      "    for day in days:\n",
      "        dayPnl=[]\n",
      "        negdayPnl=[]\n",
      "        #print '----------------------------------'\n",
      "        #print day\n",
      "        #print '----------------------------------'\n",
      "        curr_day_signals = Signals[Signals.Date==day]\n",
      "        data = df[df.Date==day]\n",
      "        buys = curr_day_signals[curr_day_signals.Side==1]\n",
      "        buys = buys.sort(['Symbol'])\n",
      "        sells = curr_day_signals[curr_day_signals.Side==-1]\n",
      "        sells = sells.sort(['Symbol'])\n",
      "        \n",
      "        #endTimestamp = pd.Timestamp('09:30:01')\n",
      "        #print 'BUY'\n",
      "        for count, row in buys.iterrows():\n",
      "            symbol = row[2]\n",
      "            price = row[3]+add\n",
      "            curr_symbol_data=data[data.Symbol==symbol]#.between_time(startTimestamp,endTimestamp)\n",
      "\n",
      "            #AskPrices = dict()\n",
      "            #for i in range(curr_symbol_data.shape[0]):\n",
      "            #    if curr_symbol_data.Ask_P[i]>price: continue\n",
      "            #    if (not AskPrices.has_key(curr_symbol_data.Ask_P[i])):\n",
      "            #        AskPrices[curr_symbol_data.Ask_P[i]] = curr_symbol_data.Ask_S[i]\n",
      "                    \n",
      "            volumeTraded = 1#min(abs(curr_symbol_data.ImbShares[0]),curr_symbol_data.Ask_S[0]       \n",
      "            OPC = curr_symbol_data.tPrice[(curr_symbol_data.tType=='OPG')]\n",
      "            pnl = volumeTraded*(OPC.values[0]-price)    \n",
      "            dayPnl.append(pnl)\n",
      "            if pnl<0:\n",
      "                negdayPnl.append(pnl)\n",
      "            \n",
      "            #if pnl<0:\n",
      "            #    print ' BUY   %s %s shares at %s SELL at %s PNL %s' % ( symbol,volumeTraded,price,OPC.values[0],pnl)\n",
      "             \n",
      "        for count, row in sells.iterrows():\n",
      "            symbol = row[2]\n",
      "            price = row[3]-add\n",
      "            curr_symbol_data=data[data.Symbol==symbol]#.between_time(startTimestamp,endTimestamp)\n",
      "            \n",
      "            #BidPrices = dict()\n",
      "            #for i in range(curr_symbol_data.shape[0]):\n",
      "            #    if curr_symbol_data.Bid_P[i]<price: continue\n",
      "            #    if (not BidPrices.has_key(curr_symbol_data.Bid_P[i])):\n",
      "            #        BidPrices[curr_symbol_data.Bid_P[i]] = curr_symbol_data.Bid_S[i]\n",
      "            \n",
      "            volumeTraded = 1#min(abs(curr_symbol_data.ImbShares[0]),curr_symbol_data.Bid_S[0])\n",
      "            OPC = curr_symbol_data.tPrice[curr_symbol_data.tType=='OPG']\n",
      "            pnl = volumeTraded*(price-OPC.values[0])\n",
      "            dayPnl.append(pnl)\n",
      "            if pnl<0:\n",
      "                negdayPnl.append(pnl)\n",
      "                \n",
      "            #if pnl<0:\n",
      "            #    print ' SELL  %s %s shares at %s BUY as %s PNL %s' % ( symbol,volumeTraded,price,OPC.values[0],pnl)        \n",
      "            \n",
      "        PNL.append(np.sum(dayPnl))\n",
      "        NEGPNL.append(np.sum(negdayPnl))\n",
      "        print '%s %s' % (day,np.sum(dayPnl))\n",
      "      \n",
      "    result = pd.DataFrame()\n",
      "    result['Date'] = days\n",
      "    result['Pnl'] = PNL\n",
      "    print '%s %s' % (np.sum(NEGPNL),np.sum(PNL))\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createFeatures34(fdf):\n",
      "    import itertools\n",
      "    initNumFeatures = fdf.shape[1]\n",
      "    diffsInd = [x for x in itertools.combinations(range(initNumFeatures),2)]\n",
      "    d_fdf = pd.DataFrame()\n",
      "    for i in range(len(diffsInd)):\n",
      "        #print i, diffsInd[i]\n",
      "        d_fdf[\"d\"+str(i)] = fdf.ix[:,diffsInd[i][0]]-fdf.ix[:,diffsInd[i][1]]\n",
      "    return d_fdf\n",
      "\n",
      "def createFeatures35(X_pos):\n",
      "    dfdf=createFeatures34(X_pos)\n",
      "    df=pd.DataFrame()\n",
      "    for i in range(X_pos.shape[1]):\n",
      "        for j in range(dfdf.shape[1]):\n",
      "            tmp=X_pos.ix[:,i]\n",
      "            tmp.ix[tmp.ix[:]==0]=1\n",
      "            df[str(j)+str(i)]=dfdf.ix[:,j]/X_pos.ix[:,i]\n",
      "    return pd.concat([dfdf,df], axis=1)\n",
      "\n",
      "def autocreateFeatures(X_pos,y_pos,ind):\n",
      "    from sklearn.ensemble import RandomForestClassifier as RF\n",
      "    clf = RF(min_samples_split = X_pos.shape[0]*0.05, criterion = 'entropy',n_estimators =10)\n",
      "    if ind==1:\n",
      "        newX_pos=createFeatures35(X_pos)\n",
      "    else:\n",
      "        newX_pos=createFeatures34(X_pos)\n",
      "    \n",
      "    clf.fit(newX_pos,y_pos)\n",
      "\n",
      "    fi = pd.DataFrame()\n",
      "    fi['Feature'] = list(newX_pos.columns)\n",
      "    fi['Impotrance'] = clf.feature_importances_\n",
      "    fi=fi.sort(columns=['Impotrance'],ascending=False)\n",
      "    fi['Index'] = range(newX_pos.shape[1])\n",
      "    fi.index = fi['Index']\n",
      "\n",
      "    for i in range(fi.shape[0]):\n",
      "        if (fi['Impotrance'][i]<0.005):\n",
      "            break\n",
      "        #print fi['Feature'][i]\n",
      "\n",
      "    newX_pos = newX_pos[fi['Feature'][:i]]\n",
      "\n",
      "    #Stage 2\n",
      "    poly = PolynomialFeatures(2)\n",
      "    newX_pos_2=pd.DataFrame(poly.fit_transform(newX_pos))\n",
      "    clf.fit(newX_pos_2,y_pos)\n",
      "\n",
      "    fi = pd.DataFrame()\n",
      "    fi['Feature'] = list(newX_pos_2.columns)\n",
      "    fi['Impotrance'] = clf.feature_importances_\n",
      "    fi=fi.sort(columns=['Impotrance'],ascending=False)\n",
      "    fi['Index'] = range(newX_pos_2.shape[1])\n",
      "    fi.index = fi['Index']\n",
      "\n",
      "    for i in range(fi.shape[0]):\n",
      "        if (fi['Impotrance'][i]<0.01):\n",
      "            break\n",
      "        #print fi['Feature'][i]\n",
      "\n",
      "    newX_pos_2 = newX_pos_2[fi['Feature'][:i]]\n",
      "\n",
      "    return newX_pos_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}